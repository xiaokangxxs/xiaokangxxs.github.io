{"title":"Kafka你了解多少？","slug":"Kafka你了解多少","date":"2021-04-24T08:43:07.561Z","updated":"2021-12-05T11:19:20.846Z","comments":true,"path":"api/articles/Kafka你了解多少.json","realPath":null,"excerpt":"百万级消息队列Kafka","covers":["https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-architecture.png","https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-isr.png"],"cover":"http://file.xiaokang.cool/colorful/colorful-5.jpg","content":"<h3 id=\"1-Kafka架构\"><a href=\"#1-Kafka架构\" class=\"headerlink\" title=\"1. Kafka架构\"></a>1. Kafka架构</h3><div align=\"center\"> <img width=\"600px\" src=\"https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-architecture.png\"/> </div>\n**Kafka Cluster**\n\n<p>Kafka作为分布式消息队列，是以集群形式对外服务的（即使只有一个节点）。初始化时会在Zookeeper的/cluster/id目录下创建ClusterID值</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[zk: localhost:2181(CONNECTED) 5] get /cluster/id<br>&#123;&quot;version&quot;:&quot;1&quot;,&quot;id&quot;:&quot;Nf1FphTTQni9RjWWz31lrQ&quot;&#125;<br></code></pre></td></tr></table></figure>\n\n<p><strong>Producer</strong></p>\n<p>生产者是Kafka中发送消息的客户端，主要是通过Zookeeper与Kafka集群进行连接，并且将消息发送<br>到Kafka集群  </p>\n<p><strong>Consumer</strong></p>\n<p>消费者是Kafka消息消费的客户端。Consumer直接与Kafka Borker构建连接消费Broker上某个主题<br>的数据</p>\n<p><strong>Zookeeper集群</strong></p>\n<p>Kafka集群、ISR、消费者组等信息存储在Zookeeper中，0.9版本之前消费者offset维护在zk中，0.9版本之后存储在本地</p>\n<p><strong>Topic</strong></p>\n<p>生产者发送消息时必须指定一个分类，我们将它称为主题。主题是Kafka中数据隔离的一种方式，Topic是一个逻辑概念，其真正的表现形式是在Kafka存储目录下创建多个关于该主题的文件夹。每个主题代表了一种数据来源。比如topicA：代表日志数据，topicB：代表用户数据 </p>\n<p><strong>Partition</strong></p>\n<p>Partition就是Topic物理上的实现，其表现形式为目录。每个Topic可以包含多个分区，每个Partiton包含了Topic的部分数据。Partition目录命名方式：Topic名称-分区ID，比如logs，三个分区logs-0、logs-1、logs-2  </p>\n<p><strong>Broker</strong></p>\n<p>Kafka集群中每个节点都是Broker。一个集群可以包含N个Broker，Broker.id值必须不同。在Zookeeper之上可以查看每个节点的详细信息</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[zk: localhost:2181(CONNECTED) 11] get /brokers/ids/0<br>&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://hadoop:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;hadoop&quot;,&quot;timestamp&quot;:&quot;1593767504799&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;<br></code></pre></td></tr></table></figure>\n\n<p><strong>Consumer Group</strong></p>\n<p>消费者组主要用来管理组织消费者的，并且消费者组规定了消费消息的行为。Kafka实现点对点和发布订阅模式主要是基于Consumer Group的，其中：在同一个消费者组内，消息是P2P模式；在不同消费者组之间，消息是发布订阅模式  </p>\n<h3 id=\"2-Kafka压测\"><a href=\"#2-Kafka压测\" class=\"headerlink\" title=\"2. Kafka压测\"></a>2. Kafka压测</h3><p>使用Kafka官方自带压力测试脚本（kafka-consumer-perf-test.sh、kafka-producer-perf-test.sh）进行压测，可以查看哪个地方出现了瓶颈（CPU、内存、网络IO）。<strong>一般都是网络IO达到瓶颈</strong>  </p>\n<p><strong>写入10w消息压测结果</strong> </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[xiaokang@hadoop ~]$ kafka-producer-perf-test.sh --topic logs --num-records 100000 --record-size 1000  --throughput 2000 --producer-props bootstrap.servers=hadoop:9092<br><br>10002 records sent, 1999.6 records/sec (1.91 MB/sec), 30.1 ms avg latency, 608.0 ms max latency.<br>9990 records sent, 1997.6 records/sec (1.91 MB/sec), 1.4 ms avg latency, 28.0 ms max latency.<br>10022 records sent, 2004.4 records/sec (1.91 MB/sec), 0.9 ms avg latency, 13.0 ms max latency.<br>9998 records sent, 1999.6 records/sec (1.91 MB/sec), 1.0 ms avg latency, 13.0 ms max latency.<br>9986 records sent, 1996.4 records/sec (1.90 MB/sec), 0.9 ms avg latency, 12.0 ms max latency.<br>10022 records sent, 2004.4 records/sec (1.91 MB/sec), 0.7 ms avg latency, 21.0 ms max latency.<br>10002 records sent, 2000.0 records/sec (1.91 MB/sec), 0.5 ms avg latency, 12.0 ms max latency.<br>10002 records sent, 2000.0 records/sec (1.91 MB/sec), 0.4 ms avg latency, 11.0 ms max latency.<br>10004 records sent, 2000.4 records/sec (1.91 MB/sec), 0.4 ms avg latency, 12.0 ms max latency.<br>100000 records sent, 1999.000500 records/sec (1.91 MB/sec), 3.68 ms avg latency, 608.00 ms max latency, 1 ms 50th, 3 ms 95th, 164 ms 99th, 218 ms 99.9th.<br><br>--topic topic名称，此处为logs<br>--num-records 总共需要发送的消息数，此处为100000<br>--record-size 每个记录的字节数，此处为1000<br>--throughput 每秒钟发送的记录数，此处为2000，如果设置为-1，则表示不限流，可以测出生产者最大吞吐量<br>--producer-props bootstrap.servers=hadoop:9092 发送端的配置信息，此处使用默认端口号9092<br><br><span class=\"hljs-meta\">#</span><span class=\"bash\">消息写入测试结果解析：</span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">本例中写入10w条消息为例，每秒平均向Kafka写入了1.91MB的数据，大概是1999.000条消息/秒，每次写入的平均延迟为3.68毫秒，最大的延迟为608毫秒。</span><br></code></pre></td></tr></table></figure>\n\n<p><strong>消费10w消息压测结果</strong> </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[xiaokang@hadoop ~]$ kafka-consumer-perf-test.sh --broker-list hadoop:9092 --topic logs --fetch-size 1048576 --messages 100000 --threads 1<br><br>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec<br>2020-07-03 19:33:36:119, 2020-07-03 19:33:39:595, 95.3674, 27.4360, 100000, 28768.6997, 1593776018209, -1593776014733, -0.0000, -0.0001<br><br>--broker-list 指定Kafka的链接信息，此处为hadoop:9092<br>--topic 指定Topic的名称，此处为logs，即上面写入的消息<br>--fetch-size 指定每次fetch的数据的大小，本例为1048576（1M）<br>--messages 总共要消费的消息个数，此处为100000，10w<br><br><span class=\"hljs-meta\">#</span><span class=\"bash\">消息消费测试结果解析：</span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">本例中消费10w条消息为例总共消费了95.3674M的数据，每秒消费数据大小为27.4360M，总共消费了100000条消息，每秒消费28768.6997条消息。</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-Kafka机器数量计算\"><a href=\"#3-Kafka机器数量计算\" class=\"headerlink\" title=\"3. Kafka机器数量计算\"></a>3. Kafka机器数量计算</h3><p>Kafka机器数量=2*（峰值生产速度*副本数/100）+1</p>\n<p>一般我们会先拿到峰值生产速度（写入消息时每秒写入的数据量），再根据设定的副本数就可以预估出需要部署Kafka的数量</p>\n<p>一般峰值生产速度在50M/s，副本数为2，这样得出Kafka机器数量=2*（50*2/100）+1=3台</p>\n<h3 id=\"4-生产者生产数据过程\"><a href=\"#4-生产者生产数据过程\" class=\"headerlink\" title=\"4. 生产者生产数据过程\"></a>4. 生产者生产数据过程</h3><p>以kafka-console-producer.sh 命令为例：<br>该运行命令会启动ConsoleProducer进程，ConsoleProducer初始化过程中会创建KafkaProducer对象。KafkaProducer首先将消息数据封装成ProducerRecord，ProducerRecord对象会对消息进行序列化（涉及到网络传输），之后会被RecordAccumulator消息记录器进行收集，进而放在消息队列缓冲池（ConcurrentMap）。消息缓冲池中对象是以batch存在（一次一批数据）。KafkaProducer在进行初始化的时候会创建NetworkClient对象。NetworkClient主要作用负责管理客户端与服务端的网络通信，并且是以NIO的形式发送消息（同步或异步发送均可）。最后由后台sender线程将数据从缓冲池队列中拉取过来，以批量的形式将数据发送到客户端</p>\n<figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs properties\"><span class=\"hljs-attr\">NetworkClient：三大核心功能</span><br><span class=\"hljs-attr\">1.ready()：主要建立与broker链接。NetworkClient连接到kafka集群中存活的节点</span><br><span class=\"hljs-attr\">2.send()：用来将客户端请求发送到请求队列中，进而会通过网络选择器将请求最终发送到Kafka集群存活的节点</span><br><span class=\"hljs-attr\">3.poll()：用来通过socket请求读取客户端的响应。一般poll()是循环操作</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-消费者消费数据过程\"><a href=\"#5-消费者消费数据过程\" class=\"headerlink\" title=\"5. 消费者消费数据过程\"></a>5. 消费者消费数据过程</h3><p>客户端代理对象KafkaConsumer通过subscribe订阅主题，并且通过poll拉取数据，最后通过commitSync方法提交消费者消费状态（维护offset值）。拉取数据是以特定的时间参数轮询的批量拉取数据，并将拉取的结果缓存到ConsumerRecords，最后通过迭代ConsumerRecords对象获取每一条数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">ConsumerCoordinator：KafkaConsumer协调器对象，主要负责与服务端进行交互，比如自动提交offset、心跳检测、再平衡操作、跟踪kafka元数据<br>Fetcher：拉取数据管理器，负责拉取数据并且接受客户端响应<br>ConsumerNetworkClient：主要负责与Kafka服务节点进行连接，发送拉取数据请求<br><br>max.poll.records ：每次轮询获取最大批量的数据条数 默认500条<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-一些Kafka经验值\"><a href=\"#6-一些Kafka经验值\" class=\"headerlink\" title=\"6. 一些Kafka经验值\"></a>6. 一些Kafka经验值</h3><figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs properties\"><span class=\"hljs-comment\"># Kafka的日志保存时间，默认7天</span><br><span class=\"hljs-meta\">log.retention.hours</span>=<span class=\"hljs-string\">168</span><br><br><span class=\"hljs-attr\">Kafka硬盘大小多大合适？</span><br><span class=\"hljs-attr\">每天的数据量*7天/70%</span><br><br><span class=\"hljs-attr\">Kafka监控器：KafkaManager、KafkaMonitor、kafkaeagle</span><br><br><span class=\"hljs-attr\">Kafka分区数设置多少合适？</span><br><span class=\"hljs-attr\">分区数并不是越多越好，一般分区数不要超过集群机器数量。分区数越多占用内存越大（ISR等），一个节点集中的分区也就越多，当它宕机的时候，对系统的影响也就越大。分区数一般设置为：3-10</span><br><br><span class=\"hljs-attr\">副本数设置多少合适？</span><br><span class=\"hljs-attr\">一般设置成2个或3个，大部分企业设置为2个</span><br><br><span class=\"hljs-attr\">Topic搞多少个合适？</span><br><span class=\"hljs-attr\">通常情况下多少个日志类型就多少个Topic，也有对日志类型进行合并的</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"7-一条消息如何确定分区？\"><a href=\"#7-一条消息如何确定分区？\" class=\"headerlink\" title=\"7. 一条消息如何确定分区？\"></a>7. 一条消息如何确定分区？</h3><p>KafkaProducer提供了三种方式来让一条消息确定分区</p>\n<p>1.通过ProducerRecord对象中partition属性指定分区id</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ProducerRecord</span>&lt;<span class=\"hljs-title\">K</span>, <span class=\"hljs-title\">V</span>&gt; </span>&#123;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> String topic;<br>        <span class=\"hljs-comment\">//分区</span><br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> Integer partition;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> Headers headers;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> K key;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> V value;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> Long timestamp;<br>        <span class=\"hljs-comment\">//构造函数</span><br>        <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">ProducerRecord</span><span class=\"hljs-params\">(String topic, Integer partition, Long timestamp, K key, V value)</span> </span>&#123;<br>        \t\t<span class=\"hljs-keyword\">this</span>(topic, partition, timestamp, key, value, <span class=\"hljs-keyword\">null</span>);<br>        &#125;<br>&#125; <br><br><span class=\"hljs-comment\">// Kafka消息被封装成ProducerRecord，在创建时可以通过构造函数指定partitionId</span><br></code></pre></td></tr></table></figure>\n\n<p>2.未指定partitionId，但key不为空，此时根据key的hash值进行分区</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">partition</span><span class=\"hljs-params\">(ProducerRecord&lt;K, V&gt; record, <span class=\"hljs-keyword\">byte</span>[]serializedKey, <span class=\"hljs-keyword\">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;<br>        Integer partition = record.partition();<br>        <span class=\"hljs-keyword\">return</span> partition != <span class=\"hljs-keyword\">null</span> ?<br>        partition :<br>        partitioner.partition(<br>        record.topic(), record.key(), serializedKey,record.value(), serializedValue, cluster);<br>&#125;<br><span class=\"hljs-comment\">// hash the keyBytes to choose a partition</span><br><span class=\"hljs-keyword\">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;<br><span class=\"hljs-comment\">// 根据key字节数组的hash值和分区数量进行取模得到paritionId。在partition数量不变的情况，相同的key值数据可以被分配到相同的partition</span><br></code></pre></td></tr></table></figure>\n\n<p>3.未指定partitionId，同时key也为null，此时会采用轮询的方式将消息均衡的分配到不同分区中（默认情况下key就是null）</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">//计算轮询值</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">nextValue</span><span class=\"hljs-params\">(String topic)</span> </span>&#123;<br>        AtomicInteger counter = topicCounterMap.get(topic);<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">null</span> == counter) &#123;<br>                counter = <span class=\"hljs-keyword\">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());<br>                AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);<br>                <span class=\"hljs-keyword\">if</span> (currentCounter != <span class=\"hljs-keyword\">null</span>) &#123;<br>                \t\tcounter = currentCounter;<br>                &#125;<br>        &#125; <br>    \t<span class=\"hljs-keyword\">return</span> counter.getAndIncrement();<br>&#125;<br><span class=\"hljs-comment\">//key为空采用轮询方式均衡分配到不同Id</span><br><span class=\"hljs-keyword\">if</span> (keyBytes == <span class=\"hljs-keyword\">null</span>) &#123;<br>        <span class=\"hljs-keyword\">int</span> nextValue = nextValue(topic);<br>        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);<br>        <span class=\"hljs-keyword\">if</span> (availablePartitions.size() &gt; <span class=\"hljs-number\">0</span>) &#123;<br>                <span class=\"hljs-keyword\">int</span> part = Utils.toPositive(nextValue) %availablePartitions.size();<br>                <span class=\"hljs-keyword\">return</span> availablePartitions.get(part).partition();<br>        &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>                <span class=\"hljs-comment\">// no partitions are available, give a nonavailable partition</span><br>                <span class=\"hljs-keyword\">return</span> Utils.toPositive(nextValue) % numPartitions;<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"8-可用性和可靠性保证机制\"><a href=\"#8-可用性和可靠性保证机制\" class=\"headerlink\" title=\"8. 可用性和可靠性保证机制\"></a>8. 可用性和可靠性保证机制</h3><p>KafkaProducer发送数据请求，可以通过acks参数确保整个提交请求完成。acks主要是设置Producer在确认一条消息发送完成之前需要收到的反馈信息。  </p>\n<p>acks=0，相当于异步发送，表示不等待任何服务器反馈消息，消息发送完毕即offset增加，继续生产。</p>\n<p>优点：发送效率比较高，能够适应高并发场景。<br>缺点：不能够有效保证数据不丢失<br>适用场景：对于数据准确定要求不高的实时系统，登录、操作等log日志  </p>\n<p>acks=1，leader收到leader replica 对一个消息的接受ack才增加offset，然后继续生产。</p>\n<p>优点：该配置能够确保每个partition的leader节点能够成功的接收消息<br>缺点：不能够保证partition的副本节点接收到数据，该种情况有可能造成数据丢失。leader接收到消息后宕机，此时该partition的其他副本没有同步到该消息，这样就造成数据丢失</p>\n<p>acks=-1/all，leader收到所有replica 对一个消息的接受ack才增加offset，然后继续生产。</p>\n<p>优点：该配置能够最大限度的保证数据持久化并且不丢失<br>缺点：降低系统响应速度</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 该参数表示成功写入最小副本数</span><br>min.insync.replicas=2 表示只要是能够写入2个副本就表示成功。<br>生产环境下一般配合acks=-1使用，这样能够兼顾数据安全和响应速度  <br></code></pre></td></tr></table></figure>\n\n<h3 id=\"9-ISR机制\"><a href=\"#9-ISR机制\" class=\"headerlink\" title=\"9. ISR机制\"></a>9. ISR机制</h3><p>ISR（In-Sync Replicas），副本同步队列。ISR中包括Leader和Follower，Leader副本负责维护和跟踪ISR集合中所有Follower副本的。当Follower副本同步Leader数据时，如果滞后太多或者失效的话，Leader会将Follower从ISR列表中移除从而转移到OSR。OSR集合中Follower一旦追上Leader副本，那么Leader会将该Follower从OSR集合转移到ISR中。当Leader副本发生故障时，只有在ISR集合的副本会有资格选举成Leader。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">replica.lag.time.max.ms=10000 单位毫秒：表示follower在规定的时间内没有同步完成Leader数据，将会被剔除从而到OSR中<br></code></pre></td></tr></table></figure>\n\n<div align=\"center\"> <img width=\"600px\" src=\"https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-isr.png\"/> </div>\n### 10. Kafka幂等性和数据重复\n\n<p>Producer的幂等性指的是当发送同一条消息时，数据在Server端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：</p>\n<p>1）<strong>只能保证Producer在单个会话内不丟不重，如果Producer出现意外而挂掉再重启是无法保证的</strong>（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）。</p>\n<p>2）幂等性不能跨多个Topic-Partition，<strong>只能保证单个Partition内的幂等性</strong>，当涉及多个Topic-Partition时，这中间的状态并没有同步。</p>\n<p>解决数据重复：开启幂等性+ack=-1+事务  </p>\n<h3 id=\"11-Kafka参数优化\"><a href=\"#11-Kafka参数优化\" class=\"headerlink\" title=\"11. Kafka参数优化\"></a>11. Kafka参数优化</h3><p><strong>Broker参数配置（server.properties）</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">broker处理消息的最大线程数（默认为3）</span><br>num.network.threads=cpu核数+1<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> broker处理磁盘IO的线程数</span> <br>num.io.threads=cpu核数*2<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 每当producer写入10000条消息时，刷数据到磁盘</span> <br>log.flush.interval.messages=10000<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 每间隔1秒钟时间，刷数据到磁盘</span><br>log.flush.interval.ms=1000<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 保留三天，也可以更短 （log.cleaner.delete.retention.ms）</span><br>log.retention.hours=72<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 这个参数指新创建一个topic时，默认的Replica数量,Replica过少会影响数据的可用性，太多则会白白浪费存储资源，一般建议在2~3为宜。</span><br>offsets.topic.replication.factor:3<br></code></pre></td></tr></table></figure>\n\n<p><strong>Producer优化（producer.properties）</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">在Producer端用来存放尚未发送出去的Message的缓冲区大小。缓冲区满了之后可以选择阻塞发送或抛出异常，由block.on.buffer.full的配置来决定。</span><br>buffer.memory:33554432 (32m)<br><span class=\"hljs-meta\">#</span><span class=\"bash\">默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力。</span><br>compression.type:none<br></code></pre></td></tr></table></figure>\n\n<p><strong>Consumer优化</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">启动Consumer的个数，适当增加可以提高并发度。</span><br>num.consumer.fetchers:1<br><span class=\"hljs-meta\">#</span><span class=\"bash\">每次Fetch Request至少要拿到多少字节的数据才可以返回。</span><br>fetch.min.bytes:1<br><span class=\"hljs-meta\">#</span><span class=\"bash\">在Fetch Request获取的数据至少达到fetch.min.bytes之前，允许等待的最大时长。对应上面说到的Purgatory中请求的超时时间。</span><br>fetch.wait.max.ms:100<br></code></pre></td></tr></table></figure>\n\n<p><strong>Kafka内存调整（kafka-server-start.sh）</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 默认内存1个G，生产环境尽量不要超过6个G。</span><br>export KAFKA_HEAP_OPTS=&quot;-Xms4g -Xmx4g&quot;<br></code></pre></td></tr></table></figure>","more":"<h3 id=\"1-Kafka架构\"><a href=\"#1-Kafka架构\" class=\"headerlink\" title=\"1. Kafka架构\"></a>1. Kafka架构</h3><div align=\"center\"> <img width=\"600px\" src=\"https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-architecture.png\"/> </div>\n**Kafka Cluster**\n\n<p>Kafka作为分布式消息队列，是以集群形式对外服务的（即使只有一个节点）。初始化时会在Zookeeper的/cluster/id目录下创建ClusterID值</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[zk: localhost:2181(CONNECTED) 5] get /cluster/id<br>&#123;&quot;version&quot;:&quot;1&quot;,&quot;id&quot;:&quot;Nf1FphTTQni9RjWWz31lrQ&quot;&#125;<br></code></pre></td></tr></table></figure>\n\n<p><strong>Producer</strong></p>\n<p>生产者是Kafka中发送消息的客户端，主要是通过Zookeeper与Kafka集群进行连接，并且将消息发送<br>到Kafka集群  </p>\n<p><strong>Consumer</strong></p>\n<p>消费者是Kafka消息消费的客户端。Consumer直接与Kafka Borker构建连接消费Broker上某个主题<br>的数据</p>\n<p><strong>Zookeeper集群</strong></p>\n<p>Kafka集群、ISR、消费者组等信息存储在Zookeeper中，0.9版本之前消费者offset维护在zk中，0.9版本之后存储在本地</p>\n<p><strong>Topic</strong></p>\n<p>生产者发送消息时必须指定一个分类，我们将它称为主题。主题是Kafka中数据隔离的一种方式，Topic是一个逻辑概念，其真正的表现形式是在Kafka存储目录下创建多个关于该主题的文件夹。每个主题代表了一种数据来源。比如topicA：代表日志数据，topicB：代表用户数据 </p>\n<p><strong>Partition</strong></p>\n<p>Partition就是Topic物理上的实现，其表现形式为目录。每个Topic可以包含多个分区，每个Partiton包含了Topic的部分数据。Partition目录命名方式：Topic名称-分区ID，比如logs，三个分区logs-0、logs-1、logs-2  </p>\n<p><strong>Broker</strong></p>\n<p>Kafka集群中每个节点都是Broker。一个集群可以包含N个Broker，Broker.id值必须不同。在Zookeeper之上可以查看每个节点的详细信息</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[zk: localhost:2181(CONNECTED) 11] get /brokers/ids/0<br>&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://hadoop:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;hadoop&quot;,&quot;timestamp&quot;:&quot;1593767504799&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;<br></code></pre></td></tr></table></figure>\n\n<p><strong>Consumer Group</strong></p>\n<p>消费者组主要用来管理组织消费者的，并且消费者组规定了消费消息的行为。Kafka实现点对点和发布订阅模式主要是基于Consumer Group的，其中：在同一个消费者组内，消息是P2P模式；在不同消费者组之间，消息是发布订阅模式  </p>\n<h3 id=\"2-Kafka压测\"><a href=\"#2-Kafka压测\" class=\"headerlink\" title=\"2. Kafka压测\"></a>2. Kafka压测</h3><p>使用Kafka官方自带压力测试脚本（kafka-consumer-perf-test.sh、kafka-producer-perf-test.sh）进行压测，可以查看哪个地方出现了瓶颈（CPU、内存、网络IO）。<strong>一般都是网络IO达到瓶颈</strong>  </p>\n<p><strong>写入10w消息压测结果</strong> </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[xiaokang@hadoop ~]$ kafka-producer-perf-test.sh --topic logs --num-records 100000 --record-size 1000  --throughput 2000 --producer-props bootstrap.servers=hadoop:9092<br><br>10002 records sent, 1999.6 records/sec (1.91 MB/sec), 30.1 ms avg latency, 608.0 ms max latency.<br>9990 records sent, 1997.6 records/sec (1.91 MB/sec), 1.4 ms avg latency, 28.0 ms max latency.<br>10022 records sent, 2004.4 records/sec (1.91 MB/sec), 0.9 ms avg latency, 13.0 ms max latency.<br>9998 records sent, 1999.6 records/sec (1.91 MB/sec), 1.0 ms avg latency, 13.0 ms max latency.<br>9986 records sent, 1996.4 records/sec (1.90 MB/sec), 0.9 ms avg latency, 12.0 ms max latency.<br>10022 records sent, 2004.4 records/sec (1.91 MB/sec), 0.7 ms avg latency, 21.0 ms max latency.<br>10002 records sent, 2000.0 records/sec (1.91 MB/sec), 0.5 ms avg latency, 12.0 ms max latency.<br>10002 records sent, 2000.0 records/sec (1.91 MB/sec), 0.4 ms avg latency, 11.0 ms max latency.<br>10004 records sent, 2000.4 records/sec (1.91 MB/sec), 0.4 ms avg latency, 12.0 ms max latency.<br>100000 records sent, 1999.000500 records/sec (1.91 MB/sec), 3.68 ms avg latency, 608.00 ms max latency, 1 ms 50th, 3 ms 95th, 164 ms 99th, 218 ms 99.9th.<br><br>--topic topic名称，此处为logs<br>--num-records 总共需要发送的消息数，此处为100000<br>--record-size 每个记录的字节数，此处为1000<br>--throughput 每秒钟发送的记录数，此处为2000，如果设置为-1，则表示不限流，可以测出生产者最大吞吐量<br>--producer-props bootstrap.servers=hadoop:9092 发送端的配置信息，此处使用默认端口号9092<br><br><span class=\"hljs-meta\">#</span><span class=\"bash\">消息写入测试结果解析：</span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">本例中写入10w条消息为例，每秒平均向Kafka写入了1.91MB的数据，大概是1999.000条消息/秒，每次写入的平均延迟为3.68毫秒，最大的延迟为608毫秒。</span><br></code></pre></td></tr></table></figure>\n\n<p><strong>消费10w消息压测结果</strong> </p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">[xiaokang@hadoop ~]$ kafka-consumer-perf-test.sh --broker-list hadoop:9092 --topic logs --fetch-size 1048576 --messages 100000 --threads 1<br><br>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec<br>2020-07-03 19:33:36:119, 2020-07-03 19:33:39:595, 95.3674, 27.4360, 100000, 28768.6997, 1593776018209, -1593776014733, -0.0000, -0.0001<br><br>--broker-list 指定Kafka的链接信息，此处为hadoop:9092<br>--topic 指定Topic的名称，此处为logs，即上面写入的消息<br>--fetch-size 指定每次fetch的数据的大小，本例为1048576（1M）<br>--messages 总共要消费的消息个数，此处为100000，10w<br><br><span class=\"hljs-meta\">#</span><span class=\"bash\">消息消费测试结果解析：</span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">本例中消费10w条消息为例总共消费了95.3674M的数据，每秒消费数据大小为27.4360M，总共消费了100000条消息，每秒消费28768.6997条消息。</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-Kafka机器数量计算\"><a href=\"#3-Kafka机器数量计算\" class=\"headerlink\" title=\"3. Kafka机器数量计算\"></a>3. Kafka机器数量计算</h3><p>Kafka机器数量=2*（峰值生产速度*副本数/100）+1</p>\n<p>一般我们会先拿到峰值生产速度（写入消息时每秒写入的数据量），再根据设定的副本数就可以预估出需要部署Kafka的数量</p>\n<p>一般峰值生产速度在50M/s，副本数为2，这样得出Kafka机器数量=2*（50*2/100）+1=3台</p>\n<h3 id=\"4-生产者生产数据过程\"><a href=\"#4-生产者生产数据过程\" class=\"headerlink\" title=\"4. 生产者生产数据过程\"></a>4. 生产者生产数据过程</h3><p>以kafka-console-producer.sh 命令为例：<br>该运行命令会启动ConsoleProducer进程，ConsoleProducer初始化过程中会创建KafkaProducer对象。KafkaProducer首先将消息数据封装成ProducerRecord，ProducerRecord对象会对消息进行序列化（涉及到网络传输），之后会被RecordAccumulator消息记录器进行收集，进而放在消息队列缓冲池（ConcurrentMap）。消息缓冲池中对象是以batch存在（一次一批数据）。KafkaProducer在进行初始化的时候会创建NetworkClient对象。NetworkClient主要作用负责管理客户端与服务端的网络通信，并且是以NIO的形式发送消息（同步或异步发送均可）。最后由后台sender线程将数据从缓冲池队列中拉取过来，以批量的形式将数据发送到客户端</p>\n<figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs properties\"><span class=\"hljs-attr\">NetworkClient：三大核心功能</span><br><span class=\"hljs-attr\">1.ready()：主要建立与broker链接。NetworkClient连接到kafka集群中存活的节点</span><br><span class=\"hljs-attr\">2.send()：用来将客户端请求发送到请求队列中，进而会通过网络选择器将请求最终发送到Kafka集群存活的节点</span><br><span class=\"hljs-attr\">3.poll()：用来通过socket请求读取客户端的响应。一般poll()是循环操作</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-消费者消费数据过程\"><a href=\"#5-消费者消费数据过程\" class=\"headerlink\" title=\"5. 消费者消费数据过程\"></a>5. 消费者消费数据过程</h3><p>客户端代理对象KafkaConsumer通过subscribe订阅主题，并且通过poll拉取数据，最后通过commitSync方法提交消费者消费状态（维护offset值）。拉取数据是以特定的时间参数轮询的批量拉取数据，并将拉取的结果缓存到ConsumerRecords，最后通过迭代ConsumerRecords对象获取每一条数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">ConsumerCoordinator：KafkaConsumer协调器对象，主要负责与服务端进行交互，比如自动提交offset、心跳检测、再平衡操作、跟踪kafka元数据<br>Fetcher：拉取数据管理器，负责拉取数据并且接受客户端响应<br>ConsumerNetworkClient：主要负责与Kafka服务节点进行连接，发送拉取数据请求<br><br>max.poll.records ：每次轮询获取最大批量的数据条数 默认500条<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-一些Kafka经验值\"><a href=\"#6-一些Kafka经验值\" class=\"headerlink\" title=\"6. 一些Kafka经验值\"></a>6. 一些Kafka经验值</h3><figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs properties\"><span class=\"hljs-comment\"># Kafka的日志保存时间，默认7天</span><br><span class=\"hljs-meta\">log.retention.hours</span>=<span class=\"hljs-string\">168</span><br><br><span class=\"hljs-attr\">Kafka硬盘大小多大合适？</span><br><span class=\"hljs-attr\">每天的数据量*7天/70%</span><br><br><span class=\"hljs-attr\">Kafka监控器：KafkaManager、KafkaMonitor、kafkaeagle</span><br><br><span class=\"hljs-attr\">Kafka分区数设置多少合适？</span><br><span class=\"hljs-attr\">分区数并不是越多越好，一般分区数不要超过集群机器数量。分区数越多占用内存越大（ISR等），一个节点集中的分区也就越多，当它宕机的时候，对系统的影响也就越大。分区数一般设置为：3-10</span><br><br><span class=\"hljs-attr\">副本数设置多少合适？</span><br><span class=\"hljs-attr\">一般设置成2个或3个，大部分企业设置为2个</span><br><br><span class=\"hljs-attr\">Topic搞多少个合适？</span><br><span class=\"hljs-attr\">通常情况下多少个日志类型就多少个Topic，也有对日志类型进行合并的</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"7-一条消息如何确定分区？\"><a href=\"#7-一条消息如何确定分区？\" class=\"headerlink\" title=\"7. 一条消息如何确定分区？\"></a>7. 一条消息如何确定分区？</h3><p>KafkaProducer提供了三种方式来让一条消息确定分区</p>\n<p>1.通过ProducerRecord对象中partition属性指定分区id</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ProducerRecord</span>&lt;<span class=\"hljs-title\">K</span>, <span class=\"hljs-title\">V</span>&gt; </span>&#123;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> String topic;<br>        <span class=\"hljs-comment\">//分区</span><br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> Integer partition;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> Headers headers;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> K key;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> V value;<br>        <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> Long timestamp;<br>        <span class=\"hljs-comment\">//构造函数</span><br>        <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-title\">ProducerRecord</span><span class=\"hljs-params\">(String topic, Integer partition, Long timestamp, K key, V value)</span> </span>&#123;<br>        \t\t<span class=\"hljs-keyword\">this</span>(topic, partition, timestamp, key, value, <span class=\"hljs-keyword\">null</span>);<br>        &#125;<br>&#125; <br><br><span class=\"hljs-comment\">// Kafka消息被封装成ProducerRecord，在创建时可以通过构造函数指定partitionId</span><br></code></pre></td></tr></table></figure>\n\n<p>2.未指定partitionId，但key不为空，此时根据key的hash值进行分区</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">partition</span><span class=\"hljs-params\">(ProducerRecord&lt;K, V&gt; record, <span class=\"hljs-keyword\">byte</span>[]serializedKey, <span class=\"hljs-keyword\">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;<br>        Integer partition = record.partition();<br>        <span class=\"hljs-keyword\">return</span> partition != <span class=\"hljs-keyword\">null</span> ?<br>        partition :<br>        partitioner.partition(<br>        record.topic(), record.key(), serializedKey,record.value(), serializedValue, cluster);<br>&#125;<br><span class=\"hljs-comment\">// hash the keyBytes to choose a partition</span><br><span class=\"hljs-keyword\">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;<br><span class=\"hljs-comment\">// 根据key字节数组的hash值和分区数量进行取模得到paritionId。在partition数量不变的情况，相同的key值数据可以被分配到相同的partition</span><br></code></pre></td></tr></table></figure>\n\n<p>3.未指定partitionId，同时key也为null，此时会采用轮询的方式将消息均衡的分配到不同分区中（默认情况下key就是null）</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">//计算轮询值</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">nextValue</span><span class=\"hljs-params\">(String topic)</span> </span>&#123;<br>        AtomicInteger counter = topicCounterMap.get(topic);<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">null</span> == counter) &#123;<br>                counter = <span class=\"hljs-keyword\">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());<br>                AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);<br>                <span class=\"hljs-keyword\">if</span> (currentCounter != <span class=\"hljs-keyword\">null</span>) &#123;<br>                \t\tcounter = currentCounter;<br>                &#125;<br>        &#125; <br>    \t<span class=\"hljs-keyword\">return</span> counter.getAndIncrement();<br>&#125;<br><span class=\"hljs-comment\">//key为空采用轮询方式均衡分配到不同Id</span><br><span class=\"hljs-keyword\">if</span> (keyBytes == <span class=\"hljs-keyword\">null</span>) &#123;<br>        <span class=\"hljs-keyword\">int</span> nextValue = nextValue(topic);<br>        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);<br>        <span class=\"hljs-keyword\">if</span> (availablePartitions.size() &gt; <span class=\"hljs-number\">0</span>) &#123;<br>                <span class=\"hljs-keyword\">int</span> part = Utils.toPositive(nextValue) %availablePartitions.size();<br>                <span class=\"hljs-keyword\">return</span> availablePartitions.get(part).partition();<br>        &#125; <span class=\"hljs-keyword\">else</span> &#123;<br>                <span class=\"hljs-comment\">// no partitions are available, give a nonavailable partition</span><br>                <span class=\"hljs-keyword\">return</span> Utils.toPositive(nextValue) % numPartitions;<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"8-可用性和可靠性保证机制\"><a href=\"#8-可用性和可靠性保证机制\" class=\"headerlink\" title=\"8. 可用性和可靠性保证机制\"></a>8. 可用性和可靠性保证机制</h3><p>KafkaProducer发送数据请求，可以通过acks参数确保整个提交请求完成。acks主要是设置Producer在确认一条消息发送完成之前需要收到的反馈信息。  </p>\n<p>acks=0，相当于异步发送，表示不等待任何服务器反馈消息，消息发送完毕即offset增加，继续生产。</p>\n<p>优点：发送效率比较高，能够适应高并发场景。<br>缺点：不能够有效保证数据不丢失<br>适用场景：对于数据准确定要求不高的实时系统，登录、操作等log日志  </p>\n<p>acks=1，leader收到leader replica 对一个消息的接受ack才增加offset，然后继续生产。</p>\n<p>优点：该配置能够确保每个partition的leader节点能够成功的接收消息<br>缺点：不能够保证partition的副本节点接收到数据，该种情况有可能造成数据丢失。leader接收到消息后宕机，此时该partition的其他副本没有同步到该消息，这样就造成数据丢失</p>\n<p>acks=-1/all，leader收到所有replica 对一个消息的接受ack才增加offset，然后继续生产。</p>\n<p>优点：该配置能够最大限度的保证数据持久化并且不丢失<br>缺点：降低系统响应速度</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 该参数表示成功写入最小副本数</span><br>min.insync.replicas=2 表示只要是能够写入2个副本就表示成功。<br>生产环境下一般配合acks=-1使用，这样能够兼顾数据安全和响应速度  <br></code></pre></td></tr></table></figure>\n\n<h3 id=\"9-ISR机制\"><a href=\"#9-ISR机制\" class=\"headerlink\" title=\"9. ISR机制\"></a>9. ISR机制</h3><p>ISR（In-Sync Replicas），副本同步队列。ISR中包括Leader和Follower，Leader副本负责维护和跟踪ISR集合中所有Follower副本的。当Follower副本同步Leader数据时，如果滞后太多或者失效的话，Leader会将Follower从ISR列表中移除从而转移到OSR。OSR集合中Follower一旦追上Leader副本，那么Leader会将该Follower从OSR集合转移到ISR中。当Leader副本发生故障时，只有在ISR集合的副本会有资格选举成Leader。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\">replica.lag.time.max.ms=10000 单位毫秒：表示follower在规定的时间内没有同步完成Leader数据，将会被剔除从而到OSR中<br></code></pre></td></tr></table></figure>\n\n<div align=\"center\"> <img width=\"600px\" src=\"https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-isr.png\"/> </div>\n### 10. Kafka幂等性和数据重复\n\n<p>Producer的幂等性指的是当发送同一条消息时，数据在Server端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：</p>\n<p>1）<strong>只能保证Producer在单个会话内不丟不重，如果Producer出现意外而挂掉再重启是无法保证的</strong>（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）。</p>\n<p>2）幂等性不能跨多个Topic-Partition，<strong>只能保证单个Partition内的幂等性</strong>，当涉及多个Topic-Partition时，这中间的状态并没有同步。</p>\n<p>解决数据重复：开启幂等性+ack=-1+事务  </p>\n<h3 id=\"11-Kafka参数优化\"><a href=\"#11-Kafka参数优化\" class=\"headerlink\" title=\"11. Kafka参数优化\"></a>11. Kafka参数优化</h3><p><strong>Broker参数配置（server.properties）</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">broker处理消息的最大线程数（默认为3）</span><br>num.network.threads=cpu核数+1<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> broker处理磁盘IO的线程数</span> <br>num.io.threads=cpu核数*2<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 每当producer写入10000条消息时，刷数据到磁盘</span> <br>log.flush.interval.messages=10000<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 每间隔1秒钟时间，刷数据到磁盘</span><br>log.flush.interval.ms=1000<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 保留三天，也可以更短 （log.cleaner.delete.retention.ms）</span><br>log.retention.hours=72<br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 这个参数指新创建一个topic时，默认的Replica数量,Replica过少会影响数据的可用性，太多则会白白浪费存储资源，一般建议在2~3为宜。</span><br>offsets.topic.replication.factor:3<br></code></pre></td></tr></table></figure>\n\n<p><strong>Producer优化（producer.properties）</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">在Producer端用来存放尚未发送出去的Message的缓冲区大小。缓冲区满了之后可以选择阻塞发送或抛出异常，由block.on.buffer.full的配置来决定。</span><br>buffer.memory:33554432 (32m)<br><span class=\"hljs-meta\">#</span><span class=\"bash\">默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力。</span><br>compression.type:none<br></code></pre></td></tr></table></figure>\n\n<p><strong>Consumer优化</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">启动Consumer的个数，适当增加可以提高并发度。</span><br>num.consumer.fetchers:1<br><span class=\"hljs-meta\">#</span><span class=\"bash\">每次Fetch Request至少要拿到多少字节的数据才可以返回。</span><br>fetch.min.bytes:1<br><span class=\"hljs-meta\">#</span><span class=\"bash\">在Fetch Request获取的数据至少达到fetch.min.bytes之前，允许等待的最大时长。对应上面说到的Purgatory中请求的超时时间。</span><br>fetch.wait.max.ms:100<br></code></pre></td></tr></table></figure>\n\n<p><strong>Kafka内存调整（kafka-server-start.sh）</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 默认内存1个G，生产环境尽量不要超过6个G。</span><br>export KAFKA_HEAP_OPTS=&quot;-Xms4g -Xmx4g&quot;<br></code></pre></td></tr></table></figure>","categories":[{"name":"大数据","path":"api/categories/大数据.json"}],"tags":[{"name":"消息队列","path":"api/tags/消息队列.json"},{"name":"Kafka","path":"api/tags/Kafka.json"},{"name":"消费","path":"api/tags/消费.json"},{"name":"MQ","path":"api/tags/MQ.json"}]}