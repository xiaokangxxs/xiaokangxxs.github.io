<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2021最新python从入门到放弃-初识python</title>
    <url>/2021/04/22/2021%E6%9C%80%E6%96%B0python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83-%E5%88%9D%E8%AF%86python/</url>
    <content><![CDATA[<p><lottie-player autoplay loop renderer="svg" speed="1.5" background="transparent" mode="normal" src="https://assets7.lottiefiles.com/packages/lf20_ok9cq9zj.json" style="width: 320px"></lottie-player></p>
<blockquote>
<p>辞旧迎新，元旦快乐！都2021年了，还不赶紧学习python？</p>
</blockquote>
<h2 id="python简介"><a href="#python简介" class="headerlink" title="python简介"></a>python简介</h2><h3 id="1-Python的历史"><a href="#1-Python的历史" class="headerlink" title="1. Python的历史"></a>1. Python的历史</h3><p>1989年圣诞节，著名的“龟叔” Guido van Rossum （吉多·范罗苏姆 <strong>荷兰人</strong>）开始写Python语言的编译器。</p>
<p>1991年2月，第一个Python编译器（同时也是解释器）诞生，它是用C语言实现的（后面），可以调用C语言的库函数。在最早的版本中，Python已经提供了对类、函数、异常处理等构造块的支持，还有对列表、字典等核心数据类型的支持，同时支持以模块为基础来构造应用程序。</p>
<p>1994年1月，Python 1.0正式发布。</p>
<p>2000年10月16日，Python 2.0发布，增加了完整的垃圾回收，提供了对Unicode的支持。与此同时，Python的整个开发过程更加透明，社区对开发进度的影响逐渐扩大，生态圈开始慢慢形成。</p>
<p>2008年12月3日，Python 3.0发布，它并不完全兼容之前的Python代码，不过因为目前还有不少公司在项目和运维中使用Python 2.x版本，所以Python 3.x的很多新特性后来也被移植到Python 2.6/2.7版本中。</p>
<p>目前我们使用的Python 3.7.x的版本是在2018年发布的。</p>
<p><code>版本号解释：Python的版本号分为三段，形如A.B.C。其中A表示大版本号，一般当整体重写，或出现不向后兼容的改变时，增加A；B表示功能更新，出现新功能时增加B；C表示小的改动（例如：修复了某个Bug），只要有修改就增加C。</code></p>
<h3 id="2-Python的优缺点"><a href="#2-Python的优缺点" class="headerlink" title="2. Python的优缺点"></a>2. Python的优缺点</h3><p>Python的优点很多，可以总结为以下几点：</p>
<ul>
<li>简单明了，学习曲线低，比很多编程语言都容易上手。</li>
<li>开放源代码，拥有强大的社区和生态圈，尤其是在数据分析和机器学习领域。</li>
<li>解释型语言，天生具有平台可移植性，代码可以工作于不同的操作系统。</li>
<li>对两种主流的编程范式（面向对象编程和函数式编程）都提供了支持。</li>
<li>代码规范程度高，可读性强，适合有代码洁癖和强迫症的人群。</li>
</ul>
<p>Python的缺点主要集中在以下几点：</p>
<ul>
<li>执行效率稍低，对执行效率要求高的部分可以由其他语言（如：C、C++）编写。</li>
<li>代码无法加密，但是现在很多公司都不销售卖软件而是销售服务，这个问题会被弱化。</li>
<li>在开发时可以选择的框架太多（如Web框架就有100多个），有选择的地方就容易有错误。</li>
</ul>
<h3 id="3-Python的应用领域"><a href="#3-Python的应用领域" class="headerlink" title="3. Python的应用领域"></a>3. Python的应用领域</h3><p>目前Python在Web后端开发、云基础设施建设、DevOps、网络数据采集（爬虫）、运维开发、自动化测试、数据分析、机器学习、人工智能等领域都有着广泛的应用。</p>
<h2 id="搭建编程环境"><a href="#搭建编程环境" class="headerlink" title="搭建编程环境"></a>搭建编程环境</h2><p>视频中使用的Python版本下载链接：<a href="https://www.python.org/downloads/release/python-371/">Python 3.7.1  <strong>Release Date:</strong> Oct. 20, 2018</a></p>
<h3 id="1-Windows环境"><a href="#1-Windows环境" class="headerlink" title="1. Windows环境"></a>1. Windows环境</h3><p>从上方Python官网下载Python 3.7.1的exe安装包，双击进行安装，特别要注意勾上<code>Add Python 3.7 to PATH</code>， 然后点“Install Now”即可完成安装。  </p>
<p><img src="http://file.xiaokang.cool/python-01/image-20210101144401100.png" alt="image-20210101144401100"></p>
<p>安装成功如下如图所示</p>
<p><img src="http://file.xiaokang.cool/python-01/image-20210101143742245.png" alt="image-20210101143742245"></p>
<p>验证：</p>
<p>安装成功后， 打开命令提示符窗口， 敲入<code>python --version</code>，出现下图说明成功</p>
<p><img src="http://file.xiaokang.cool/python-01/image-20210101145002004.png" alt="image-20210101145002004"></p>
<p><code>–web-based installer：在线安装。下载的是一个exe可执行程序，双击后，该程序自动下载安装文件（需要有网络）进行安装。  –executable installer：程序安装。下载的是一个exe可执行程序，双击进行安装。  –embeddable zip file：解压安装。下载的是一个压缩文件，解压后即表示安装完成。</code></p>
<h3 id="2-Linux环境"><a href="#2-Linux环境" class="headerlink" title="2. Linux环境"></a>2. Linux环境</h3><p><a href="https://mp.weixin.qq.com/s/FNXjVGzIJlNDLbS6u0j6Pg">Linux下Python的安装-视频教程</a></p>
<h3 id="3-MacOS环境"><a href="#3-MacOS环境" class="headerlink" title="3. MacOS环境"></a>3. MacOS环境</h3><p>从上方Python官网下载Python 3.7.1的安装程序（网速慢的同学请移步国内镜像），双击运行并安装即可或者直接通过命令brew install python3安装即可。  </p>
<h2 id="第一个python程序"><a href="#第一个python程序" class="headerlink" title="第一个python程序"></a>第一个python程序</h2><h3 id="1-在python自带的IDLE交互环境中执行代码"><a href="#1-在python自带的IDLE交互环境中执行代码" class="headerlink" title="1. 在python自带的IDLE交互环境中执行代码"></a>1. 在python自带的IDLE交互环境中执行代码</h3><p>首先打开命令提示符窗口， 敲入<code>python</code>，再输入以下语句</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第一行python代码</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello xiaokang.WeChat:xiaokangxxs&quot;</span>)<br></code></pre></td></tr></table></figure>

<p><img src="http://file.xiaokang.cool/python-01/image-20210101150005489.png" alt="image-20210101150005489"></p>
<h3 id="2-使用python命令运行程序"><a href="#2-使用python命令运行程序" class="headerlink" title="2. 使用python命令运行程序"></a>2. 使用python命令运行程序</h3><p>首先在当前目录创建一个名为<code>hello.py</code>的文件，将上面的语句输入进去保存，然后在当前目录打开命令提示符窗口，输入<code>python hello.py</code></p>
<p><img src="http://file.xiaokang.cool/python-01/image-20210101150349268.png" alt="image-20210101150349268"></p>
<h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p>注释是编程语言中一个重要组成部分，用于在源代码中解释代码的作用从而增强程序的可读性和可维护性，当然也可以将源代码中不需要参与运行的代码段通过注释来去掉，这一点在调试程序的时候经常用到。注释在随源代码进入预处理器或编译时会被移除，不会在目标代码中保留也不会影响程序的执行结果。</p>
<ol>
<li>单行注释：以#开头的部分</li>
<li>多行注释：三个双/单引号开头，三个双/单引号结尾</li>
</ol>
<p>改造上面的<code>hello.py</code>文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Date : 2021/1/1</span><br><span class="hljs-string">Author : 小康</span><br><span class="hljs-string">description ：</span><br><span class="hljs-string">Site : www.xiaokang.cool</span><br><span class="hljs-string">微信公众号: 小康新鲜事儿</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">Date : 2021/1/1</span><br><span class="hljs-string">Author : 小康</span><br><span class="hljs-string">description ：</span><br><span class="hljs-string">Site : www.xiaokang.cool</span><br><span class="hljs-string">微信公众号: 小康新鲜事儿</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-comment"># 第一行python代码</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello xiaokang.WeChat:xiaokangxxs&quot;</span>) <span class="hljs-comment"># 这是单行注释</span><br></code></pre></td></tr></table></figure>

<p>改造完成后使用python命令运行程序，结果和上面一样。</p>
<h2 id="python之禅"><a href="#python之禅" class="headerlink" title="python之禅"></a>python之禅</h2><p>在Python自带的IDLE交互式环境中输入下面的代码就可以看到python的设计理念（禅）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> this<br></code></pre></td></tr></table></figure>

<p><img src="http://file.xiaokang.cool/python-01/image-20210101151141665.png" alt="image-20210101151141665"></p>
<figure class="highlight html"><table><tr><td class="code"><pre><code class="hljs html">The Zen of Python, by Tim Peters<br>Python之禅 ，by Tim Peters<br><br>Beautiful is better than ugly.<br>优美好于丑陋（Python 以优美的代码为其风格，不要写丑陋的代码）<br><br>Explicit is better than implicit.<br>明了好于隐晦（Python的每一行代码、每一个变量、每一函数的意义应该是明确的，让人看了一目了然）<br><br>Simple is better than complex.<br>简洁好于复杂（Python的每一行代码应当是简洁的，一行代码只为一个子功能）<br><br>Complex is better than complicated.<br>复杂好于凌乱（如果无法避免引入复杂的代码，也要尽量保证代码之间明确简洁的关系）<br><br>Flat is better than nested.<br>扁平好于嵌套（Python的代码结构应该是扁平的，不应该有太多嵌套的结构）<br><br>Sparse is better than dense.<br>稀疏好于密集（Python代码之间应该是有间隔的，每个功能块、每个函数、每个参数、每个类之间应当有适当的间距）<br><br>Readability counts.<br>代码可读性很重要（Python代码具有很好的可读性，注释、变量名、函数名、类名、模块名、代码块功能等的作用和意义都是一目了然的）<br><br>Special cases aren&#x27;t special enough to break the rules.<br>Although practicality beats purity.<br>虽然实用性很重要，但任何特殊情况都不足以特殊到违背上述规则（不要为了处理某一个特殊情况，而破坏了上述任何一个规则）<br><br>Errors should never pass silently.<br>Unless explicitly silenced.<br>不要忽视任何错误，除非有意为之（任何时候都要对异常和错误进行处理，不要写 except:pass 风格的代码）<br><br>In the face of ambiguity, refuse the temptation to guess.<br>There should be one-- and preferably only one --obvious way to do it.<br>面对模棱两可的情况，拒绝享受让别人去猜测的乐趣<br>提供有且仅有的一种最明显解决方法（解决一个问题的方法可能会有很多种，但在Python中，只选择最明显的那一个）<br><br>Although that way may not be obvious at first unless you&#x27;re Dutch.<br>虽然起初这很难做到，除非你是荷兰人（荷兰人暗指 Python之父：Guido van Rossum（龟叔） ）<br><br>Now is better than never.<br>Although never is often better than *right* now.<br>动手行动好于什么都不做，但不加思考就行动还不如不做<br><br>If the implementation is hard to explain, it&#x27;s a bad idea.<br>如果某问题一个代码实现很难解释，那说明这个实现不是很好<br><br>If the implementation is easy to explain, it may be a good idea.<br>如果某问题一个代码实现很简单，那这个实现可能走在正确的路上<br><br>Namespaces are one honking great idea -- let&#x27;s do more of those!<br>命名空间是一个很棒的注意，应当多加利用<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>xiaokang</tag>
        <tag>教程</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS-JavaAPI</title>
    <url>/2021/04/28/HDFS-JavaAPI/</url>
    <content><![CDATA[<h2 id="一、前置准备"><a href="#一、前置准备" class="headerlink" title="一、前置准备"></a>一、前置准备</h2><h3 id="1-Windows下配置开发环境"><a href="#1-Windows下配置开发环境" class="headerlink" title="1. Windows下配置开发环境"></a>1. Windows下配置开发环境</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Hadoop/hadoop_home.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Hadoop/hadoopenv.png"/> </div>

<h3 id="2-基于IDEA创建-maven-jar工程"><a href="#2-基于IDEA创建-maven-jar工程" class="headerlink" title="2. 基于IDEA创建 maven jar工程"></a>2. 基于IDEA创建 maven jar工程</h3><p>想要使用 HDFS API，需要导入依赖<code>hadoop-common</code>、<code>hadoop-client</code>、 <code>hadoop-hdfs</code>、<code>hadoop-client</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">project</span> <span class="hljs-attr">xmlns</span>=<span class="hljs-string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span><br><span class="hljs-tag">         <span class="hljs-attr">xmlns:xsi</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span><br><span class="hljs-tag">         <span class="hljs-attr">xsi:schemaLocation</span>=<span class="hljs-string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">modelVersion</span>&gt;</span>4.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">modelVersion</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>cool.xiaokang<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hdfs-java-api<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- jdk版本 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">jdk.version</span>&gt;</span>8<span class="hljs-tag">&lt;/<span class="hljs-name">jdk.version</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- 设置字符编码 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">project.reporting.outputEncoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">project.reporting.outputEncoding</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">hadoop.version</span>&gt;</span>2.7.7<span class="hljs-tag">&lt;/<span class="hljs-name">hadoop.version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.11.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-hdfs<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>4.12<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>test<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.8.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-comment">&lt;!-- 设置编译字符编码 --&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">encoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">encoding</span>&gt;</span><br>                    <span class="hljs-comment">&lt;!-- 设置编译jdk版本 --&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>$&#123;jdk.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>$&#123;jdk.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">project</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p><strong>log4j.properties</strong></p>
<figure class="highlight properties"><table><tr><td class="code"><pre><code class="hljs properties"><span class="hljs-meta">log4j.rootLogger</span>=<span class="hljs-string">INFO,console,file</span><br><span class="hljs-comment">#配置输出到控制台</span><br><span class="hljs-meta">log4j.appender.console</span>=<span class="hljs-string">org.apache.log4j.ConsoleAppender</span><br><span class="hljs-meta">log4j.appender.console.layout</span>=<span class="hljs-string">org.apache.log4j.PatternLayout</span><br><span class="hljs-meta">log4j.appender.console.Encoding</span>=<span class="hljs-string">UTF-8</span><br><span class="hljs-meta">log4j.appender.console.layout.ConversionPattern</span>=<span class="hljs-string">%d&#123;yyyy-MM-dd HH\:mm\:ss&#125; -%-4r [%t] %-5p  %x - %m%n</span><br><span class="hljs-comment">#配置输入日志到日志文件</span><br><span class="hljs-meta">log4j.appender.file</span>=<span class="hljs-string">org.apache.log4j.FileAppender</span><br><span class="hljs-meta">log4j.appender.file.File</span>=<span class="hljs-string">target/mylog.log</span><br><span class="hljs-meta">log4j.appender.file.layout</span>=<span class="hljs-string">org.apache.log4j.PatternLayout</span><br><span class="hljs-meta">log4j.appender.file.layout.ConversionPattern</span>=<span class="hljs-string">%d %p [%c] - %m%n</span><br></code></pre></td></tr></table></figure>

<h2 id="二、API的使用"><a href="#二、API的使用" class="headerlink" title="二、API的使用"></a>二、API的使用</h2><h3 id="2-1-FileSystem"><a href="#2-1-FileSystem" class="headerlink" title="2.1 FileSystem"></a>2.1 FileSystem</h3><p>FileSystem 是所有 HDFS 操作的主入口。由于之后的每个小功能的测试都需要用到它，这里使用写了一个工具类HDFSUtils</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> cool.xiaokang.utils;<br><br><span class="hljs-keyword">import</span> org.apache.hadoop.conf.Configuration;<br><span class="hljs-keyword">import</span> org.apache.hadoop.fs.FileSystem;<br><br><span class="hljs-keyword">import</span> java.io.IOException;<br><span class="hljs-keyword">import</span> java.net.URI;<br><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * HDFS工具类</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span> xiaokang</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HDFSUtils</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String HDFS_PATH = <span class="hljs-string">&quot;hdfs://192.168.239.161:9000&quot;</span>;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String HDFS_USER = <span class="hljs-string">&quot;xiaokang&quot;</span>;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 获取FileSystem对象</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> FileSystem <span class="hljs-title">getFileSystem</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            Configuration conf = <span class="hljs-keyword">new</span> Configuration();<br>            <span class="hljs-comment">//conf.set(&quot;dfs.replication&quot;, &quot;3&quot;);</span><br>       		<span class="hljs-comment">//conf.addResource(&quot;hdfs-site.xml&quot;);</span><br>            FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(HDFS_PATH), conf, HDFS_USER);<br>            <span class="hljs-keyword">return</span> fileSystem;<br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！！---&quot;</span> + e.getMessage());<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 关闭FileSystem对象</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> fileSystem</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">closeFileSystem</span><span class="hljs-params">(FileSystem fileSystem)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (fileSystem != <span class="hljs-keyword">null</span>) &#123;<br>            <span class="hljs-keyword">try</span> &#123;<br>                fileSystem.close();<br>            &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>                e.printStackTrace();<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-2-实现-ls列表查看"><a href="#2-2-实现-ls列表查看" class="headerlink" title="2.2 实现-ls列表查看"></a>2.2 实现<code>-ls</code>列表查看</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//HDFS Shell操作：hdfs dfs -ls /input</span><br><span class="hljs-comment">//查看指定目录下所有文件的信息</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testFileStatus</span><span class="hljs-params">(String path)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            FileStatus[] fileStatuses = fs.listStatus(<span class="hljs-keyword">new</span> Path(path));<br>            <span class="hljs-keyword">for</span>(FileStatus file:fileStatuses)&#123;<br>                <span class="hljs-comment">//fileStatus的toString方法被重写过，直接打印可以看到所有信息</span><br>                <span class="hljs-comment">//System.out.println(file.toString());</span><br>                <span class="hljs-comment">//System.out.println(&quot;路径:&quot;+file.getPath());</span><br>                <span class="hljs-comment">//System.out.println(&quot;拥有者:&quot;+file.getOwner());</span><br>                <span class="hljs-comment">//System.out.println(&quot;权限:&quot;+file.getPermission().toString());</span><br>                <span class="hljs-comment">//System.out.println();</span><br>                <span class="hljs-keyword">if</span> (file.isFile())&#123;<br>                    System.out.println(file.getPath().getName()+<span class="hljs-string">&quot;是文件&quot;</span>);<br>                &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (file.isDirectory())&#123;<br>                    System.out.println(file.getPath().getName()+<span class="hljs-string">&quot;是目录&quot;</span>);<br>                &#125;<br>            &#125;<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;error&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p><code>FileStatus</code> 中包含了文件的基本信息，比如文件路径，是否是文件夹，修改时间，访问时间，所有者，所属组，文件权限，是否是符号链接等，输出内容示例如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">FileStatus&#123;</span><br><span class="hljs-attr">path</span>=<span class="hljs-string">hdfs://192.168.239.161:9000/xiaokang/test; </span><br><span class="hljs-attr">isDirectory</span>=<span class="hljs-string">true; </span><br><span class="hljs-attr">modification_time</span>=<span class="hljs-string">1556680796191; </span><br><span class="hljs-attr">access_time</span>=<span class="hljs-string">0; </span><br><span class="hljs-attr">owner</span>=<span class="hljs-string">xiaokang; </span><br><span class="hljs-attr">group</span>=<span class="hljs-string">supergroup; </span><br><span class="hljs-attr">permission</span>=<span class="hljs-string">rwxr-xr-x; </span><br><span class="hljs-attr">isSymlink</span>=<span class="hljs-string">false</span><br><span class="hljs-attr">&#125;</span><br></code></pre></td></tr></table></figure>

<h3 id="2-3-递归查看目录下所有文件的详细信息"><a href="#2-3-递归查看目录下所有文件的详细信息" class="headerlink" title="2.3 递归查看目录下所有文件的详细信息"></a>2.3 递归查看目录下所有文件的详细信息</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//递归查看目录下所有文件的详细信息</span><br>    <span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testFileDetails</span><span class="hljs-params">(String path)</span></span>&#123;<br>        FileSystem fs = <span class="hljs-keyword">null</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            fs=HDFSUtils.getFileSystem();<br>            <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>                RemoteIterator&lt;LocatedFileStatus&gt; fileList = fs.listFiles(<span class="hljs-keyword">new</span> Path(path),<span class="hljs-keyword">true</span>);<br>                <span class="hljs-keyword">while</span> (fileList.hasNext())&#123;<br>                    LocatedFileStatus file = fileList.next();<br>                    <span class="hljs-comment">//每个文件的详细信息</span><br>                    System.out.println(file.getOwner()+<span class="hljs-string">&quot;--&quot;</span>+file.getPermission());<br>                    <span class="hljs-comment">//文件的块信息</span><br>                    BlockLocation[] blocks = file.getBlockLocations();<br>                    <span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>;<br>                    <span class="hljs-keyword">for</span>(BlockLocation block:blocks)&#123;<br>                        String[] hosts = block.getHosts();<br>                        System.out.println(<span class="hljs-string">&quot;块数：&quot;</span>+block.getLength());<br>                        System.out.println(<span class="hljs-string">&quot;第【&quot;</span>+i+<span class="hljs-string">&quot;】块：&quot;</span>+ Arrays.toString(hosts));<br>                        i++;<br>                    &#125;<br>                    System.out.println(<span class="hljs-string">&quot;===================&quot;</span>);<br>                &#125;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>            &#125;<br>        &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>            System.out.println(<span class="hljs-string">&quot;创建失败&quot;</span>+e.getMessage());<br>        &#125;<span class="hljs-keyword">finally</span> &#123;<br>            HDFSUtils.closeFileSystem(fs);<br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-4-创建目录"><a href="#2-4-创建目录" class="headerlink" title="2.4 创建目录"></a>2.4 创建目录</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//创建目录,支持递归创建</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testMkdirs</span><span class="hljs-params">(String path)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            fs.mkdirs(<span class="hljs-keyword">new</span> Path(path));<br>            System.out.println(<span class="hljs-string">&quot;创建成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;创建失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-5-文件复制"><a href="#2-5-文件复制" class="headerlink" title="2.5 文件复制"></a>2.5 文件复制</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//集群内文件复制</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testCopy</span><span class="hljs-params">(String src,String dest)</span></span>&#123;<br>    FileSystem fileSystem=<span class="hljs-keyword">null</span>;<br>    FSDataInputStream in=<span class="hljs-keyword">null</span>;<br>    FSDataOutputStream out=<span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span>&#123;<br>        fileSystem = HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fileSystem!=<span class="hljs-keyword">null</span>)&#123;<br>            in=fileSystem.open(<span class="hljs-keyword">new</span> Path(src));<br>            out=fileSystem.create(<span class="hljs-keyword">new</span> Path(dest));<br>            IOUtils.copyBytes(in,out,<span class="hljs-number">4096</span>);<br>            System.out.println(<span class="hljs-string">&quot;复制完成&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;error&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            out.close();<br>            in.close();<br>            HDFSUtils.closeFileSystem(fileSystem);<br>        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-6-文件重命名"><a href="#2-6-文件重命名" class="headerlink" title="2.6 文件重命名"></a>2.6 文件重命名</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//集群文件重命名</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testRename</span><span class="hljs-params">(String oldName,String newName)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            fs.rename(<span class="hljs-keyword">new</span> Path(oldName),<span class="hljs-keyword">new</span> Path(newName));<br>            System.out.println(<span class="hljs-string">&quot;重命名成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;重命名失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-7-删除目录或文件"><a href="#2-7-删除目录或文件" class="headerlink" title="2.7 删除目录或文件"></a>2.7 删除目录或文件</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">	<span class="hljs-comment">/*</span><br><span class="hljs-comment">     *  delete方法中第二个参数代表是否递归删除</span><br><span class="hljs-comment">     *    +  如果 path 是一个目录且递归删除为 true, 则删除该目录及其中所有文件;</span><br><span class="hljs-comment">     *    +  如果 path 是一个目录但递归删除为 false,则会则抛出异常。</span><br><span class="hljs-comment">     */</span><br><span class="hljs-comment">//删除集群中目录或文件</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testDelete</span><span class="hljs-params">(String path)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            fs.delete(<span class="hljs-keyword">new</span> Path(path),<span class="hljs-keyword">true</span>);<br>            System.out.println(<span class="hljs-string">&quot;删除成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;删除失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-8-上传文件到HDFS"><a href="#2-8-上传文件到HDFS" class="headerlink" title="2.8 上传文件到HDFS"></a>2.8 上传文件到HDFS</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//本地文件上传至HDFS</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testPut</span><span class="hljs-params">(String localSrc,String hdfsDest)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            fs.copyFromLocalFile(<span class="hljs-keyword">new</span> Path(localSrc),<span class="hljs-keyword">new</span> Path(hdfsDest));<br>            System.out.println(<span class="hljs-string">&quot;上传成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;上传失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-9-上传文件到HDFS-IO流方式"><a href="#2-9-上传文件到HDFS-IO流方式" class="headerlink" title="2.9 上传文件到HDFS-IO流方式"></a>2.9 上传文件到HDFS-IO流方式</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//本地文件上传至HDFS-IO流方式</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testPutWithIO</span><span class="hljs-params">(String localSrc,String hdfsDest)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    FileInputStream in=<span class="hljs-keyword">null</span>;<br>    FSDataOutputStream out=<span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            in=<span class="hljs-keyword">new</span> FileInputStream(<span class="hljs-keyword">new</span> File(localSrc));<br>            out=fs.create(<span class="hljs-keyword">new</span> Path(hdfsDest));<br>            IOUtils.copyBytes(in,out,<span class="hljs-number">4096</span>);<br>            System.out.println(<span class="hljs-string">&quot;IO流-上传成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;IO流-上传失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            out.close();<br>            in.close();<br>            HDFSUtils.closeFileSystem(fs);<br>        &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-10-从HDFS上下载文件"><a href="#2-10-从HDFS上下载文件" class="headerlink" title="2.10 从HDFS上下载文件"></a>2.10 从HDFS上下载文件</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//从HDFS下载文件到本地</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testGet</span><span class="hljs-params">(String hdfsSrc,String localDest)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            fs.copyToLocalFile(<span class="hljs-keyword">new</span> Path(hdfsSrc),<span class="hljs-keyword">new</span> Path(localDest));<br>            System.out.println(<span class="hljs-string">&quot;下载成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;下载失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br><br>	<span class="hljs-comment">/*</span><br><span class="hljs-comment">     * 第一个参数控制下载完成后是否删除源文件,默认是 true,即删除;</span><br><span class="hljs-comment">     * 最后一个参数表示是否将 RawLocalFileSystem 用作本地文件系统;</span><br><span class="hljs-comment">     * RawLocalFileSystem 默认为 false,通常情况下可以不设置,</span><br><span class="hljs-comment">     * 但如果你在执行时候抛出 NullPointerException 异常,则代表你的文件系统与程序可能存在不兼容的情况 (window 下常见),</span><br><span class="hljs-comment">     * 此时可以将 RawLocalFileSystem 设置为 true</span><br><span class="hljs-comment">     */</span><br>    fs.copyToLocalFile(<span class="hljs-keyword">false</span>, src, dst, <span class="hljs-keyword">true</span>);<br></code></pre></td></tr></table></figure>

<h3 id="2-11-从HDFS上下载文件-IO流方式"><a href="#2-11-从HDFS上下载文件-IO流方式" class="headerlink" title="2.11 从HDFS上下载文件-IO流方式"></a>2.11 从HDFS上下载文件-IO流方式</h3><figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//从HDFS下载文件到本地-IO流方式</span><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testGetWithIO</span><span class="hljs-params">(String hdfsSrc,String localDest)</span></span>&#123;<br>    FileSystem fs = <span class="hljs-keyword">null</span>;<br>    FSDataInputStream in=<span class="hljs-keyword">null</span>;<br>    FileOutputStream out=<span class="hljs-keyword">null</span>;<br>    <span class="hljs-keyword">try</span> &#123;<br>        fs=HDFSUtils.getFileSystem();<br>        <span class="hljs-keyword">if</span> (fs!=<span class="hljs-keyword">null</span>)&#123;<br>            in=fs.open(<span class="hljs-keyword">new</span> Path(hdfsSrc));<br>            out=<span class="hljs-keyword">new</span> FileOutputStream(<span class="hljs-keyword">new</span> File(localDest));<br>            IOUtils.copyBytes(in,out,<span class="hljs-number">4096</span>);<br>            System.out.println(<span class="hljs-string">&quot;IO流-下载成功！！！&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;获取FileSystem失败！！&quot;</span>);<br>        &#125;<br>    &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>        System.out.println(<span class="hljs-string">&quot;IO流-下载失败&quot;</span>+e.getMessage());<br>    &#125;<span class="hljs-keyword">finally</span> &#123;<br>        HDFSUtils.closeFileSystem(fs);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<br/>

<p><strong>以上所有测试用例下载地址</strong>：<a href="https://github.com/heibaiying/BigData-Notes/tree/master/code/Hadoop/hdfs-java-api">HDFS-JavaAPI</a></p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>java</tag>
        <tag>API</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala环境搭建</title>
    <url>/2021/04/28/Scala%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<blockquote>
<p><strong>系统环境</strong>：CentOS 7.x、Windows10</p>
<p><strong>JDK 版本</strong>：1.8+</p>
</blockquote>
<h2 id="一、Window-下搭建开发环境"><a href="#一、Window-下搭建开发环境" class="headerlink" title="一、Window 下搭建开发环境"></a>一、Window 下搭建开发环境</h2><h3 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><p>确保 JDK8 安装成功, 并成功配置环境变量:<code>JAVA_HOME</code>, <code>Path</code></p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/Windows-env.png"/> </div>

<h3 id="2-下载"><a href="#2-下载" class="headerlink" title="2. 下载"></a>2. 下载</h3><p>下载对应的Scala安装文件，我这里下载的是<code>scala-2.11.12.zip </code>，下载地址： <a href="https://www.scala-lang.org/download/2.11.12.html">https://www.scala-lang.org/download/2.11.12.html</a></p>
<h3 id="3-解压"><a href="#3-解压" class="headerlink" title="3. 解压"></a>3. 解压</h3><p>解压<code>scala-2.11.12.zip</code>，我这里解压到<code>E:\software</code></p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_dir.png"/> </div>

<h3 id="4-配置环境变量"><a href="#4-配置环境变量" class="headerlink" title="4. 配置环境变量"></a>4. 配置环境变量</h3><p>配置 Scala 环境变量:<code>SCALA_HOME</code>和<code>Path</code></p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_home.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_path.png"/> </div>

<h3 id="5-验证安装是否成功"><a href="#5-验证安装是否成功" class="headerlink" title="5. 验证安装是否成功"></a>5. 验证安装是否成功</h3><p>按下键盘的<code>Win+R</code>后，输入<code>cmd</code>回车，输入Scala，如果能进入 Scala 交互环境，则代表安装成功：</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/win_scala.png"/> </div>
## 二、Linux 下搭建开发环境

<h3 id="1-环境准备-1"><a href="#1-环境准备-1" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><p>确保 JDK8 安装成功</p>
<h3 id="2-下载解压"><a href="#2-下载解压" class="headerlink" title="2. 下载解压"></a>2. 下载解压</h3><p>下载对应的Scala安装文件，我这里下载的是<code>scala-2.11.12.tgz </code>，下载地址： <a href="https://www.scala-lang.org/download/2.11.12.html">https://www.scala-lang.org/download/2.11.12.html</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ tar -zxvf scala-2.11.12.tgz -C /opt/moudle/<br></code></pre></td></tr></table></figure>

<h3 id="3-配置环境变量"><a href="#3-配置环境变量" class="headerlink" title="3. 配置环境变量"></a>3. 配置环境变量</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ sudo vim /etc/profile<br></code></pre></td></tr></table></figure>

<p>在原有的基础上添加如下环境变量：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">export SCALA_HOME=/opt/moudle/scala-2.11.12<br>export PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$&#123;ZOOKEEPER_HOME&#125;/bin:$&#123;HIVE_HOME&#125;/bin:$&#123;ZEPPELIN_HOME&#125;/bin:$&#123;HBASE_HOME&#125;/bin:$&#123;SQOOP_HOME&#125;/bin:$&#123;FLUME_HOME&#125;/bin:$&#123;PYTHON_HOME&#125;/bin:$&#123;SCALA_HOME&#125;/bin:$PATH<br></code></pre></td></tr></table></figure>

<p>使得配置的环境变量立即生效：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ source /etc/profile<br></code></pre></td></tr></table></figure>

<h3 id="4-验证安装是否成功"><a href="#4-验证安装是否成功" class="headerlink" title="4. 验证安装是否成功"></a>4. 验证安装是否成功</h3><p>输入<code>scala</code>，如果能进入 Scala 交互环境，则代表安装成功：</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/linux_scala.png"/> </div>

<h2 id="三、Scala-的-Hello-world-案例"><a href="#三、Scala-的-Hello-world-案例" class="headerlink" title="三、Scala 的 Hello world 案例"></a>三、Scala 的 Hello world 案例</h2><p><code>需要提前给IDEA安装好Scala插件</code>，插件下载地址：<a href="https://plugins.jetbrains.com/plugin/1347-scala/versions">https://plugins.jetbrains.com/plugin/1347-scala/versions</a></p>
<h3 id="1-创建一个-Maven-工程"><a href="#1-创建一个-Maven-工程" class="headerlink" title="1. 创建一个 Maven 工程"></a>1. 创建一个 Maven 工程</h3><h3 id="2-引入-Scala-框架"><a href="#2-引入-Scala-框架" class="headerlink" title="2. 引入 Scala 框架"></a>2. 引入 Scala 框架</h3><p>默认下，maven 不支持 scala 的开发，需要引入 scala 框架。 </p>
<p>点击项目-&gt; 右键 -&gt; add framework support… ，在下图选择scala </p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/idea_scala_sdk.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_sdk.png"/> </div>

<h3 id="3-创建项目的源文件目录"><a href="#3-创建项目的源文件目录" class="headerlink" title="3. 创建项目的源文件目录"></a>3. 创建项目的源文件目录</h3><p>在 <code>main</code> 下创建一个文件夹作为 scala 源文件的根目录, 比如目录名: <code>scala</code>, 然后标记为源文件根目录 </p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_source.png"/> </div>

<h3 id="4-创建-Scala-的类"><a href="#4-创建-Scala-的类" class="headerlink" title="4. 创建 Scala 的类"></a>4. 创建 Scala 的类</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_class.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_object.png"/> </div>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@author</span>: 小康</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@date</span>: 2020/4/9 17:25</span><br><span class="hljs-comment"> *        微信公众号：小康新鲜事儿</span><br><span class="hljs-comment"> *        小康个人文档：http://www.xiaokang.cool/</span><br><span class="hljs-comment"> */</span><br>object HelloWorld &#123;<br>  <span class="hljs-function">def <span class="hljs-title">main</span><span class="hljs-params">(args: Array[String])</span>: Unit </span>= &#123;<br>    println(<span class="hljs-string">&quot;hello,world-Scala&quot;</span>)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="5-运行"><a href="#5-运行" class="headerlink" title="5. 运行"></a>5. 运行</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Scala/scala_hello.png"/> </div>
demo代码下载地址：[scala_demo](https://github.com/xiaokangxxs/notebook/tree/master/docs/code/scala_demo)]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Scala</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>18个开箱即用的Shell脚本</title>
    <url>/2021/04/28/18%E4%B8%AA%E5%BC%80%E7%AE%B1%E5%8D%B3%E7%94%A8%E7%9A%84Shell%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<p>1、检测两台服务器指定目录下的文件一致性</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#####################################</span></span><br>检测两台服务器指定目录下的文件一致性<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">####################################</span></span><br><span class="hljs-meta">#</span><span class="bash">通过对比两台服务器上文件的md5值，达到检测一致性的目的</span><br>dir=/data/web<br>b_ip=192.168.88.10<br><span class="hljs-meta">#</span><span class="bash">将指定目录下的文件全部遍历出来并作为md5sum命令的参数，进而得到所有文件的md5值，并写入到指定文件中</span><br>find $dir -type f|xargs md5sum &gt; /tmp/md5_a.txt<br>ssh $b_ip &quot;find $dir -type f|xargs md5sum &gt; /tmp/md5_b.txt&quot;<br>scp $b_ip:/tmp/md5_b.txt /tmp<br><span class="hljs-meta">#</span><span class="bash">将文件名作为遍历对象进行一一比对</span><br>for f in `awk &#x27;&#123;print 2&#125; /tmp/md5_a.txt&#x27;`do<br><span class="hljs-meta">#</span><span class="bash">以a机器为标准，当b机器不存在遍历对象中的文件时直接输出不存在的结果</span><br>if grep -qw &quot;$f&quot; /tmp/md5_b.txt<br>then<br>md5_a=`grep -w &quot;$f&quot; /tmp/md5_a.txt|awk &#x27;&#123;print 1&#125;&#x27;`<br>md5_b=`grep -w &quot;$f&quot; /tmp/md5_b.txt|awk &#x27;&#123;print 1&#125;&#x27;`<br><span class="hljs-meta">#</span><span class="bash">当文件存在时，如果md5值不一致则输出文件改变的结果</span><br>if [ $md5_a != $md5_b ]then<br>echo &quot;$f changed.&quot;<br>fi<br>else<br>echo &quot;$f deleted.&quot;<br>fi<br>done<br></code></pre></td></tr></table></figure>

<p>2、定时清空文件内容，定时记录文件大小</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">################################################################</span></span><br>每小时执行一次脚本（任务计划），当时间为0点或12点时，将目标目录下的所有文件内#容清空，但不删除文件，其他时间则只统计各个文件的大小，一个文件一行，输出到以时#间和日期命名的文件中，需要考虑目标目录下二级、三级等子目录的文件<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">###############################################################</span></span><br>logfile=/tmp/`date +%H-%F`.log<br>n=`date +%H`<br>if [ $n -eq 00 ] || [ $n -eq 12 ]<br>then<br><span class="hljs-meta">#</span><span class="bash">通过<span class="hljs-keyword">for</span>循环，以find命令作为遍历条件，将目标目录下的所有文件进行遍历并做相应操作</span><br>for i in `find /data/log/ -type f`<br>do<br>true &gt; $i<br>done<br>else<br>for i in `find /data/log/ -type f`<br>do<br>du -sh $i &gt;&gt; $logfile<br>done<br>fi<br></code></pre></td></tr></table></figure>

<p>3、检测网卡流量，并按规定格式记录在日志中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">######################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">检测网卡流量，并按规定格式记录在日志中<span class="hljs-comment">#规定一分钟记录一次</span></span><br><span class="hljs-meta">#</span><span class="bash">日志格式如下所示:</span><br><span class="hljs-meta">#</span><span class="bash">2019-08-12 20:40</span><br><span class="hljs-meta">#</span><span class="bash">ens33 input: 1234bps</span><br><span class="hljs-meta">#</span><span class="bash">ens33 output: 1235bps</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#####################################################3</span></span><br>while :<br>do<br><span class="hljs-meta">#</span><span class="bash">设置语言为英文，保障输出结果是英文，否则会出现bug</span><br>LANG=en<br>logfile=/tmp/`date +%d`.log<br><span class="hljs-meta">#</span><span class="bash">将下面执行的命令结果输出重定向到logfile日志中</span><br>exec &gt;&gt; $logfile<br>date +&quot;%F %H:%M&quot;<br><span class="hljs-meta">#</span><span class="bash">sar命令统计的流量单位为kb/s，日志格式为bps，因此要*1000*8</span><br>sar -n DEV 1 59|grep Average|grep ens33|awk &#x27;&#123;print $2,&quot;\t&quot;,&quot;input:&quot;,&quot;\t&quot;,$5*1000*8,&quot;bps&quot;,&quot;\n&quot;,$2,&quot;\t&quot;,&quot;output:&quot;,&quot;\t&quot;,$6*1000*8,&quot;bps&quot;&#125;&#x27;<br>echo &quot;####################&quot;<br><span class="hljs-meta">#</span><span class="bash">因为执行sar命令需要59秒，因此不需要sleep</span><br>done<br></code></pre></td></tr></table></figure>

<p>4、计算文档每行出现的数字个数，并计算整个文档的数字总数</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">########################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">计算文档每行出现的数字个数，并计算整个文档的数字总数</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#######################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">使用awk只输出文档行数（截取第一段）</span><br>n=`wc -l a.txt|awk &#x27;&#123;print $1&#125;&#x27;`<br>sum=0<br><span class="hljs-meta">#</span><span class="bash">文档中每一行可能存在空格，因此不能直接用文档内容进行遍历</span><br>for i in `seq 1 $n`do<br><span class="hljs-meta">#</span><span class="bash">输出的行用变量表示时，需要用双引号</span><br>line=`sed -n &quot;$i&quot;p a.txt`#wc -L选项，统计最长行的长度<br>n_n=`echo $line|sed s&#x27;/[^0-9]//&#x27;g|wc -L`<br>echo $n_nsum=$[$sum+$n_n]<br>done<br>echo &quot;sum:$sum&quot;<br></code></pre></td></tr></table></figure>

<p>杀死所有脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">###############################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">有一些脚本加入到了cron之中，存在脚本尚未运行完毕又有新任务需要执行的情况，</span><br><span class="hljs-meta">#</span><span class="bash">导致系统负载升高，因此可通过编写脚本，筛选出影响负载的进程一次性全部杀死。</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">###############################################################</span></span><br>ps aux|grep 指定进程名|grep -v grep|awk &#x27;&#123;print $2&#125;&#x27;|xargs kill -9<br></code></pre></td></tr></table></figure>

<p>5、从 FTP 服务器下载文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>if [ $# -ne 1 ]; then<br>    echo &quot;Usage: $0 filename&quot;<br>fi<br>dir=$(dirname $1)<br>file=$(basename $1)<br>ftp -n -v &lt;&lt; EOF   # -n 自动登录<br>open 192.168.1.10  # ftp服务器<br>user admin password<br>binary   # 设置ftp传输模式为二进制，避免MD5值不同或.tar.gz压缩包格式错误<br>cd $dir<br>get &quot;$file&quot;<br>EOF<br></code></pre></td></tr></table></figure>

<p>6、连续输入5个100以内的数字，统计和、最小和最大</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>COUNT=1<br>SUM=0<br>MIN=0<br>MAX=100<br>while [ $COUNT -le 5 ]; do<br>    read -p &quot;请输入1-10个整数：&quot; INT    <br>    if [[ ! $INT =~ ^[0-9]+$ ]]; then<br>        echo &quot;输入必须是整数！&quot;<br>        exit 1<br>    elif [[ $INT -gt 100 ]]; then<br>        echo &quot;输入必须是100以内！&quot;<br>        exit 1<br>    fi<br>    SUM=$(($SUM+$INT))<br>    [ $MIN -lt $INT ] &amp;&amp; MIN=$INT<br>    [ $MAX -gt $INT ] &amp;&amp; MAX=$INT<br>    let COUNT++<br>    done<br>echo &quot;SUM: $SUM&quot;<br>echo &quot;MIN: $MIN&quot;<br>echo &quot;MAX: $MAX<br></code></pre></td></tr></table></figure>

<p>用户猜数字</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash  <span class="hljs-comment"># 脚本生成一个 100 以内的随机数,提示用户猜数字,根据用户的输入,提示用户猜对了,</span></span><br><span class="hljs-meta">#</span><span class="bash"> 猜小了或猜大了,直至用户猜对脚本结束。</span><br><span class="hljs-meta">#</span><span class="bash"> RANDOM 为系统自带的系统变量,值为 0‐32767的随机数</span><br><span class="hljs-meta">#</span><span class="bash"> 使用取余算法将随机数变为 1‐100 的随机数num=$[RANDOM%100+1]<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$num</span>&quot;</span></span> <br><span class="hljs-meta">#</span><span class="bash"> 使用 <span class="hljs-built_in">read</span> 提示用户猜数字</span><br><span class="hljs-meta">#</span><span class="bash"> 使用 <span class="hljs-keyword">if</span> 判断用户猜数字的大小关系:‐eq(等于),‐ne(不等于),‐gt(大于),‐ge(大于等于),</span><br><span class="hljs-meta">#</span><span class="bash"> ‐lt(小于),‐le(小于等于)</span><br><br>while :<br>  do     <br>    read -p &quot;计算机生成了一个 1‐100 的随机数,你猜: &quot; cai    <br>    if [ $cai -eq $num ]    <br>    then        <br>        echo &quot;恭喜,猜对了&quot;           <br>        exit        <br>    elif [ $cai -gt $num ]       <br>    then            <br>        echo &quot;Oops,猜大了&quot;         <br>    else            <br>        echo &quot;Oops,猜小了&quot;     <br>    fi<br>  done<br></code></pre></td></tr></table></figure>

<p>7、监测 Nginx 访问日志 502 情况，并做相应动作</p>
<p>假设服务器环境为 lnmp，近期访问经常出现 502 现象，且 502 错误在重启 php-fpm 服务后消失，因此需要编写监控脚本，一旦出现 502，则自动重启 php-fpm 服务。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">场景：</span><br><span class="hljs-meta">#</span><span class="bash">1.访问日志文件的路径：/data/<span class="hljs-built_in">log</span>/access.log</span><br><span class="hljs-meta">#</span><span class="bash">2.脚本死循环，每10秒检测一次，10秒的日志条数为300条，出现502的比例不低于10%（30条）则需要重启php-fpm服务</span><br><span class="hljs-meta">#</span><span class="bash">3.重启命令为：/etc/init.d/php-fpm restart</span><br><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##########################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">监测Nginx访问日志502情况，并做相应动作</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##########################################################</span></span><br>log=/data/log/access.log<br>N=30 #设定阈值<br>while :do<br><span class="hljs-meta"> #</span><span class="bash">查看访问日志的最新300条，并统计502的次数</span><br>    err=`tail -n 300 $log |grep -c &#x27;502&quot; &#x27;` <br>if [ $err -ge $N ] <br>then<br>/etc/init.d/php-fpm restart 2&gt; /dev/null <br><span class="hljs-meta">#</span><span class="bash">设定60s延迟防止脚本bug导致无限重启php-fpm服务</span><br>     sleep 60<br> fi<br> sleep 10<br> done<br></code></pre></td></tr></table></figure>

<p>8、将结果分别赋值给变量</p>
<p>应用场景：希望将执行结果或者位置参数赋值给变量，以便后续使用。</p>
<p>方法1：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">for i in $(echo &quot;4 5 6&quot;); do<br>   eval a$i=$idone<br>echo $a4 $a5 $a6<br></code></pre></td></tr></table></figure>

<p>方法2：将位置参数192.168.1.1{1,2}拆分为到每个变量</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">num=0<br>for i in $(eval echo $*);do   #eval将&#123;1,2&#125;分解为1 2<br>   let num+=1<br>   eval node$&#123;num&#125;=&quot;$i&quot;<br>done<br>echo $node1 $node2 $node3<br><span class="hljs-meta">#</span><span class="bash"> bash a.sh 192.168.1.1&#123;1,2&#125;</span><br>192.168.1.11 192.168.1.12<br><br>方法3：arr=(4 5 6)<br>INDEX1=$(echo $&#123;arr[0]&#125;)<br>INDEX2=$(echo $&#123;arr[1]&#125;)<br>INDEX3=$(echo $&#123;arr[2]&#125;)<br></code></pre></td></tr></table></figure>

<p>9、批量修改文件名</p>
<p>示例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> touch article_&#123;1..3&#125;.html</span><br><span class="hljs-meta">#</span><span class="bash"> lsarticle_1.html  article_2.html  article_3.html</span><br>目的：把article改为bbs<br></code></pre></td></tr></table></figure>

<p>方法1：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">for file in $(ls *html); do<br>    mv $file bbs_$&#123;file#*_&#125;<br>    # mv $file $(echo $file |sed -r &#x27;s/.*(_.*)/bbs\1/&#x27;)<br>    # mv $file $(echo $file |echo bbs_$(cut -d_ -f2)<br></code></pre></td></tr></table></figure>

<p>方法2：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">for file in $(find . -maxdepth 1 -name &quot;*html&quot;); do<br>     mv $file bbs_$&#123;file#*_&#125;done<br></code></pre></td></tr></table></figure>

<p>方法3：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> rename article bbs *.html</span><br>把一个文档前五行中包含字母的行删掉，同时删除6到10行包含的所有字母<br><br>1）准备测试文件，文件名为2.txt<br><br>第1行1234567不包含字母<br>第2行56789BBBBBB<br>第3行67890CCCCCCCC<br>第4行78asdfDDDDDDDDD<br>第5行123456EEEEEEEE<br>第6行1234567ASDF<br>第7行56789ASDF<br>第8行67890ASDF<br>第9行78asdfADSF<br>第10行123456AAAA<br>第11行67890ASDF<br>第12行78asdfADSF<br>第13行123456AAAA<br></code></pre></td></tr></table></figure>

<p>2）脚本如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##############################################################</span></span><br>把一个文档前五行中包含字母的行删掉，同时删除6到10行包含的所有字母<br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br>sed -n &#x27;1,5&#x27;p 2.txt |sed &#x27;/[a-zA-Z]/&#x27;d<br>sed -n &#x27;6,10&#x27;p 2.txt |sed s&#x27;/[a-zA-Z]//&#x27;g<br>sed -n &#x27;11,$&#x27;p 2.txt<br><span class="hljs-meta">#</span><span class="bash">最终结果只是在屏幕上打印结果，如果想直接更改文件，可将输出结果写入临时文件中，再替换2.txt或者使用-i选项</span><br></code></pre></td></tr></table></figure>

<p>10、统计当前目录中以.html结尾的文件总大</p>
<p>方法1：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> find . -name <span class="hljs-string">&quot;*.html&quot;</span> -<span class="hljs-built_in">exec</span> du -k &#123;&#125; \; |awk <span class="hljs-string">&#x27;&#123;sum+=$1&#125;END&#123;print sum&#125;&#x27;</span></span><br><br>方法2：<br>```bash<br>for size in $(ls -l *.html |awk &#x27;&#123;print $5&#125;&#x27;); do<br>    sum=$(($sum+$size))<br>done<br>echo $sum<br></code></pre></td></tr></table></figure>

<p>11、扫描主机端口状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>HOST=$1<br>PORT=&quot;22 25 80 8080&quot;<br>for PORT in $PORT; do<br>    if echo &amp;&gt;/dev/null &gt; /dev/tcp/$HOST/$PORT; then<br>        echo &quot;$PORT open&quot;<br>    else<br>        echo &quot;$PORT close&quot;<br>    fi<br>done<br>用 shell 打印示例语句中字母数小于6的单词<br><br><span class="hljs-meta">#</span><span class="bash">示例语句：</span><br><span class="hljs-meta">#</span><span class="bash">Bash also interprets a number of multi-character options.</span><br><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">shell打印示例语句中字母数小于6的单词</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br>for s in Bash also interprets a number of multi-character options.<br>do<br> n=`echo $s|wc -c` <br> if [ $n -lt 6 ] <br> then<br> echo $s<br> fi<br>done<br></code></pre></td></tr></table></figure>

<p>12、输入数字运行相应命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">输入数字运行相应命令</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br>echo &quot;*cmd menu* 1-date 2-ls 3-who 4-pwd 0-exit &quot;<br>while :<br>do<br><span class="hljs-meta">#</span><span class="bash">捕获用户键入值</span><br> read -p &quot;please input number :&quot; n<br> n1=`echo $n|sed s&#x27;/[0-9]//&#x27;g`<br><span class="hljs-meta">#</span><span class="bash">空输入检测</span> <br> if [ -z &quot;$n&quot; ]<br> then<br> continue<br> fi<br><span class="hljs-meta">#</span><span class="bash">非数字输入检测</span> <br> if [ -n &quot;$n1&quot; ]<br> then<br> exit 0<br> fi<br> break<br>done<br>case $n in<br> 1)<br> date<br> ;;<br> 2)<br> ls<br> ;;<br> 3)<br> who<br> ;;<br> 4)<br> pwd<br> ;;<br> 0)<br> break<br> ;;<br>    #输入数字非1-4的提示<br> *)<br> echo &quot;please input number is [1-4]&quot;<br>esac<br></code></pre></td></tr></table></figure>

<p>13、Expect 实现 SSH 免交互执行命令</p>
<p>Expect是一个自动交互式应用程序的工具，如telnet，ftp，passwd等。</p>
<p>需先安装expect软件包。</p>
<p>方法1：EOF标准输出作为expect标准输入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>USER=root<br>PASS=123.com<br>IP=192.168.1.120<br>expect &lt;&lt; EOFset timeout 30spawn ssh $USER@$IP   expect &#123;    &quot;(yes/no)&quot; &#123;send &quot;yes\r&quot;; exp_continue&#125;    &quot;password:&quot; &#123;send &quot;$PASS\r&quot;&#125;<br>&#125;<br>expect &quot;$USER@*&quot;  &#123;send &quot;$1\r&quot;&#125;<br>expect &quot;$USER@*&quot;  &#123;send &quot;exit\r&quot;&#125;<br>expect eof<br>EOF<br></code></pre></td></tr></table></figure>

<p>方法2：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>USER=root<br>PASS=123.com<br>IP=192.168.1.120<br>expect -c &quot;<br>    spawn ssh $USER@$IP<br>    expect &#123;<br>        \&quot;(yes/no)\&quot; &#123;send \&quot;yes\r\&quot;; exp_continue&#125;<br>        \&quot;password:\&quot; &#123;send \&quot;$PASS\r\&quot;; exp_continue&#125;<br>        \&quot;$USER@*\&quot; &#123;send \&quot;df -h\r exit\r\&quot;; exp_continue&#125;<br>    &#125;&quot;<br></code></pre></td></tr></table></figure>

<p>方法3：将expect脚本独立出来</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">登录脚本：<br><span class="hljs-meta">#</span><span class="bash"> cat login.exp</span><br><span class="hljs-meta">#</span><span class="bash">!/usr/bin/expect</span><br>set ip [lindex $argv 0]<br>set user [lindex $argv 1]<br>set passwd [lindex $argv 2]<br>set cmd [lindex $argv 3]<br>if &#123; $argc != 4 &#125; &#123;<br>puts &quot;Usage: expect login.exp ip user passwd&quot;<br>exit 1<br>&#125;<br>set timeout 30<br>spawn ssh $user@$ip<br>expect &#123;    <br>    &quot;(yes/no)&quot; &#123;send &quot;yes\r&quot;; exp_continue&#125;<br>    &quot;password:&quot; &#123;send &quot;$passwd\r&quot;&#125;<br>&#125;<br>expect &quot;$user@*&quot;  &#123;send &quot;$cmd\r&quot;&#125;<br>expect &quot;$user@*&quot;  &#123;send &quot;exit\r&quot;&#125;<br>expect eof<br></code></pre></td></tr></table></figure>

<p>执行命令脚本：写个循环可以批量操作多台服务器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>HOST_INFO=user_info.txt<br>for ip in $(awk &#x27;&#123;print $1&#125;&#x27; $HOST_INFO)<br>do<br>    user=$(awk -v I=&quot;$ip&quot; &#x27;I==$1&#123;print $2&#125;&#x27; $HOST_INFO)<br>    pass=$(awk -v I=&quot;$ip&quot; &#x27;I==$1&#123;print $3&#125;&#x27; $HOST_INFO)<br>    expect login.exp $ip $user $pass $1<br>done<br>Linux主机SSH连接信息：<br><span class="hljs-meta">#</span><span class="bash"> cat user_info.txt</span><br>192.168.1.120 root 123456<br></code></pre></td></tr></table></figure>

<p>创建10个用户，并分别设置密码，密码要求10位且包含大小写字母以及数字，最后需要把每个用户的密码存在指定文件中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">创建10个用户，并分别设置密码，密码要求10位且包含大小写字母以及数字</span><br><span class="hljs-meta">#</span><span class="bash">最后需要把每个用户的密码存在指定文件中<span class="hljs-comment">#前提条件：安装mkpasswd命令</span></span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#############################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">生成10个用户的序列（00-09）</span><br>for u in `seq -w 0 09`do<br><span class="hljs-meta"> #</span><span class="bash">创建用户</span><br> useradd user_$u<br><span class="hljs-meta"> #</span><span class="bash">生成密码</span><br> p=`mkpasswd -s 0 -l 10` <br><span class="hljs-meta"> #</span><span class="bash">从标准输入中读取密码进行修改（不安全）</span><br> echo $p|passwd --stdin user_$u<br><span class="hljs-meta"> #</span><span class="bash">常规修改密码</span><br> echo -e &quot;$p\n$p&quot;|passwd user_$u<br><span class="hljs-meta"> #</span><span class="bash">将创建的用户及对应的密码记录到日志文件中</span><br> echo &quot;user_$u $p&quot; &gt;&gt; /tmp/userpassworddone<br></code></pre></td></tr></table></figure>

<p>14、监控 httpd 的进程数，根据监控情况做相应处理</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##############################################################################################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">需求：</span><br><span class="hljs-meta">#</span><span class="bash">1.每隔10s监控httpd的进程数，若进程数大于等于500，则自动重启Apache服务，并检测服务是否重启成功</span><br><span class="hljs-meta">#</span><span class="bash">2.若未成功则需要再次启动，若重启5次依旧没有成功，则向管理员发送告警邮件，并退出检测</span><br><span class="hljs-meta">#</span><span class="bash">3.如果启动成功，则等待1分钟后再次检测httpd进程数，若进程数正常，则恢复正常检测（10s一次），否则放弃重启并向管理员发送告警邮件，并退出检测</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">##############################################################################################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">计数器函数</span><br>check_service()<br>&#123;<br> j=0<br> for i in `seq 1 5` <br> do<br><span class="hljs-meta"> #</span><span class="bash">重启Apache的命令</span><br> /usr/local/apache2/bin/apachectl restart 2&gt; /var/log/httpderr.log    <br>    #判断服务是否重启成功<br> if [ $? -eq 0 ] then<br> break<br> else<br> j=$[$j+1] fi<br>    #判断服务是否已尝试重启5次<br> if [ $j -eq 5 ] then<br> mail.py exit<br> fi<br> done &#125;while :do<br> n=`pgrep -l httpd|wc -l` <br><span class="hljs-meta"> #</span><span class="bash">判断httpd服务进程数是否超过500</span><br> if [ $n -gt 500 ] then<br> /usr/local/apache2/bin/apachectl restart <br> if [ $? -ne 0 ] <br> then<br> check_service <br> else<br> sleep 60<br> n2=`pgrep -l httpd|wc -l` <br><span class="hljs-meta"> #</span><span class="bash">判断重启后是否依旧超过500</span><br>             if [ $n2 -gt 500 ] <br> then <br> mail.py exit<br> fi<br> fi<br> fi<br><span class="hljs-meta"> #</span><span class="bash">每隔10s检测一次</span><br> sleep 10done<br></code></pre></td></tr></table></figure>

<p>15、批量修改服务器用户密码</p>
<p>Linux主机SSH连接信息：旧密码</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> cat old_pass.txt</span> <br>192.168.18.217  root    123456     22<br>192.168.18.218  root    123456     22<br>内容格式：IP User Password Port<br><br>SSH远程修改密码脚本：新密码随机生成<br>https://www.linuxprobe.com/books<br><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>OLD_INFO=old_pass.txt<br>NEW_INFO=new_pass.txt<br>for IP in $(awk &#x27;/^[^#]/&#123;print $1&#125;&#x27; $OLD_INFO); do<br>    USER=$(awk -v I=$IP &#x27;I==$1&#123;print $2&#125;&#x27; $OLD_INFO)<br>    PASS=$(awk -v I=$IP &#x27;I==$1&#123;print $3&#125;&#x27; $OLD_INFO)<br>    PORT=$(awk -v I=$IP &#x27;I==$1&#123;print $4&#125;&#x27; $OLD_INFO)<br>    NEW_PASS=$(mkpasswd -l 8)  # 随机密码<br>    echo &quot;$IP   $USER   $NEW_PASS   $PORT&quot; &gt;&gt; $NEW_INFO<br>    expect -c &quot;<br>    spawn ssh -p$PORT $USER@$IP<br>    set timeout 2<br>    expect &#123;<br>        \&quot;(yes/no)\&quot; &#123;send \&quot;yes\r\&quot;;exp_continue&#125;<br>        \&quot;password:\&quot; &#123;send \&quot;$PASS\r\&quot;;exp_continue&#125;<br>        \&quot;$USER@*\&quot; &#123;send \&quot;echo \&#x27;$NEW_PASS\&#x27; |passwd --stdin $USER\r exit\r\&quot;;exp_continue&#125;<br>    &#125;&quot;<br>done<br>生成新密码文件：<br><br><span class="hljs-meta">#</span><span class="bash"> cat new_pass.txt</span> <br>192.168.18.217  root    n8wX3mU%      22<br>192.168.18.218  root    c87;ZnnL      22<br></code></pre></td></tr></table></figure>

<p>16、iptables 自动屏蔽访问网站频繁的IP</p>
<p>场景：恶意访问,安全防范</p>
<p>1）屏蔽每分钟访问超过200的IP</p>
<p>方法1：根据访问日志（Nginx为例）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>DATE=$(date +%d/%b/%Y:%H:%M)<br>ABNORMAL_IP=$(tail -n5000 access.log |grep $DATE |awk &#x27;&#123;a[$1]++&#125;END&#123;for(i in a)if(a[i]&gt;100)print i&#125;&#x27;)<br><span class="hljs-meta">#</span><span class="bash">先tail防止文件过大，读取慢，数字可调整每分钟最大的访问量。awk不能直接过滤日志，因为包含特殊字符。</span><br>for IP in $ABNORMAL_IP; do<br>    if [ $(iptables -vnL |grep -c &quot;$IP&quot;) -eq 0 ]; then<br>        iptables -I INPUT -s $IP -j DROP    fidone<br></code></pre></td></tr></table></figure>

<p>方法2：通过TCP建立的连接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>ABNORMAL_IP=$(netstat -an |awk &#x27;$4~/:80$/ &amp;&amp; $6~/ESTABLISHED/&#123;gsub(/:[0-9]+/,&quot;&quot;,$5);&#123;a[$5]++&#125;&#125;END&#123;for(i in a)if(a[i]&gt;100)print i&#125;&#x27;)<br><span class="hljs-meta">#</span><span class="bash">gsub是将第五列（客户端IP）的冒号和端口去掉</span><br>for IP in $ABNORMAL_IP; do<br>    if [ $(iptables -vnL |grep -c &quot;$IP&quot;) -eq 0 ]; then<br>        iptables -I INPUT -s $IP -j DROP    <br>        fi<br>done<br></code></pre></td></tr></table></figure>

<p>2）屏蔽每分钟SSH尝试登录超过10次的IP</p>
<p>方法1：通过lastb获取登录状态:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>DATE=$(date +&quot;%a %b %e %H:%M&quot;) #星期月天时分  %e单数字时显示7，而%d显示07<br>ABNORMAL_IP=$(lastb |grep &quot;$DATE&quot; |awk &#x27;&#123;a[$3]++&#125;END&#123;for(i in a)if(a[i]&gt;10)print i&#125;&#x27;)for IP in $ABNORMAL_IP; do<br>    if [ $(iptables -vnL |grep -c &quot;$IP&quot;) -eq 0 ]; then<br>        iptables -I INPUT -s $IP -j DROP    fidone<br></code></pre></td></tr></table></figure>

<p>方法2：通过日志获取登录状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>DATE=$(date +&quot;%b %d %H&quot;)<br>ABNORMAL_IP=&quot;$(tail -n10000 /var/log/auth.log |grep &quot;$DATE&quot; |awk &#x27;/Failed/&#123;a[$(NF-3)]++&#125;END&#123;for(i in a)if(a[i]&gt;5)print i&#125;&#x27;)&quot;<br>for IP in $ABNORMAL_IP; do<br>    if [ $(iptables -vnL |grep -c &quot;$IP&quot;) -eq 0 ]; then<br>        iptables -A INPUT -s $IP -j DROP        <br>        echo &quot;$(date +&quot;%F %T&quot;) - iptables -A INPUT -s $IP -j DROP&quot; &gt;&gt;~/ssh-login-limit.log    <br>    fi<br>done<br></code></pre></td></tr></table></figure>

<p>17、根据web访问日志，封禁请求量异常的IP，如IP在半小时后恢复正常，则解除封禁</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">###################################################################################</span></span><br><span class="hljs-meta">#</span><span class="bash">根据web访问日志，封禁请求量异常的IP，如IP在半小时后恢复正常，则解除封禁</span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">###################################################################################</span></span><br>logfile=/data/log/access.log<br><span class="hljs-meta">#</span><span class="bash">显示一分钟前的小时和分钟</span><br>d1=`date -d &quot;-1 minute&quot; +%H%M`<br>d2=`date +%M`<br>ipt=/sbin/iptables<br>ips=/tmp/ips.txt<br>block()<br>&#123; <br><span class="hljs-meta">#</span><span class="bash">将一分钟前的日志全部过滤出来并提取IP以及统计访问次数</span><br> grep &#x27;$d1:&#x27; $logfile|awk &#x27;&#123;print $1&#125;&#x27;|sort -n|uniq -c|sort -n &gt; $ips<br><span class="hljs-meta"> #</span><span class="bash">利用<span class="hljs-keyword">for</span>循环将次数超过100的IP依次遍历出来并予以封禁</span><br> for i in `awk &#x27;$1&gt;100 &#123;print $2&#125;&#x27; $ips` <br> do<br><span class="hljs-meta"> $</span><span class="bash">ipt -I INPUT -p tcp --dport 80 -s <span class="hljs-variable">$i</span> -j REJECT</span> <br> echo &quot;`date +%F-%T` $i&quot; &gt;&gt; /tmp/badip.log <br> done<br>&#125;<br>unblock()<br>&#123; <br><span class="hljs-meta">#</span><span class="bash">将封禁后所产生的pkts数量小于10的IP依次遍历予以解封</span><br> for a in `$ipt -nvL INPUT --line-numbers |grep &#x27;0.0.0.0/0&#x27;|awk &#x27;$2&lt;10 &#123;print $1&#125;&#x27;|sort -nr` <br> do <br><span class="hljs-meta"> $</span><span class="bash">ipt -D INPUT <span class="hljs-variable">$a</span></span><br> done<br><span class="hljs-meta"> $</span><span class="bash">ipt -Z</span><br>&#125;<br><span class="hljs-meta">#</span><span class="bash">当时间在00分以及30分时执行解封函数</span><br>if [ $d2 -eq &quot;00&quot; ] || [ $d2 -eq &quot;30&quot; ] <br> then<br><span class="hljs-meta"> #</span><span class="bash">要先解再封，因为刚刚封禁时产生的pkts数量很少</span><br> unblock<br> block <br> else<br> block<br>fi<br></code></pre></td></tr></table></figure>

<p>18、判断用户输入的是否为IP地址</p>
<p>方法1:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>function check_ip()&#123;<br>    IP=$1<br>    VALID_CHECK=$(echo $IP|awk -F. &#x27;$1&lt; =255&amp;&amp;$2&lt;=255&amp;&amp;$3&lt;=255&amp;&amp;$4&lt;=255&#123;print &quot;yes&quot;&#125;&#x27;)<br>    if echo $IP|grep -E &quot;^[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;$&quot;&gt;/dev/null; then<br>        if [ $VALID_CHECK == &quot;yes&quot; ]; then<br>            echo &quot;$IP available.&quot;<br>        else<br>            echo &quot;$IP not available!&quot;<br>        fi<br>    else<br>        echo &quot;Format error!&quot;<br>    fi<br>&#125;<br>check_ip 192.168.1.1<br>check_ip 256.1.1.1<br></code></pre></td></tr></table></figure>

<p>方法2：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>function check_ip()&#123;<br>    IP=$1<br>    if [[ $IP =~ ^[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;$ ]]; then<br>        FIELD1=$(echo $IP|cut -d. -f1)<br>        FIELD2=$(echo $IP|cut -d. -f2)<br>        FIELD3=$(echo $IP|cut -d. -f3)<br>        FIELD4=$(echo $IP|cut -d. -f4)<br>        if [ $FIELD1 -le 255 -a $FIELD2 -le 255 -a $FIELD3 -le 255 -a $FIELD4 -le 255 ]; then<br>            echo &quot;$IP available.&quot;<br>        else<br>            echo &quot;$IP not available!&quot;<br>        fi<br>    else<br>        echo &quot;Format error!&quot;<br>    fi<br>&#125;<br>check_ip 192.168.1.1<br>check_ip 256.1.1.1<br></code></pre></td></tr></table></figure>

<p>增加版：</p>
<p>加个死循环，如果IP可用就退出，不可用提示继续输入，并使用awk判断。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span><br>function check_ip()&#123;<br>    local IP=$1<br>    VALID_CHECK=$(echo $IP|awk -F. &#x27;$1&lt; =255&amp;&amp;$2&lt;=255&amp;&amp;$3&lt;=255&amp;&amp;$4&lt;=255&#123;print &quot;yes&quot;&#125;&#x27;)<br>    if echo $IP|grep -E &quot;^[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;$&quot; &gt;/dev/null; then<br>        if [ $VALID_CHECK == &quot;yes&quot; ]; then<br>            return 0<br>        else<br>            echo &quot;$IP not available!&quot;<br>            return 1<br>        fi<br>    else<br>        echo &quot;Format error! Please input again.&quot;<br>        return 1<br>    fi<br>&#125;<br>while true; do<br>    read -p &quot;Please enter IP: &quot; IP<br>    check_ip $IP<br>    [ $? -eq 0 ] &amp;&amp; break || continue<br>done<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>实用</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>DataX安装及基本使用</title>
    <url>/2021/04/24/DataX%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前置准备"><a href="#前置准备" class="headerlink" title="前置准备"></a>前置准备</h2><p>这里我们演示 MySQL 和 HDFS 之间的数据导入导出，需要预先安装 Hadoop集群。Hadoop 集群的安装教程如下：</p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s/WNS9Ho-UWesQifwk4FjxQQ">Linux下jdk的安装</a></p>
<p><a href="https://mp.weixin.qq.com/s/FNXjVGzIJlNDLbS6u0j6Pg">Linux下Python的安装-视频教程</a></p>
<p><a href="https://mp.weixin.qq.com/s/Ic1aumcFa8B-a-9kg5AscQ">Hadoop单机伪分布式-视频教程</a></p>
<p><a href="https://mp.weixin.qq.com/s/NLpvOiqr8tLDY4kA3EM7Zg">Hadoop完全分布式集群环境搭建-视频教程</a></p>
<p><a href="https://mp.weixin.qq.com/s/gmOmg6uKD2LjhZPf4eZXdA">HA(高可用)-Hadoop集群环境搭建视频+图文教程</a></p>
</blockquote>
<h2 id="一、DataX-概述"><a href="#一、DataX-概述" class="headerlink" title="一、DataX 概述"></a>一、DataX 概述</h2><p>DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。 </p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/DataX/datax_relation.png"/> </div>

<h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><h3 id="2-1-下载并解压"><a href="#2-1-下载并解压" class="headerlink" title="2.1 下载并解压"></a>2.1 下载并解压</h3><p>源码地址：<a href="https://github.com/alibaba/DataX">https://github.com/alibaba/DataX</a> </p>
<p>这里我下载的是最新版本的 DataX3.0 。下载地址为：<a href="http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz">http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz </a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 下载后进行解压</span><br>[xiaokang@hadoop ~]$ tar -zxvf datax.tar.gz -C /opt/software/<br></code></pre></td></tr></table></figure>

<h3 id="2-2-运行自检脚本"><a href="#2-2-运行自检脚本" class="headerlink" title="2.2 运行自检脚本"></a>2.2 运行自检脚本</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ cd /opt/software/datax/<br>[xiaokang@hadoop datax]$ bin/datax.py job/job.json<br></code></pre></td></tr></table></figure>

<p>出现以下界面说明DataX安装成功</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/DataX/job.png"/> </div>

<h2 id="三、基本使用"><a href="#三、基本使用" class="headerlink" title="三、基本使用"></a>三、基本使用</h2><h3 id="3-1-从stream读取数据并打印到控制台"><a href="#3-1-从stream读取数据并打印到控制台" class="headerlink" title="3.1 从stream读取数据并打印到控制台"></a>3.1 从stream读取数据并打印到控制台</h3><h4 id="1-查看官方json配置模板"><a href="#1-查看官方json配置模板" class="headerlink" title="1. 查看官方json配置模板"></a>1. 查看官方json配置模板</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ python /opt/software/datax/bin/datax.py -r streamreader -w streamwriter<br><br>DataX (DATAX-OPENSOURCE-3.0), From Alibaba !<br>Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.<br><br><br>Please refer to the streamreader document:<br>     https://github.com/alibaba/DataX/blob/master/streamreader/doc/streamreader.md <br><br>Please refer to the streamwriter document:<br>     https://github.com/alibaba/DataX/blob/master/streamwriter/doc/streamwriter.md <br> <br>Please save the following configuration as a json file and  use<br>     python &#123;DATAX_HOME&#125;/bin/datax.py &#123;JSON_FILE_NAME&#125;.json <br>to run the job.<br><br>&#123;<br>    &quot;job&quot;: &#123;<br>        &quot;content&quot;: [<br>            &#123;<br>                &quot;reader&quot;: &#123;<br>                    &quot;name&quot;: &quot;streamreader&quot;, <br>                    &quot;parameter&quot;: &#123;<br>                        &quot;column&quot;: [], <br>                        &quot;sliceRecordCount&quot;: &quot;&quot;<br>                    &#125;<br>                &#125;, <br>                &quot;writer&quot;: &#123;<br>                    &quot;name&quot;: &quot;streamwriter&quot;, <br>                    &quot;parameter&quot;: &#123;<br>                        &quot;encoding&quot;: &quot;&quot;, <br>                        &quot;print&quot;: true<br>                    &#125;<br>                &#125;<br>            &#125;<br>        ], <br>        &quot;setting&quot;: &#123;<br>            &quot;speed&quot;: &#123;<br>                &quot;channel&quot;: &quot;&quot;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="2-根据模板编写json文件"><a href="#2-根据模板编写json文件" class="headerlink" title="2. 根据模板编写json文件"></a>2. 根据模板编写json文件</h4><figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json">&#123;<br>    <span class="hljs-attr">&quot;job&quot;</span>: &#123;<br>        <span class="hljs-attr">&quot;content&quot;</span>: [<br>            &#123;<br>                <span class="hljs-attr">&quot;reader&quot;</span>: &#123;<br>                    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;streamreader&quot;</span>, <br>                    <span class="hljs-attr">&quot;parameter&quot;</span>: &#123;<br>                        <span class="hljs-attr">&quot;column&quot;</span>: [<br>							&#123;<br>								<span class="hljs-attr">&quot;type&quot;</span>:<span class="hljs-string">&quot;string&quot;</span>,<br>								<span class="hljs-attr">&quot;value&quot;</span>:<span class="hljs-string">&quot;xiaokang-微信公众号:小康新鲜事儿&quot;</span><br>							&#125;,<br>							&#123;<br>								<span class="hljs-attr">&quot;type&quot;</span>:<span class="hljs-string">&quot;string&quot;</span>,<br>								<span class="hljs-attr">&quot;value&quot;</span>:<span class="hljs-string">&quot;你好，世界-DataX&quot;</span><br>							&#125;<br>                        ], <br>                        <span class="hljs-attr">&quot;sliceRecordCount&quot;</span>: <span class="hljs-string">&quot;10&quot;</span><br>                    &#125;<br>                &#125;, <br>                <span class="hljs-attr">&quot;writer&quot;</span>: &#123;<br>                    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;streamwriter&quot;</span>, <br>                    <span class="hljs-attr">&quot;parameter&quot;</span>: &#123;<br>                        <span class="hljs-attr">&quot;encoding&quot;</span>: <span class="hljs-string">&quot;utf-8&quot;</span>, <br>                        <span class="hljs-attr">&quot;print&quot;</span>: <span class="hljs-literal">true</span><br>                    &#125;<br>                &#125;<br>            &#125;<br>        ], <br>        <span class="hljs-attr">&quot;setting&quot;</span>: &#123;<br>            <span class="hljs-attr">&quot;speed&quot;</span>: &#123;<br>                <span class="hljs-attr">&quot;channel&quot;</span>: <span class="hljs-string">&quot;2&quot;</span><br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="3-运行Job"><a href="#3-运行Job" class="headerlink" title="3. 运行Job"></a>3. 运行Job</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop json]$ /opt/software/datax/bin/datax.py ./stream2stream.json<br></code></pre></td></tr></table></figure>

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/DataX/stream2stream.png"/> </div>

<h3 id="3-2-MySQL数据导入到HDFS"><a href="#3-2-MySQL数据导入到HDFS" class="headerlink" title="3.2 MySQL数据导入到HDFS"></a>3.2 MySQL数据导入到HDFS</h3><p>示例：导出 MySQL 数据库中的 <code>help_keyword</code> 表到 HDFS 的 <code>/datax </code>目录下(此目录必须提前创建)。</p>
<blockquote>
<p>注：help_keyword 是 MySQL 内置的一张字典表，之后的示例均使用这张表。</p>
</blockquote>
<h4 id="1-查看官方json配置模板-1"><a href="#1-查看官方json配置模板-1" class="headerlink" title="1. 查看官方json配置模板"></a>1. 查看官方json配置模板</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop json]$ python /opt/software/datax/bin/datax.py -r mysqlreader -w hdfswriter<br><br>DataX (DATAX-OPENSOURCE-3.0), From Alibaba !<br>Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.<br><br><br>Please refer to the mysqlreader document:<br>     https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md <br><br>Please refer to the hdfswriter document:<br>     https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md <br> <br>Please save the following configuration as a json file and  use<br>     python &#123;DATAX_HOME&#125;/bin/datax.py &#123;JSON_FILE_NAME&#125;.json <br>to run the job.<br><br>&#123;<br>    &quot;job&quot;: &#123;<br>        &quot;content&quot;: [<br>            &#123;<br>                &quot;reader&quot;: &#123;<br>                    &quot;name&quot;: &quot;mysqlreader&quot;, <br>                    &quot;parameter&quot;: &#123;<br>                        &quot;column&quot;: [], <br>                        &quot;connection&quot;: [<br>                            &#123;<br>                                &quot;jdbcUrl&quot;: [], <br>                                &quot;table&quot;: []<br>                            &#125;<br>                        ], <br>                        &quot;password&quot;: &quot;&quot;, <br>                        &quot;username&quot;: &quot;&quot;, <br>                        &quot;where&quot;: &quot;&quot;<br>                    &#125;<br>                &#125;, <br>                &quot;writer&quot;: &#123;<br>                    &quot;name&quot;: &quot;hdfswriter&quot;, <br>                    &quot;parameter&quot;: &#123;<br>                        &quot;column&quot;: [], <br>                        &quot;compress&quot;: &quot;&quot;, <br>                        &quot;defaultFS&quot;: &quot;&quot;, <br>                        &quot;fieldDelimiter&quot;: &quot;&quot;, <br>                        &quot;fileName&quot;: &quot;&quot;, <br>                        &quot;fileType&quot;: &quot;&quot;, <br>                        &quot;path&quot;: &quot;&quot;, <br>                        &quot;writeMode&quot;: &quot;&quot;<br>                    &#125;<br>                &#125;<br>            &#125;<br>        ], <br>        &quot;setting&quot;: &#123;<br>            &quot;speed&quot;: &#123;<br>                &quot;channel&quot;: &quot;&quot;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="2-根据模板编写json文件-1"><a href="#2-根据模板编写json文件-1" class="headerlink" title="2. 根据模板编写json文件"></a>2. 根据模板编写json文件</h4><p>mysqlreader参数解析： </p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/DataX/mysqlreader.png"/> </div>
hdfswriter参数解析： 

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/DataX/hdfswriter.png"/> </div>
<figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json">&#123;<br>    <span class="hljs-attr">&quot;job&quot;</span>: &#123;<br>        <span class="hljs-attr">&quot;content&quot;</span>: [<br>            &#123;<br>                <span class="hljs-attr">&quot;reader&quot;</span>: &#123;<br>                    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;mysqlreader&quot;</span>, <br>                    <span class="hljs-attr">&quot;parameter&quot;</span>: &#123;<br>                        <span class="hljs-attr">&quot;column&quot;</span>: [<br>							<span class="hljs-string">&quot;help_keyword_id&quot;</span>,<br>							<span class="hljs-string">&quot;name&quot;</span><br>                        ], <br>                        <span class="hljs-attr">&quot;connection&quot;</span>: [<br>                            &#123;<br>                                <span class="hljs-attr">&quot;jdbcUrl&quot;</span>: [<br>									<span class="hljs-string">&quot;jdbc:mysql://192.168.1.106:3306/mysql&quot;</span><br>                                ], <br>                                <span class="hljs-attr">&quot;table&quot;</span>: [<br>									<span class="hljs-string">&quot;help_keyword&quot;</span><br>                                ]<br>                            &#125;<br>                        ], <br>                        <span class="hljs-attr">&quot;password&quot;</span>: <span class="hljs-string">&quot;xiaokang&quot;</span>, <br>                        <span class="hljs-attr">&quot;username&quot;</span>: <span class="hljs-string">&quot;root&quot;</span><br>                    &#125;<br>                &#125;, <br>                <span class="hljs-attr">&quot;writer&quot;</span>: &#123;<br>                    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;hdfswriter&quot;</span>, <br>                    <span class="hljs-attr">&quot;parameter&quot;</span>: &#123;<br>                        <span class="hljs-attr">&quot;column&quot;</span>: [<br>	                        &#123;<br>								<span class="hljs-attr">&quot;name&quot;</span>:<span class="hljs-string">&quot;help_keyword_id&quot;</span>,<br>								<span class="hljs-attr">&quot;type&quot;</span>:<span class="hljs-string">&quot;int&quot;</span><br>	                        &#125;,<br>	                        &#123;<br>								<span class="hljs-attr">&quot;name&quot;</span>:<span class="hljs-string">&quot;name&quot;</span>,<br>								<span class="hljs-attr">&quot;type&quot;</span>:<span class="hljs-string">&quot;string&quot;</span><br>	                        &#125;<br>                        ], <br>                        <span class="hljs-attr">&quot;defaultFS&quot;</span>: <span class="hljs-string">&quot;hdfs://hadoop:9000&quot;</span>, <br>                        <span class="hljs-attr">&quot;fieldDelimiter&quot;</span>: <span class="hljs-string">&quot;|&quot;</span>, <br>                        <span class="hljs-attr">&quot;fileName&quot;</span>: <span class="hljs-string">&quot;keyword.txt&quot;</span>, <br>                        <span class="hljs-attr">&quot;fileType&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <br>                        <span class="hljs-attr">&quot;path&quot;</span>: <span class="hljs-string">&quot;/datax&quot;</span>, <br>                        <span class="hljs-attr">&quot;writeMode&quot;</span>: <span class="hljs-string">&quot;append&quot;</span><br>                    &#125;<br>                &#125;<br>            &#125;<br>        ], <br>        <span class="hljs-attr">&quot;setting&quot;</span>: &#123;<br>            <span class="hljs-attr">&quot;speed&quot;</span>: &#123;<br>                <span class="hljs-attr">&quot;channel&quot;</span>: <span class="hljs-string">&quot;3&quot;</span><br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="3-运行Job-1"><a href="#3-运行Job-1" class="headerlink" title="3. 运行Job"></a>3. 运行Job</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop json]$ /opt/software/datax/bin/datax.py ./mysql2hdfs.json<br></code></pre></td></tr></table></figure>

<h3 id="3-3-HDFS数据导出到MySQL"><a href="#3-3-HDFS数据导出到MySQL" class="headerlink" title="3.3 HDFS数据导出到MySQL"></a>3.3 HDFS数据导出到MySQL</h3><h4 id="1-将3-2中导入的文件重命名并在数据库创建表"><a href="#1-将3-2中导入的文件重命名并在数据库创建表" class="headerlink" title="1. 将3.2中导入的文件重命名并在数据库创建表"></a>1. 将3.2中导入的文件重命名并在数据库创建表</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ hdfs dfs -mv /datax/keyword.txt__4c0e0d04_e503_437a_a1e3_49db49cbaaed /datax/keyword.txt<br></code></pre></td></tr></table></figure>

<p>表必须预先创建，建表语句如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> help_keyword_from_hdfs_datax <span class="hljs-keyword">LIKE</span> help_keyword;<br></code></pre></td></tr></table></figure>

<h4 id="2-查看官方json配置模板"><a href="#2-查看官方json配置模板" class="headerlink" title="2. 查看官方json配置模板"></a>2. 查看官方json配置模板</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop json]$ python /opt/software/datax/bin/datax.py -r hdfsreader -w mysqlwriter<br><br>DataX (DATAX-OPENSOURCE-3.0), From Alibaba !<br>Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.<br><br><br>Please refer to the hdfsreader document:<br>     https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md <br><br>Please refer to the mysqlwriter document:<br>     https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md <br> <br>Please save the following configuration as a json file and  use<br>     python &#123;DATAX_HOME&#125;/bin/datax.py &#123;JSON_FILE_NAME&#125;.json <br>to run the job.<br><br>&#123;<br>    &quot;job&quot;: &#123;<br>        &quot;content&quot;: [<br>            &#123;<br>                &quot;reader&quot;: &#123;<br>                    &quot;name&quot;: &quot;hdfsreader&quot;, <br>                    &quot;parameter&quot;: &#123;<br>                        &quot;column&quot;: [], <br>                        &quot;defaultFS&quot;: &quot;&quot;, <br>                        &quot;encoding&quot;: &quot;UTF-8&quot;, <br>                        &quot;fieldDelimiter&quot;: &quot;,&quot;, <br>                        &quot;fileType&quot;: &quot;orc&quot;, <br>                        &quot;path&quot;: &quot;&quot;<br>                    &#125;<br>                &#125;, <br>                &quot;writer&quot;: &#123;<br>                    &quot;name&quot;: &quot;mysqlwriter&quot;, <br>                    &quot;parameter&quot;: &#123;<br>                        &quot;column&quot;: [], <br>                        &quot;connection&quot;: [<br>                            &#123;<br>                                &quot;jdbcUrl&quot;: &quot;&quot;, <br>                                &quot;table&quot;: []<br>                            &#125;<br>                        ], <br>                        &quot;password&quot;: &quot;&quot;, <br>                        &quot;preSql&quot;: [], <br>                        &quot;session&quot;: [], <br>                        &quot;username&quot;: &quot;&quot;, <br>                        &quot;writeMode&quot;: &quot;&quot;<br>                    &#125;<br>                &#125;<br>            &#125;<br>        ], <br>        &quot;setting&quot;: &#123;<br>            &quot;speed&quot;: &#123;<br>                &quot;channel&quot;: &quot;&quot;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="3-根据模板编写json文件"><a href="#3-根据模板编写json文件" class="headerlink" title="3. 根据模板编写json文件"></a>3. 根据模板编写json文件</h4><figure class="highlight json"><table><tr><td class="code"><pre><code class="hljs json">&#123;<br>    <span class="hljs-attr">&quot;job&quot;</span>: &#123;<br>        <span class="hljs-attr">&quot;content&quot;</span>: [<br>            &#123;<br>                <span class="hljs-attr">&quot;reader&quot;</span>: &#123;<br>                    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;hdfsreader&quot;</span>, <br>                    <span class="hljs-attr">&quot;parameter&quot;</span>: &#123;<br>                        <span class="hljs-attr">&quot;column&quot;</span>: [<br>							<span class="hljs-string">&quot;*&quot;</span><br>                        ], <br>                        <span class="hljs-attr">&quot;defaultFS&quot;</span>: <span class="hljs-string">&quot;hdfs://hadoop:9000&quot;</span>, <br>                        <span class="hljs-attr">&quot;encoding&quot;</span>: <span class="hljs-string">&quot;UTF-8&quot;</span>, <br>                        <span class="hljs-attr">&quot;fieldDelimiter&quot;</span>: <span class="hljs-string">&quot;|&quot;</span>, <br>                        <span class="hljs-attr">&quot;fileType&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <br>                        <span class="hljs-attr">&quot;path&quot;</span>: <span class="hljs-string">&quot;/datax/keyword.txt&quot;</span><br>                    &#125;<br>                &#125;, <br>                <span class="hljs-attr">&quot;writer&quot;</span>: &#123;<br>                    <span class="hljs-attr">&quot;name&quot;</span>: <span class="hljs-string">&quot;mysqlwriter&quot;</span>, <br>                    <span class="hljs-attr">&quot;parameter&quot;</span>: &#123;<br>                        <span class="hljs-attr">&quot;column&quot;</span>: [<br>							<span class="hljs-string">&quot;help_keyword_id&quot;</span>,<br>							<span class="hljs-string">&quot;name&quot;</span><br>                        ], <br>                        <span class="hljs-attr">&quot;connection&quot;</span>: [<br>                            &#123;<br>                                <span class="hljs-attr">&quot;jdbcUrl&quot;</span>: <span class="hljs-string">&quot;jdbc:mysql://192.168.1.106:3306/mysql&quot;</span>, <br>                                <span class="hljs-attr">&quot;table&quot;</span>: [<span class="hljs-string">&quot;help_keyword_from_hdfs_datax&quot;</span>]<br>                            &#125;<br>                        ], <br>                        <span class="hljs-attr">&quot;password&quot;</span>: <span class="hljs-string">&quot;xiaokang&quot;</span>,  <br>                        <span class="hljs-attr">&quot;username&quot;</span>: <span class="hljs-string">&quot;root&quot;</span>, <br>                        <span class="hljs-attr">&quot;writeMode&quot;</span>: <span class="hljs-string">&quot;insert&quot;</span><br>                    &#125;<br>                &#125;<br>            &#125;<br>        ], <br>        <span class="hljs-attr">&quot;setting&quot;</span>: &#123;<br>            <span class="hljs-attr">&quot;speed&quot;</span>: &#123;<br>                <span class="hljs-attr">&quot;channel&quot;</span>: <span class="hljs-string">&quot;3&quot;</span><br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="3-运行Job-2"><a href="#3-运行Job-2" class="headerlink" title="3. 运行Job"></a>3. 运行Job</h4><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop json]$ /opt/software/datax/bin/datax.py ./hdfs2mysql.json<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>安装</tag>
        <tag>使用</tag>
        <tag>DataX</tag>
      </tags>
  </entry>
  <entry>
    <title>64条常用正则</title>
    <url>/2021/04/24/64%E6%9D%A1%E5%B8%B8%E7%94%A8%E6%AD%A3%E5%88%99/</url>
    <content><![CDATA[<h3 id="火车车次"><a href="#火车车次" class="headerlink" title="火车车次"></a>火车车次</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[GCDZTSPKXLY1-9]\d&#123;1,4&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="手机机身码-IMEI"><a href="#手机机身码-IMEI" class="headerlink" title="手机机身码(IMEI)"></a>手机机身码(IMEI)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\d&#123;15,17&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="必须带端口号的网址-或ip"><a href="#必须带端口号的网址-或ip" class="headerlink" title="必须带端口号的网址(或ip)"></a>必须带端口号的网址(或ip)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^((ht|f)tps?:\/\/)?[\w-]+(\.[\w-]+)+:\d&#123;1,5&#125;\/?$/<br></code></pre></td></tr></table></figure>

<h3 id="网址-url-支持端口和”-参数”和”-参数"><a href="#网址-url-支持端口和”-参数”和”-参数" class="headerlink" title="网址(url,支持端口和”?+参数”和”#+参数)"></a>网址(url,支持端口和”?+参数”和”#+参数)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(((ht|f)tps?):\/\/)?[\w-]+(\.[\w-]+)+([\w.,@?^=%&amp;:/~+#-]*[\w@?^=%&amp;/~+#-])?$/<br></code></pre></td></tr></table></figure>

<h3 id="统一社会信用代码"><a href="#统一社会信用代码" class="headerlink" title="统一社会信用代码"></a>统一社会信用代码</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[0-9A-HJ-NPQRTUWXY]&#123;2&#125;\d&#123;6&#125;[0-9A-HJ-NPQRTUWXY]&#123;10&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="迅雷链接"><a href="#迅雷链接" class="headerlink" title="迅雷链接"></a>迅雷链接</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^thunderx?:\/\/[a-zA-Z\d]+=$/<br></code></pre></td></tr></table></figure>

<h3 id="ed2k链接-宽松匹配"><a href="#ed2k链接-宽松匹配" class="headerlink" title="ed2k链接(宽松匹配)"></a>ed2k链接(宽松匹配)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^ed2k:\/\/\|file\|.+\|\/$/<br></code></pre></td></tr></table></figure>

<h3 id="磁力链接-宽松匹配"><a href="#磁力链接-宽松匹配" class="headerlink" title="磁力链接(宽松匹配)"></a>磁力链接(宽松匹配)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^magnet:\?xt=urn:btih:[0-9a-fA-F]&#123;40,&#125;.*$/<br></code></pre></td></tr></table></figure>

<h3 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:\d&#123;1,2&#125;|1\d\d|2[0-4]\d|25[0-5])(?:\.(?:\d&#123;1,2&#125;|1\d\d|2[0-4]\d|25[0-5]))&#123;3&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="linux”隐藏文件”路径"><a href="#linux”隐藏文件”路径" class="headerlink" title="linux”隐藏文件”路径"></a>linux”隐藏文件”路径</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\/(?:[^/]+\/)*\.[^/]*/<br></code></pre></td></tr></table></figure>

<h3 id="linux文件夹路径"><a href="#linux文件夹路径" class="headerlink" title="linux文件夹路径"></a>linux文件夹路径</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\/(?:[^/]+\/)*$/<br></code></pre></td></tr></table></figure>

<h3 id="linux文件路径"><a href="#linux文件路径" class="headerlink" title="linux文件路径"></a>linux文件路径</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\/(?:[^/]+\/)*[^/]+$/<br></code></pre></td></tr></table></figure>

<h3 id="window”文件夹”路径"><a href="#window”文件夹”路径" class="headerlink" title="window”文件夹”路径"></a>window”文件夹”路径</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-zA-Z]:\\(?:\w+\\?)*$/<br></code></pre></td></tr></table></figure>

<h3 id="window下”文件”路径"><a href="#window下”文件”路径" class="headerlink" title="window下”文件”路径"></a>window下”文件”路径</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-zA-Z]:\\(?:\w+\\)*\w+\.\w+$/<br></code></pre></td></tr></table></figure>

<h3 id="股票代码-A股"><a href="#股票代码-A股" class="headerlink" title="股票代码(A股)"></a>股票代码(A股)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(s[hz]|S[HZ])(000[\d]&#123;3&#125;|002[\d]&#123;3&#125;|300[\d]&#123;3&#125;|600[\d]&#123;3&#125;|60[\d]&#123;4&#125;)$/<br></code></pre></td></tr></table></figure>

<h3 id="大于等于0-小于等于150-支持小数位出现5-如145-5-用于判断考卷分数"><a href="#大于等于0-小于等于150-支持小数位出现5-如145-5-用于判断考卷分数" class="headerlink" title="大于等于0, 小于等于150, 支持小数位出现5, 如145.5, 用于判断考卷分数"></a>大于等于0, 小于等于150, 支持小数位出现5, 如145.5, 用于判断考卷分数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^150$|^(?:\d|[1-9]\d|1[0-4]\d)(?:.5)?$/<br></code></pre></td></tr></table></figure>

<h3 id="html注释"><a href="#html注释" class="headerlink" title="html注释"></a>html注释</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^&lt;!--[\s\S]*?--&gt;$/<br></code></pre></td></tr></table></figure>

<h3 id="md5格式-32位"><a href="#md5格式-32位" class="headerlink" title="md5格式(32位)"></a>md5格式(32位)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^([a-f\d]&#123;32&#125;|[A-F\d]&#123;32&#125;)$/<br></code></pre></td></tr></table></figure>

<h3 id="版本号-version-格式必须为X-Y-Z"><a href="#版本号-version-格式必须为X-Y-Z" class="headerlink" title="版本号(version)格式必须为X.Y.Z"></a>版本号(version)格式必须为X.Y.Z</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\d+(?:\.\d+)&#123;2&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="视频-video-链接地址（视频格式可按需增删）"><a href="#视频-video-链接地址（视频格式可按需增删）" class="headerlink" title="视频(video)链接地址（视频格式可按需增删）"></a>视频(video)链接地址（视频格式可按需增删）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^https?:\/\/(.+\/)+.+(\.(swf|avi|flv|mpg|rm|mov|wav|asf|3gp|mkv|rmvb|mp4))$/i<br></code></pre></td></tr></table></figure>

<h3 id="图片-image-链接地址（图片格式可按需增删）"><a href="#图片-image-链接地址（图片格式可按需增删）" class="headerlink" title="图片(image)链接地址（图片格式可按需增删）"></a>图片(image)链接地址（图片格式可按需增删）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^https?:\/\/(.+\/)+.+(\.(gif|png|jpg|jpeg|webp|svg|psd|bmp|tif))$/i<br></code></pre></td></tr></table></figure>

<h3 id="24小时制时间（HH-mm-ss）"><a href="#24小时制时间（HH-mm-ss）" class="headerlink" title="24小时制时间（HH:mm:ss）"></a>24小时制时间（HH:mm:ss）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:[01]\d|2[0-3]):[0-5]\d:[0-5]\d$/<br></code></pre></td></tr></table></figure>

<h3 id="12小时制时间（hh-mm-ss）"><a href="#12小时制时间（hh-mm-ss）" class="headerlink" title="12小时制时间（hh:mm:ss）"></a>12小时制时间（hh:mm:ss）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:1[0-2]|0?[1-9]):[0-5]\d:[0-5]\d$/<br></code></pre></td></tr></table></figure>

<h3 id="base64格式"><a href="#base64格式" class="headerlink" title="base64格式"></a>base64格式</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\s*data:(?:[a-z]+\/[a-z0-9-+.]+(?:;[a-z-]+=[a-z0-9-]+)?)?(?:;base64)?,([a-z0-9!$&amp;&#x27;,()*+;=\-._~:@/?%\s]*?)\s*$/i<br></code></pre></td></tr></table></figure>

<h3 id="数字-货币金额（支持负数、千分位分隔符）"><a href="#数字-货币金额（支持负数、千分位分隔符）" class="headerlink" title="数字/货币金额（支持负数、千分位分隔符）"></a>数字/货币金额（支持负数、千分位分隔符）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^-?\d+(,\d&#123;3&#125;)*(\.\d&#123;1,2&#125;)?$/<br></code></pre></td></tr></table></figure>

<h3 id="数字-货币金额-只支持正数、不支持校验千分位分隔符"><a href="#数字-货币金额-只支持正数、不支持校验千分位分隔符" class="headerlink" title="数字/货币金额 (只支持正数、不支持校验千分位分隔符)"></a>数字/货币金额 (只支持正数、不支持校验千分位分隔符)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/(?:^[1-9]([0-9]+)?(?:\.[0-9]&#123;1,2&#125;)?$)|(?:^(?:0)&#123;1&#125;$)|(?:^[0-9]\.[0-9](?:[0-9])?$)/<br></code></pre></td></tr></table></figure>

<h3 id="银行卡号（10到30位-覆盖对公-私账户-参考微信支付）"><a href="#银行卡号（10到30位-覆盖对公-私账户-参考微信支付）" class="headerlink" title="银行卡号（10到30位, 覆盖对公/私账户, 参考微信支付）"></a>银行卡号（10到30位, 覆盖对公/私账户, 参考<a href="https://pay.weixin.qq.com/wiki/doc/api/xiaowei.php?chapter=22_1">微信支付</a>）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[1-9]\d&#123;9,29&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="中文姓名"><a href="#中文姓名" class="headerlink" title="中文姓名"></a>中文姓名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:[\u4e00-\u9fa5·]&#123;2,16&#125;)$/<br></code></pre></td></tr></table></figure>

<h3 id="英文姓名"><a href="#英文姓名" class="headerlink" title="英文姓名"></a>英文姓名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/(^[a-zA-Z]&#123;1&#125;[a-zA-Z\s]&#123;0,20&#125;[a-zA-Z]&#123;1&#125;$)/<br></code></pre></td></tr></table></figure>

<h3 id="车牌号-新能源"><a href="#车牌号-新能源" class="headerlink" title="车牌号(新能源)"></a>车牌号(新能源)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/[京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领 A-Z]&#123;1&#125;[A-HJ-NP-Z]&#123;1&#125;(([0-9]&#123;5&#125;[DF])|([DF][A-HJ-NP-Z0-9][0-9]&#123;4&#125;))$/<br></code></pre></td></tr></table></figure>

<h3 id="车牌号-非新能源"><a href="#车牌号-非新能源" class="headerlink" title="车牌号(非新能源)"></a>车牌号(非新能源)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领 A-Z]&#123;1&#125;[A-HJ-NP-Z]&#123;1&#125;[A-Z0-9]&#123;4&#125;[A-Z0-9挂学警港澳]&#123;1&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="车牌号-新能源-非新能源"><a href="#车牌号-新能源-非新能源" class="headerlink" title="车牌号(新能源+非新能源)"></a>车牌号(新能源+非新能源)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:[京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领 A-Z]&#123;1&#125;[A-HJ-NP-Z]&#123;1&#125;(?:(?:[0-9]&#123;5&#125;[DF])|(?:[DF](?:[A-HJ-NP-Z0-9])[0-9]&#123;4&#125;)))$|(?:[京津沪渝冀豫云辽黑湘皖鲁新苏浙赣鄂桂甘晋蒙陕吉闽贵粤青藏川宁琼使领 A-Z]&#123;1&#125;[A-Z]&#123;1&#125;[A-HJ-NP-Z0-9]&#123;4&#125;[A-HJ-NP-Z0-9 挂学警港澳]&#123;1&#125;)$/<br></code></pre></td></tr></table></figure>

<h3 id="手机号-mobile-phone-中国-严谨-根据工信部2019年最新公布的手机号段"><a href="#手机号-mobile-phone-中国-严谨-根据工信部2019年最新公布的手机号段" class="headerlink" title="手机号(mobile phone)中国(严谨), 根据工信部2019年最新公布的手机号段"></a>手机号(mobile phone)中国(严谨), 根据工信部2019年最新公布的手机号段</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:(?:\+|00)86)?1(?:(?:3[\d])|(?:4[5-7|9])|(?:5[0-3|5-9])|(?:6[5-7])|(?:7[0-8])|(?:8[\d])|(?:9[1|8|9]))\d&#123;8&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="手机号-mobile-phone-中国-宽松-只要是13-14-15-16-17-18-19开头即可"><a href="#手机号-mobile-phone-中国-宽松-只要是13-14-15-16-17-18-19开头即可" class="headerlink" title="手机号(mobile phone)中国(宽松), 只要是13,14,15,16,17,18,19开头即可"></a>手机号(mobile phone)中国(宽松), 只要是13,14,15,16,17,18,19开头即可</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:(?:\+|00)86)?1[3-9]\d&#123;9&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="手机号-mobile-phone-中国-最宽松-只要是1开头即可-如果你的手机号是用来接收短信-优先建议选择这一条"><a href="#手机号-mobile-phone-中国-最宽松-只要是1开头即可-如果你的手机号是用来接收短信-优先建议选择这一条" class="headerlink" title="手机号(mobile phone)中国(最宽松), 只要是1开头即可, 如果你的手机号是用来接收短信, 优先建议选择这一条"></a>手机号(mobile phone)中国(最宽松), 只要是1开头即可, 如果你的手机号是用来接收短信, 优先建议选择这一条</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:(?:\+|00)86)?1\d&#123;10&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="date-日期"><a href="#date-日期" class="headerlink" title="date(日期)"></a>date(日期)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\d&#123;4&#125;(-)(1[0-2]|0?\d)\1([0-2]\d|\d|30|31)$/<br></code></pre></td></tr></table></figure>

<h3 id="email-邮箱"><a href="#email-邮箱" class="headerlink" title="email(邮箱)"></a>email(邮箱)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(([^&lt;&gt;()[\]\\.,;:\s@&quot;]+(\.[^&lt;&gt;()[\]\\.,;:\s@&quot;]+)*)|(&quot;.+&quot;))@((\[[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\.[0-9]&#123;1,3&#125;\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]&#123;2,&#125;))$/<br></code></pre></td></tr></table></figure>

<h3 id="座机-tel-phone-电话-国内-如-0341-86091234"><a href="#座机-tel-phone-电话-国内-如-0341-86091234" class="headerlink" title="座机(tel phone)电话(国内),如: 0341-86091234"></a>座机(tel phone)电话(国内),如: 0341-86091234</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\d&#123;3&#125;-\d&#123;8&#125;$|^\d&#123;4&#125;-\d&#123;7,8&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="身份证号-1代-15位数字"><a href="#身份证号-1代-15位数字" class="headerlink" title="身份证号(1代,15位数字)"></a>身份证号(1代,15位数字)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[1-9]\d&#123;7&#125;(?:0\d|10|11|12)(?:0[1-9]|[1-2][\d]|30|31)\d&#123;3&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="身份证号-2代-18位数字-最后一位是校验位-可能为数字或字符X"><a href="#身份证号-2代-18位数字-最后一位是校验位-可能为数字或字符X" class="headerlink" title="身份证号(2代,18位数字),最后一位是校验位,可能为数字或字符X"></a>身份证号(2代,18位数字),最后一位是校验位,可能为数字或字符X</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[1-9]\d&#123;5&#125;(?:18|19|20)\d&#123;2&#125;(?:0[1-9]|10|11|12)(?:0[1-9]|[1-2]\d|30|31)\d&#123;3&#125;[\dXx]$/<br></code></pre></td></tr></table></figure>

<h3 id="身份证号-支持1-2代-15位-18位数字"><a href="#身份证号-支持1-2代-15位-18位数字" class="headerlink" title="身份证号, 支持1/2代(15位/18位数字)"></a>身份证号, 支持1/2代(15位/18位数字)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/(^\d&#123;8&#125;(0\d|10|11|12)([0-2]\d|30|31)\d&#123;3&#125;$)|(^\d&#123;6&#125;(18|19|20)\d&#123;2&#125;(0[1-9]|10|11|12)([0-2]\d|30|31)\d&#123;3&#125;(\d|X|x)$)/<br></code></pre></td></tr></table></figure>

<h3 id="护照（包含香港、澳门）"><a href="#护照（包含香港、澳门）" class="headerlink" title="护照（包含香港、澳门）"></a>护照（包含香港、澳门）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/(^[EeKkGgDdSsPpHh]\d&#123;8&#125;$)|(^(([Ee][a-fA-F])|([DdSsPp][Ee])|([Kk][Jj])|([Mm][Aa])|(1[45]))\d&#123;7&#125;$)/<br></code></pre></td></tr></table></figure>

<h3 id="帐号是否合法-字母开头，允许5-16字节，允许字母数字下划线组合"><a href="#帐号是否合法-字母开头，允许5-16字节，允许字母数字下划线组合" class="headerlink" title="帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线组合"></a>帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线组合</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-zA-Z]\w&#123;4,15&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="中文-汉字"><a href="#中文-汉字" class="headerlink" title="中文/汉字"></a>中文/汉字</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:[\u3400-\u4DB5\u4E00-\u9FEA\uFA0E\uFA0F\uFA11\uFA13\uFA14\uFA1F\uFA21\uFA23\uFA24\uFA27-\uFA29]|[\uD840-\uD868\uD86A-\uD86C\uD86F-\uD872\uD874-\uD879][\uDC00-\uDFFF]|\uD869[\uDC00-\uDED6\uDF00-\uDFFF]|\uD86D[\uDC00-\uDF34\uDF40-\uDFFF]|\uD86E[\uDC00-\uDC1D\uDC20-\uDFFF]|\uD873[\uDC00-\uDEA1\uDEB0-\uDFFF]|\uD87A[\uDC00-\uDFE0])+$/<br></code></pre></td></tr></table></figure>

<h3 id="小数"><a href="#小数" class="headerlink" title="小数"></a>小数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\d+\.\d+$/<br></code></pre></td></tr></table></figure>

<h3 id="数字"><a href="#数字" class="headerlink" title="数字"></a>数字</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\d&#123;1,&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="html标签-宽松匹配"><a href="#html标签-宽松匹配" class="headerlink" title="html标签(宽松匹配)"></a>html标签(宽松匹配)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/&lt;(\w+)[^&gt;]*&gt;(.*?&lt;\/\1&gt;)?/<br></code></pre></td></tr></table></figure>

<h3 id="qq号格式正确"><a href="#qq号格式正确" class="headerlink" title="qq号格式正确"></a>qq号格式正确</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[1-9][0-9]&#123;4,10&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="数字和字母组成"><a href="#数字和字母组成" class="headerlink" title="数字和字母组成"></a>数字和字母组成</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[A-Za-z0-9]+$/<br></code></pre></td></tr></table></figure>

<h3 id="英文字母"><a href="#英文字母" class="headerlink" title="英文字母"></a>英文字母</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-zA-Z]+$/<br></code></pre></td></tr></table></figure>

<h3 id="小写英文字母组成"><a href="#小写英文字母组成" class="headerlink" title="小写英文字母组成"></a>小写英文字母组成</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-z]+$/<br></code></pre></td></tr></table></figure>

<h3 id="大写英文字母"><a href="#大写英文字母" class="headerlink" title="大写英文字母"></a>大写英文字母</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[A-Z]+$/<br></code></pre></td></tr></table></figure>

<h3 id="密码强度校验，最少6位，包括至少1个大写字母，1个小写字母，1个数字，1个特殊字符"><a href="#密码强度校验，最少6位，包括至少1个大写字母，1个小写字母，1个数字，1个特殊字符" class="headerlink" title="密码强度校验，最少6位，包括至少1个大写字母，1个小写字母，1个数字，1个特殊字符"></a>密码强度校验，最少6位，包括至少1个大写字母，1个小写字母，1个数字，1个特殊字符</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^\S*(?=\S&#123;6,&#125;)(?=\S*\d)(?=\S*[A-Z])(?=\S*[a-z])(?=\S*[!@#$%^&amp;*? ])\S*$/<br></code></pre></td></tr></table></figure>

<h3 id="用户名校验，4到16位（字母，数字，下划线，减号）"><a href="#用户名校验，4到16位（字母，数字，下划线，减号）" class="headerlink" title="用户名校验，4到16位（字母，数字，下划线，减号）"></a>用户名校验，4到16位（字母，数字，下划线，减号）</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-zA-Z0-9_-]&#123;4,16&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="ip-v4"><a href="#ip-v4" class="headerlink" title="ip-v4"></a>ip-v4</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.)&#123;3&#125;(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$/<br></code></pre></td></tr></table></figure>

<h3 id="ip-v6"><a href="#ip-v6" class="headerlink" title="ip-v6"></a>ip-v6</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;:[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;:([0-9A-Fa-f]&#123;1,4&#125;:)?[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;:([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,2&#125;[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;:([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,3&#125;[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;:([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,4&#125;[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;((\b((25[0-5])|(1\d&#123;2&#125;)|(2[0-4]\d)|(\d&#123;1,2&#125;))\b)\.)&#123;3&#125;(\b((25[0-5])|(1\d&#123;2&#125;)|(2[0-4]\d)|(\d&#123;1,2&#125;))\b))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,5&#125;:((\b((25[0-5])|(1\d&#123;2&#125;)|(2[0-4]\d)|(\d&#123;1,2&#125;))\b)\.)&#123;3&#125;(\b((25[0-5])|(1\d&#123;2&#125;)|(2[0-4]\d)|(\d&#123;1,2&#125;))\b))|(::([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,5&#125;((\b((25[0-5])|(1\d&#123;2&#125;)|(2[0-4]\d)|(\d&#123;1,2&#125;))\b)\.)&#123;3&#125;(\b((25[0-5])|(1\d&#123;2&#125;)|(2[0-4]\d)|(\d&#123;1,2&#125;))\b))|([0-9A-Fa-f]&#123;1,4&#125;::([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,5&#125;[0-9A-Fa-f]&#123;1,4&#125;)|(::([0-9A-Fa-f]&#123;1,4&#125;:)&#123;0,6&#125;[0-9A-Fa-f]&#123;1,4&#125;)|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1,7&#125;:))$/i<br></code></pre></td></tr></table></figure>

<h3 id="16进制颜色"><a href="#16进制颜色" class="headerlink" title="16进制颜色"></a>16进制颜色</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^#?([a-fA-F0-9]&#123;6&#125;|[a-fA-F0-9]&#123;3&#125;)$/<br></code></pre></td></tr></table></figure>

<h3 id="微信号-wx-，6至20位，以字母开头，字母，数字，减号，下划线"><a href="#微信号-wx-，6至20位，以字母开头，字母，数字，减号，下划线" class="headerlink" title="微信号(wx)，6至20位，以字母开头，字母，数字，减号，下划线"></a>微信号(wx)，6至20位，以字母开头，字母，数字，减号，下划线</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[a-zA-Z][-_a-zA-Z0-9]&#123;5,19&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="邮政编码-中国"><a href="#邮政编码-中国" class="headerlink" title="邮政编码(中国)"></a>邮政编码(中国)</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^(0[1-7]|1[0-356]|2[0-7]|3[0-6]|4[0-7]|5[1-7]|6[1-7]|7[0-5]|8[013-6])\d&#123;4&#125;$/<br></code></pre></td></tr></table></figure>

<h3 id="中文和数字"><a href="#中文和数字" class="headerlink" title="中文和数字"></a>中文和数字</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^((?:[\u3400-\u4DB5\u4E00-\u9FEA\uFA0E\uFA0F\uFA11\uFA13\uFA14\uFA1F\uFA21\uFA23\uFA24\uFA27-\uFA29]|[\uD840-\uD868\uD86A-\uD86C\uD86F-\uD872\uD874-\uD879][\uDC00-\uDFFF]|\uD869[\uDC00-\uDED6\uDF00-\uDFFF]|\uD86D[\uDC00-\uDF34\uDF40-\uDFFF]|\uD86E[\uDC00-\uDC1D\uDC20-\uDFFF]|\uD873[\uDC00-\uDEA1\uDEB0-\uDFFF]|\uD87A[\uDC00-\uDFE0])|(\d))+$/<br></code></pre></td></tr></table></figure>

<h3 id="不能包含字母"><a href="#不能包含字母" class="headerlink" title="不能包含字母"></a>不能包含字母</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^[^A-Za-z]*$/<br></code></pre></td></tr></table></figure>

<h3 id="java包名"><a href="#java包名" class="headerlink" title="java包名"></a>java包名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^([a-zA-Z_][a-zA-Z0-9_]*)+([.][a-zA-Z_][a-zA-Z0-9_]*)+$/<br></code></pre></td></tr></table></figure>

<h3 id="mac地址"><a href="#mac地址" class="headerlink" title="mac地址"></a>mac地址</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/^((([a-f0-9]&#123;2&#125;:)&#123;5&#125;)|(([a-f0-9]&#123;2&#125;-)&#123;5&#125;))[a-f0-9]&#123;2&#125;$/i<br></code></pre></td></tr></table></figure>

<h3 id="匹配连续重复的字符"><a href="#匹配连续重复的字符" class="headerlink" title="匹配连续重复的字符"></a>匹配连续重复的字符</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">/(.)\1+/<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>正则</category>
      </categories>
      <tags>
        <tag>日常使用</tag>
        <tag>匹配</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka你了解多少？</title>
    <url>/2021/04/24/Kafka%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%A4%9A%E5%B0%91/</url>
    <content><![CDATA[<h3 id="1-Kafka架构"><a href="#1-Kafka架构" class="headerlink" title="1. Kafka架构"></a>1. Kafka架构</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-architecture.png"/> </div>

<p><strong>Kafka Cluster</strong></p>
<p>Kafka作为分布式消息队列，是以集群形式对外服务的（即使只有一个节点）。初始化时会在Zookeeper的/cluster/id目录下创建ClusterID值</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[zk: localhost:2181(CONNECTED) 5] get /cluster/id<br>&#123;&quot;version&quot;:&quot;1&quot;,&quot;id&quot;:&quot;Nf1FphTTQni9RjWWz31lrQ&quot;&#125;<br></code></pre></td></tr></table></figure>

<p><strong>Producer</strong></p>
<p>生产者是Kafka中发送消息的客户端，主要是通过Zookeeper与Kafka集群进行连接，并且将消息发送<br>到Kafka集群  </p>
<p><strong>Consumer</strong></p>
<p>消费者是Kafka消息消费的客户端。Consumer直接与Kafka Borker构建连接消费Broker上某个主题<br>的数据</p>
<p><strong>Zookeeper集群</strong></p>
<p>Kafka集群、ISR、消费者组等信息存储在Zookeeper中，0.9版本之前消费者offset维护在zk中，0.9版本之后存储在本地</p>
<p><strong>Topic</strong></p>
<p>生产者发送消息时必须指定一个分类，我们将它称为主题。主题是Kafka中数据隔离的一种方式，Topic是一个逻辑概念，其真正的表现形式是在Kafka存储目录下创建多个关于该主题的文件夹。每个主题代表了一种数据来源。比如topicA：代表日志数据，topicB：代表用户数据 </p>
<p><strong>Partition</strong></p>
<p>Partition就是Topic物理上的实现，其表现形式为目录。每个Topic可以包含多个分区，每个Partiton包含了Topic的部分数据。Partition目录命名方式：Topic名称-分区ID，比如logs，三个分区logs-0、logs-1、logs-2  </p>
<p><strong>Broker</strong></p>
<p>Kafka集群中每个节点都是Broker。一个集群可以包含N个Broker，Broker.id值必须不同。在Zookeeper之上可以查看每个节点的详细信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[zk: localhost:2181(CONNECTED) 11] get /brokers/ids/0<br>&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://hadoop:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;hadoop&quot;,&quot;timestamp&quot;:&quot;1593767504799&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;<br></code></pre></td></tr></table></figure>

<p><strong>Consumer Group</strong></p>
<p>消费者组主要用来管理组织消费者的，并且消费者组规定了消费消息的行为。Kafka实现点对点和发布订阅模式主要是基于Consumer Group的，其中：在同一个消费者组内，消息是P2P模式；在不同消费者组之间，消息是发布订阅模式  </p>
<h3 id="2-Kafka压测"><a href="#2-Kafka压测" class="headerlink" title="2. Kafka压测"></a>2. Kafka压测</h3><p>使用Kafka官方自带压力测试脚本（kafka-consumer-perf-test.sh、kafka-producer-perf-test.sh）进行压测，可以查看哪个地方出现了瓶颈（CPU、内存、网络IO）。<strong>一般都是网络IO达到瓶颈</strong>  </p>
<p><strong>写入10w消息压测结果</strong> </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ kafka-producer-perf-test.sh --topic logs --num-records 100000 --record-size 1000  --throughput 2000 --producer-props bootstrap.servers=hadoop:9092<br><br>10002 records sent, 1999.6 records/sec (1.91 MB/sec), 30.1 ms avg latency, 608.0 ms max latency.<br>9990 records sent, 1997.6 records/sec (1.91 MB/sec), 1.4 ms avg latency, 28.0 ms max latency.<br>10022 records sent, 2004.4 records/sec (1.91 MB/sec), 0.9 ms avg latency, 13.0 ms max latency.<br>9998 records sent, 1999.6 records/sec (1.91 MB/sec), 1.0 ms avg latency, 13.0 ms max latency.<br>9986 records sent, 1996.4 records/sec (1.90 MB/sec), 0.9 ms avg latency, 12.0 ms max latency.<br>10022 records sent, 2004.4 records/sec (1.91 MB/sec), 0.7 ms avg latency, 21.0 ms max latency.<br>10002 records sent, 2000.0 records/sec (1.91 MB/sec), 0.5 ms avg latency, 12.0 ms max latency.<br>10002 records sent, 2000.0 records/sec (1.91 MB/sec), 0.4 ms avg latency, 11.0 ms max latency.<br>10004 records sent, 2000.4 records/sec (1.91 MB/sec), 0.4 ms avg latency, 12.0 ms max latency.<br>100000 records sent, 1999.000500 records/sec (1.91 MB/sec), 3.68 ms avg latency, 608.00 ms max latency, 1 ms 50th, 3 ms 95th, 164 ms 99th, 218 ms 99.9th.<br><br>--topic topic名称，此处为logs<br>--num-records 总共需要发送的消息数，此处为100000<br>--record-size 每个记录的字节数，此处为1000<br>--throughput 每秒钟发送的记录数，此处为2000，如果设置为-1，则表示不限流，可以测出生产者最大吞吐量<br>--producer-props bootstrap.servers=hadoop:9092 发送端的配置信息，此处使用默认端口号9092<br><br><span class="hljs-meta">#</span><span class="bash">消息写入测试结果解析：</span><br><span class="hljs-meta">#</span><span class="bash">本例中写入10w条消息为例，每秒平均向Kafka写入了1.91MB的数据，大概是1999.000条消息/秒，每次写入的平均延迟为3.68毫秒，最大的延迟为608毫秒。</span><br></code></pre></td></tr></table></figure>

<p><strong>消费10w消息压测结果</strong> </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">[xiaokang@hadoop ~]$ kafka-consumer-perf-test.sh --broker-list hadoop:9092 --topic logs --fetch-size 1048576 --messages 100000 --threads 1<br><br>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec<br>2020-07-03 19:33:36:119, 2020-07-03 19:33:39:595, 95.3674, 27.4360, 100000, 28768.6997, 1593776018209, -1593776014733, -0.0000, -0.0001<br><br>--broker-list 指定Kafka的链接信息，此处为hadoop:9092<br>--topic 指定Topic的名称，此处为logs，即上面写入的消息<br>--fetch-size 指定每次fetch的数据的大小，本例为1048576（1M）<br>--messages 总共要消费的消息个数，此处为100000，10w<br><br><span class="hljs-meta">#</span><span class="bash">消息消费测试结果解析：</span><br><span class="hljs-meta">#</span><span class="bash">本例中消费10w条消息为例总共消费了95.3674M的数据，每秒消费数据大小为27.4360M，总共消费了100000条消息，每秒消费28768.6997条消息。</span><br></code></pre></td></tr></table></figure>

<h3 id="3-Kafka机器数量计算"><a href="#3-Kafka机器数量计算" class="headerlink" title="3. Kafka机器数量计算"></a>3. Kafka机器数量计算</h3><p>Kafka机器数量=2*（峰值生产速度*副本数/100）+1</p>
<p>一般我们会先拿到峰值生产速度（写入消息时每秒写入的数据量），再根据设定的副本数就可以预估出需要部署Kafka的数量</p>
<p>一般峰值生产速度在50M/s，副本数为2，这样得出Kafka机器数量=2*（50*2/100）+1=3台</p>
<h3 id="4-生产者生产数据过程"><a href="#4-生产者生产数据过程" class="headerlink" title="4. 生产者生产数据过程"></a>4. 生产者生产数据过程</h3><p>以kafka-console-producer.sh 命令为例：<br>该运行命令会启动ConsoleProducer进程，ConsoleProducer初始化过程中会创建KafkaProducer对象。KafkaProducer首先将消息数据封装成ProducerRecord，ProducerRecord对象会对消息进行序列化（涉及到网络传输），之后会被RecordAccumulator消息记录器进行收集，进而放在消息队列缓冲池（ConcurrentMap）。消息缓冲池中对象是以batch存在（一次一批数据）。KafkaProducer在进行初始化的时候会创建NetworkClient对象。NetworkClient主要作用负责管理客户端与服务端的网络通信，并且是以NIO的形式发送消息（同步或异步发送均可）。最后由后台sender线程将数据从缓冲池队列中拉取过来，以批量的形式将数据发送到客户端</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">NetworkClient：三大核心功能</span><br><span class="hljs-attr">1.ready()：主要建立与broker链接。NetworkClient连接到kafka集群中存活的节点</span><br><span class="hljs-attr">2.send()：用来将客户端请求发送到请求队列中，进而会通过网络选择器将请求最终发送到Kafka集群存活的节点</span><br><span class="hljs-attr">3.poll()：用来通过socket请求读取客户端的响应。一般poll()是循环操作</span><br></code></pre></td></tr></table></figure>

<h3 id="5-消费者消费数据过程"><a href="#5-消费者消费数据过程" class="headerlink" title="5. 消费者消费数据过程"></a>5. 消费者消费数据过程</h3><p>客户端代理对象KafkaConsumer通过subscribe订阅主题，并且通过poll拉取数据，最后通过commitSync方法提交消费者消费状态（维护offset值）。拉取数据是以特定的时间参数轮询的批量拉取数据，并将拉取的结果缓存到ConsumerRecords，最后通过迭代ConsumerRecords对象获取每一条数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">ConsumerCoordinator：KafkaConsumer协调器对象，主要负责与服务端进行交互，比如自动提交offset、心跳检测、再平衡操作、跟踪kafka元数据<br>Fetcher：拉取数据管理器，负责拉取数据并且接受客户端响应<br>ConsumerNetworkClient：主要负责与Kafka服务节点进行连接，发送拉取数据请求<br><br>max.poll.records ：每次轮询获取最大批量的数据条数 默认500条<br></code></pre></td></tr></table></figure>

<h3 id="6-一些Kafka经验值"><a href="#6-一些Kafka经验值" class="headerlink" title="6. 一些Kafka经验值"></a>6. 一些Kafka经验值</h3><figure class="highlight properties"><table><tr><td class="code"><pre><code class="hljs properties"><span class="hljs-comment"># Kafka的日志保存时间，默认7天</span><br><span class="hljs-meta">log.retention.hours</span>=<span class="hljs-string">168</span><br><br><span class="hljs-attr">Kafka硬盘大小多大合适？</span><br><span class="hljs-attr">每天的数据量*7天/70%</span><br><br><span class="hljs-attr">Kafka监控器：KafkaManager、KafkaMonitor、kafkaeagle</span><br><br><span class="hljs-attr">Kafka分区数设置多少合适？</span><br><span class="hljs-attr">分区数并不是越多越好，一般分区数不要超过集群机器数量。分区数越多占用内存越大（ISR等），一个节点集中的分区也就越多，当它宕机的时候，对系统的影响也就越大。分区数一般设置为：3-10</span><br><br><span class="hljs-attr">副本数设置多少合适？</span><br><span class="hljs-attr">一般设置成2个或3个，大部分企业设置为2个</span><br><br><span class="hljs-attr">Topic搞多少个合适？</span><br><span class="hljs-attr">通常情况下多少个日志类型就多少个Topic，也有对日志类型进行合并的</span><br></code></pre></td></tr></table></figure>

<h3 id="7-一条消息如何确定分区？"><a href="#7-一条消息如何确定分区？" class="headerlink" title="7. 一条消息如何确定分区？"></a>7. 一条消息如何确定分区？</h3><p>KafkaProducer提供了三种方式来让一条消息确定分区</p>
<p>1.通过ProducerRecord对象中partition属性指定分区id</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ProducerRecord</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>&#123;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String topic;<br>        <span class="hljs-comment">//分区</span><br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Integer partition;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Headers headers;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> K key;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> V value;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Long timestamp;<br>        <span class="hljs-comment">//构造函数</span><br>        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ProducerRecord</span><span class="hljs-params">(String topic, Integer partition, Long timestamp, K key, V value)</span> </span>&#123;<br>        		<span class="hljs-keyword">this</span>(topic, partition, timestamp, key, value, <span class="hljs-keyword">null</span>);<br>        &#125;<br>&#125; <br><br><span class="hljs-comment">// Kafka消息被封装成ProducerRecord，在创建时可以通过构造函数指定partitionId</span><br></code></pre></td></tr></table></figure>

<p>2.未指定partitionId，但key不为空，此时根据key的hash值进行分区</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> <span class="hljs-title">partition</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record, <span class="hljs-keyword">byte</span>[]serializedKey, <span class="hljs-keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;<br>        Integer partition = record.partition();<br>        <span class="hljs-keyword">return</span> partition != <span class="hljs-keyword">null</span> ?<br>        partition :<br>        partitioner.partition(<br>        record.topic(), record.key(), serializedKey,record.value(), serializedValue, cluster);<br>&#125;<br><span class="hljs-comment">// hash the keyBytes to choose a partition</span><br><span class="hljs-keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;<br><span class="hljs-comment">// 根据key字节数组的hash值和分区数量进行取模得到paritionId。在partition数量不变的情况，相同的key值数据可以被分配到相同的partition</span><br></code></pre></td></tr></table></figure>

<p>3.未指定partitionId，同时key也为null，此时会采用轮询的方式将消息均衡的分配到不同分区中（默认情况下key就是null）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//计算轮询值</span><br><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> <span class="hljs-title">nextValue</span><span class="hljs-params">(String topic)</span> </span>&#123;<br>        AtomicInteger counter = topicCounterMap.get(topic);<br>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">null</span> == counter) &#123;<br>                counter = <span class="hljs-keyword">new</span> AtomicInteger(ThreadLocalRandom.current().nextInt());<br>                AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);<br>                <span class="hljs-keyword">if</span> (currentCounter != <span class="hljs-keyword">null</span>) &#123;<br>                		counter = currentCounter;<br>                &#125;<br>        &#125; <br>    	<span class="hljs-keyword">return</span> counter.getAndIncrement();<br>&#125;<br><span class="hljs-comment">//key为空采用轮询方式均衡分配到不同Id</span><br><span class="hljs-keyword">if</span> (keyBytes == <span class="hljs-keyword">null</span>) &#123;<br>        <span class="hljs-keyword">int</span> nextValue = nextValue(topic);<br>        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);<br>        <span class="hljs-keyword">if</span> (availablePartitions.size() &gt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">int</span> part = Utils.toPositive(nextValue) %availablePartitions.size();<br>                <span class="hljs-keyword">return</span> availablePartitions.get(part).partition();<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-comment">// no partitions are available, give a nonavailable partition</span><br>                <span class="hljs-keyword">return</span> Utils.toPositive(nextValue) % numPartitions;<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="8-可用性和可靠性保证机制"><a href="#8-可用性和可靠性保证机制" class="headerlink" title="8. 可用性和可靠性保证机制"></a>8. 可用性和可靠性保证机制</h3><p>KafkaProducer发送数据请求，可以通过acks参数确保整个提交请求完成。acks主要是设置Producer在确认一条消息发送完成之前需要收到的反馈信息。  </p>
<p>acks=0，相当于异步发送，表示不等待任何服务器反馈消息，消息发送完毕即offset增加，继续生产。</p>
<p>优点：发送效率比较高，能够适应高并发场景。<br>缺点：不能够有效保证数据不丢失<br>适用场景：对于数据准确定要求不高的实时系统，登录、操作等log日志  </p>
<p>acks=1，leader收到leader replica 对一个消息的接受ack才增加offset，然后继续生产。</p>
<p>优点：该配置能够确保每个partition的leader节点能够成功的接收消息<br>缺点：不能够保证partition的副本节点接收到数据，该种情况有可能造成数据丢失。leader接收到消息后宕机，此时该partition的其他副本没有同步到该消息，这样就造成数据丢失</p>
<p>acks=-1/all，leader收到所有replica 对一个消息的接受ack才增加offset，然后继续生产。</p>
<p>优点：该配置能够最大限度的保证数据持久化并且不丢失<br>缺点：降低系统响应速度</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 该参数表示成功写入最小副本数</span><br>min.insync.replicas=2 表示只要是能够写入2个副本就表示成功。<br>生产环境下一般配合acks=-1使用，这样能够兼顾数据安全和响应速度  <br></code></pre></td></tr></table></figure>

<h3 id="9-ISR机制"><a href="#9-ISR机制" class="headerlink" title="9. ISR机制"></a>9. ISR机制</h3><p>ISR（In-Sync Replicas），副本同步队列。ISR中包括Leader和Follower，Leader副本负责维护和跟踪ISR集合中所有Follower副本的。当Follower副本同步Leader数据时，如果滞后太多或者失效的话，Leader会将Follower从ISR列表中移除从而转移到OSR。OSR集合中Follower一旦追上Leader副本，那么Leader会将该Follower从OSR集合转移到ISR中。当Leader副本发生故障时，只有在ISR集合的副本会有资格选举成Leader。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">replica.lag.time.max.ms=10000 单位毫秒：表示follower在规定的时间内没有同步完成Leader数据，将会被剔除从而到OSR中<br></code></pre></td></tr></table></figure>

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/BigData/Kafka/kafka-isr.png"/> </div>

<h3 id="10-Kafka幂等性和数据重复"><a href="#10-Kafka幂等性和数据重复" class="headerlink" title="10. Kafka幂等性和数据重复"></a>10. Kafka幂等性和数据重复</h3><p>Producer的幂等性指的是当发送同一条消息时，数据在Server端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：</p>
<p>1）<strong>只能保证Producer在单个会话内不丟不重，如果Producer出现意外而挂掉再重启是无法保证的</strong>（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）。</p>
<p>2）幂等性不能跨多个Topic-Partition，<strong>只能保证单个Partition内的幂等性</strong>，当涉及多个Topic-Partition时，这中间的状态并没有同步。</p>
<p>解决数据重复：开启幂等性+ack=-1+事务  </p>
<h3 id="11-Kafka参数优化"><a href="#11-Kafka参数优化" class="headerlink" title="11. Kafka参数优化"></a>11. Kafka参数优化</h3><p><strong>Broker参数配置（server.properties）</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">broker处理消息的最大线程数（默认为3）</span><br>num.network.threads=cpu核数+1<br><span class="hljs-meta">#</span><span class="bash"> broker处理磁盘IO的线程数</span> <br>num.io.threads=cpu核数*2<br><span class="hljs-meta">#</span><span class="bash"> 每当producer写入10000条消息时，刷数据到磁盘</span> <br>log.flush.interval.messages=10000<br><span class="hljs-meta">#</span><span class="bash"> 每间隔1秒钟时间，刷数据到磁盘</span><br>log.flush.interval.ms=1000<br><span class="hljs-meta">#</span><span class="bash"> 保留三天，也可以更短 （log.cleaner.delete.retention.ms）</span><br>log.retention.hours=72<br><span class="hljs-meta">#</span><span class="bash"> 这个参数指新创建一个topic时，默认的Replica数量,Replica过少会影响数据的可用性，太多则会白白浪费存储资源，一般建议在2~3为宜。</span><br>offsets.topic.replication.factor:3<br></code></pre></td></tr></table></figure>

<p><strong>Producer优化（producer.properties）</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">在Producer端用来存放尚未发送出去的Message的缓冲区大小。缓冲区满了之后可以选择阻塞发送或抛出异常，由block.on.buffer.full的配置来决定。</span><br>buffer.memory:33554432 (32m)<br><span class="hljs-meta">#</span><span class="bash">默认发送不进行压缩，推荐配置一种适合的压缩算法，可以大幅度的减缓网络压力和Broker的存储压力。</span><br>compression.type:none<br></code></pre></td></tr></table></figure>

<p><strong>Consumer优化</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">启动Consumer的个数，适当增加可以提高并发度。</span><br>num.consumer.fetchers:1<br><span class="hljs-meta">#</span><span class="bash">每次Fetch Request至少要拿到多少字节的数据才可以返回。</span><br>fetch.min.bytes:1<br><span class="hljs-meta">#</span><span class="bash">在Fetch Request获取的数据至少达到fetch.min.bytes之前，允许等待的最大时长。对应上面说到的Purgatory中请求的超时时间。</span><br>fetch.wait.max.ms:100<br></code></pre></td></tr></table></figure>

<p><strong>Kafka内存调整（kafka-server-start.sh）</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 默认内存1个G，生产环境尽量不要超过6个G。</span><br>export KAFKA_HEAP_OPTS=&quot;-Xms4g -Xmx4g&quot;<br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>Kafka</tag>
        <tag>消费</tag>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title>手把手教你做一份儿在线简历</title>
    <url>/2021/04/24/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%81%9A%E4%B8%80%E4%BB%BD%E5%84%BF%E5%9C%A8%E7%BA%BF%E7%AE%80%E5%8E%86/</url>
    <content><![CDATA[<blockquote>
<p>微信公众号：小康新鲜事儿</p>
</blockquote>
<h2 id="前置准备"><a href="#前置准备" class="headerlink" title="前置准备"></a>前置准备</h2><p>node-12.16.3、git-2.26.2.windows.1、Typora、Windows10</p>
<p>源码：<a href="https://github.com/xiaokangxxs/note/blob/master/noteSourceCode/profile.md">https://github.com/xiaokangxxs/note/blob/master/noteSourceCode/profile.md</a></p>
<p>演示地址：<a href="https://xiaokangxxs.github.io/note/profile/">https://xiaokangxxs.github.io/note/profile/</a> or <a href="https://xiaokang_188.gitee.io/note/profile/">https://xiaokang_188.gitee.io/note/profile/</a></p>
<h2 id="一、安装nodeppt"><a href="#一、安装nodeppt" class="headerlink" title="一、安装nodeppt"></a>一、安装nodeppt</h2><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">C:\Users\xiaok&gt;npm install -g nodeppt<br><br>+ nodeppt@2.2.2<br>added 1 package from 1 contributor, removed 2 packages and updated 13 packages in 52.997s<br></code></pre></td></tr></table></figure>

<h2 id="二、编写简历"><a href="#二、编写简历" class="headerlink" title="二、编写简历"></a>二、编写简历</h2><h3 id="2-1-使用nodeppt生成模板文件"><a href="#2-1-使用nodeppt生成模板文件" class="headerlink" title="2.1 使用nodeppt生成模板文件"></a>2.1 使用nodeppt生成模板文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">D:\NodePPT\nodeppt-在线简历制作&gt;nodeppt new profile.md<br>? Input your presentation topic:  个人简历<br>? Input your name:  小康&amp;小康新鲜事儿<br><br>�  profile.md create success!<br><br>──────────────────── �  Success! ────────────────────<br><br><br>     ┌────────────────────────────────────────────┐<br>     │  To get started: nodeppt serve profile.md  │<br>     └────────────────────────────────────────────┘<br></code></pre></td></tr></table></figure>

<h3 id="2-2-改写内容"><a href="#2-2-改写内容" class="headerlink" title="2.2 改写内容"></a>2.2 改写内容</h3><figure class="highlight markdown"><table><tr><td class="code"><pre><code class="hljs markdown">title: 小康个人简历<br>speaker: 小康&amp;小康新鲜事儿<br>url: https://www.xiaokang.cool/<br>prismTheme: solarizedlight <br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;bg-black aligncenter&quot;</span> <span class="hljs-attr">image</span>=<span class="hljs-string">&quot;https://cn.bing.com/az/hprichbg/rb/PragueChristmas_EN-AU8649790921_1920x1080.jpg .dark&quot;</span>&gt;</span></span><br><br><span class="hljs-section"># 个人简历 &#123;.text-landing.text-shadow.text-landing.animated.fadeInRight&#125;</span><br><br>小康 &#123;.text-intro&#125;<br><br><span class="hljs-bullet">-</span>   翻页\: ↑/↓/←/→ Space Home End<br><span class="hljs-bullet">-</span>   全屏\: F<br><span class="hljs-bullet">-</span>   预览\: -/+<br><span class="hljs-bullet">-</span>   网格背景\: Enter<br><br>[<span class="hljs-string">:fa-envelope: Email</span>](<span class="hljs-link">mailto:xiaokang.188@qq.com</span>)&#123;.button.ghost.animated.flipInX.delay-1200&#125;<br><br>:::footer<br>[<span class="hljs-string">:fa-comments: 小康新鲜事儿</span>](<span class="hljs-link">https://mp.weixin.qq.com/s/3-3_Ns5nDIhcB7TS7d-ocA</span>)&#123;.alignright&#125;<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::cta<br>::![](https://boyue-file.oss-cn-beijing.aliyuncs.com/profile/picture.png)::<br><br>---<br><span class="hljs-section">#### 小康<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span></span><br><span class="hljs-section">##### 求职意向：大数据开发工程师<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span></span><br><span class="hljs-section">##### 出生年月：1997.11&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;电话：1583223xxxx<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span></span><br><span class="hljs-section">##### 籍&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;贯：河北保定&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;邮箱：xiaokang.188@qq.com</span><br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::&#123;.content-center&#125;<br>:::flexblock &#123;.specs&#125;<br><span class="hljs-section">## 教育背景</span><br>2016.09-2020.06&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;xxxx学校&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;计算机科学与技术&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;本科<br><br>---<br><span class="hljs-section">## 专业技能</span><br>1.熟练掌握JAVA，了解Scala编程语言，拥有良好的编程习惯。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>2.熟悉Linux常用命令，熟练使用Shell编写脚本。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>3.熟悉Hadoop运行原理以及高可用部署安装，掌握HDFS的存储机制。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>4.熟练使用Flume、Sqoop、DataX实现数据采集、迁移。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>5.熟练使用Hive进行数据分析，掌握自定义UDF。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>6.熟悉Kafka工作原理，了解Kafka的Topic消息处理模式和消息分区备份机制。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>7.熟悉分布式数据库HBase工作原理，具备一定的HBase调优经验。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>8.了解离线多维分析Kylin的基本使用。<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::&#123;.content-center&#125;<br>:::flexblock &#123;.specs&#125;<br><span class="hljs-section">## 工作经历</span><br>时间：2019.06-2020.06<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>职位：大数据开发实习生<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>公司：xxxx有限公司<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>职责：1.参与大数据平台搭建与维护&amp;nbsp;2.协助完成Hive中的数据分析&amp;nbsp;3.完成与工作相关的技术文档编写<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::&#123;.content-center&#125;<br>:::flexblock &#123;.specs&#125;<br><span class="hljs-section">## 项目经验-1</span><br>项目名称：用户兴趣取向预测离线数据分析平台<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>技术架构：Flume+Kafka+HBase+Zookeeper+Hive+Hadoop+Sqoop+MySQL<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>项目描述：该项目是为活动举办方开发的活动分析预测大数据平台，通过Flume将第三方数据导入Kafka，通过Kafka流处理将数据放入HBase中。使用Hive关联HBase中的数据进行分析，将分析结果送到机器学习组进行建模，最终将分析预测结果送入HBase，导出到MySQL中并使用Tableau进行可视化展示，为企业活动举办提供决策支撑。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>主要职责：<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;1.参与大数据平台搭建与维护。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;2.通过Flume采集数据到Kafka。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;3.协助完成Hive中的数据分析。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;4.完成与工作相关的技术文档编写。<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::&#123;.content-center&#125;<br>:::flexblock &#123;.specs&#125;<br><span class="hljs-section">## 项目经验-2</span><br>项目名称：用户兴趣取向预测离线数据分析平台<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>技术架构：Flume+Kafka+HBase+Zookeeper+Hive+Hadoop+Sqoop+MySQL<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>项目描述：该项目是为活动举办方开发的活动分析预测大数据平台，通过Flume将第三方数据导入Kafka，通过Kafka流处理将数据放入HBase中。使用Hive关联HBase中的数据进行分析，将分析结果送到机器学习组进行建模，最终将分析预测结果送入HBase，导出到MySQL中并使用Tableau进行可视化展示，为企业活动举办提供决策支撑。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>主要职责：<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;1.参与大数据平台搭建与维护。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;2.通过Flume采集数据到Kafka。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;3.协助完成Hive中的数据分析。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;4.完成与工作相关的技术文档编写。<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::&#123;.content-center&#125;<br>:::flexblock &#123;.specs&#125;<br><span class="hljs-section">## 项目经验-3</span><br>项目名称：用户兴趣取向预测离线数据分析平台<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>技术架构：Flume+Kafka+HBase+Zookeeper+Hive+Hadoop+Sqoop+MySQL<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>项目描述：该项目是为活动举办方开发的活动分析预测大数据平台，通过Flume将第三方数据导入Kafka，通过Kafka流处理将数据放入HBase中。使用Hive关联HBase中的数据进行分析，将分析结果送到机器学习组进行建模，最终将分析预测结果送入HBase，导出到MySQL中并使用Tableau进行可视化展示，为企业活动举办提供决策支撑。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>主要职责：<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;1.参与大数据平台搭建与维护。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;2.通过Flume采集数据到Kafka。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;3.协助完成Hive中的数据分析。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>&amp;nbsp;&amp;nbsp;4.完成与工作相关的技术文档编写。<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span>&gt;</span></span><br>:::&#123;.content-center&#125;<br>:::flexblock &#123;.specs&#125;<br><span class="hljs-section">## 自我评价</span><br>1.善于学习总结，乐于分享，运营个人公众号&quot;小康新鲜事儿&quot;。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>2.抗压能力强，能快速适应公司的开发环境，能快速融入、凝聚团队。<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>3.良好的表达与沟通能力，积极主动，对工作尽心尽责。<br>:::<br><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">slide</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;bg-black-blue aligncenter&quot;</span> <span class="hljs-attr">image</span>=<span class="hljs-string">&quot;https://cn.bing.com/az/hprichbg/rb/PragueChristmas_EN-AU8649790921_1920x1080.jpg .dark&quot;</span>&gt;</span></span><br><span class="hljs-section">## 感谢您查看我的简历 &#123;.animated.tada&#125;</span><br><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">br</span>/&gt;</span></span><br>[<span class="hljs-string">:fa-cloud-download: nodeppt提供服务</span>](<span class="hljs-link">https://github.com/ksky521/nodeppt</span>)&#123;.button.animated.delay-1s.fadeInUp&#125;<br></code></pre></td></tr></table></figure>

<h3 id="2-3-本地预览效果"><a href="#2-3-本地预览效果" class="headerlink" title="2.3 本地预览效果"></a>2.3 本地预览效果</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">D:\NodePPT\nodeppt-在线简历制作&gt;nodeppt serve profile.md<br><br>  NodePPT running at:<br>  - Url: http://192.168.56.1:8081/<br>  - Speaker Mode: http://192.168.56.1:8081/?mode=speaker<br></code></pre></td></tr></table></figure>

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/profile-local.png"/> </div>

<h2 id="三、部署"><a href="#三、部署" class="headerlink" title="三、部署"></a>三、部署</h2><h3 id="3-1-GitHub上创建一个项目"><a href="#3-1-GitHub上创建一个项目" class="headerlink" title="3.1 GitHub上创建一个项目"></a>3.1 GitHub上创建一个项目</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/github-1.png"/> </div>
把地址记下来：[https://github.com/xiaokangxxs/nodeppt-profile.git](https://github.com/xiaokangxxs/nodeppt-profile.git)

<h3 id="3-2-打包本地项目"><a href="#3-2-打包本地项目" class="headerlink" title="3.2 打包本地项目"></a>3.2 打包本地项目</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell">D:\NodePPT\nodeppt-在线简历制作&gt;nodeppt build profile.md<br><br> DONE  Compiled successfully in 5387ms<br></code></pre></td></tr></table></figure>

<h3 id="3-3-将本地项目提交至GitHub"><a href="#3-3-将本地项目提交至GitHub" class="headerlink" title="3.3 将本地项目提交至GitHub"></a>3.3 将本地项目提交至GitHub</h3><figure class="highlight shell"><table><tr><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 初始化</span><br>git init<br><span class="hljs-meta">#</span><span class="bash"> 添加远程库地址</span><br>git remote add nodepptProfile https://github.com/xiaokangxxs/nodeppt-profile.git<br><span class="hljs-meta">#</span><span class="bash"> 将所有文件提交至暂存区</span><br>git add .<br><span class="hljs-meta">#</span><span class="bash"> 提交至本地库</span><br>git commit -m &quot;init profile&quot;<br><span class="hljs-meta">#</span><span class="bash"> 推送至GitHub远程库</span><br>git push nodepptProfile master<br></code></pre></td></tr></table></figure>

<h3 id="3-4-开启GitHub-Pages"><a href="#3-4-开启GitHub-Pages" class="headerlink" title="3.4 开启GitHub Pages"></a>3.4 开启GitHub Pages</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/github-2.png"/> </div>

<h3 id="3-5-查看效果"><a href="#3-5-查看效果" class="headerlink" title="3.5 查看效果"></a>3.5 查看效果</h3><p>开启GitHub Pages后稍等片刻即可访问制作的简历，地址：<a href="https://xiaokangxxs.github.io/nodeppt-profile/dist/profile.html">https://xiaokangxxs.github.io/nodeppt-profile/dist/profile.html</a></p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/github-3.png"/> </div>

<h3 id="3-6-部署至码云（访问速度更快）"><a href="#3-6-部署至码云（访问速度更快）" class="headerlink" title="3.6 部署至码云（访问速度更快）"></a>3.6 部署至码云（访问速度更快）</h3><div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/gitee-1.png"/> </div>
将`3.1`中的地址复制过来

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/gitee-2.png"/> </div>
点击`导入`后，来到代码主界面，点击`服务`选择`Gitee Pages`，按照下图配置后点击启动

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/gitee-3.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/gitee-4.png"/> </div>
地址：[https://xiaokang_188.gitee.io/nodeppt-profile/dist/profile.html](https://xiaokang_188.gitee.io/nodeppt-profile/dist/profile.html)，最终效果如下图所示：

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/profile/product.png"/> </div>

<h2 id="四、写在最后"><a href="#四、写在最后" class="headerlink" title="四、写在最后"></a>四、写在最后</h2><p>此文档记录了如何使用 nodeppt 结合 GitHub 和 Gitee 制作一份儿在线简历！另外，nodeppt 官方GitHub上也有相应的教程，不过我的这个文档比较贴合实际，方便大家快速上手。 记得三连哦！！！最后附上视频链接地址：<a href="https://www.bilibili.com/video/BV1ot4y1Q7ne">手把手教你做一份儿在线简历</a></p>
]]></content>
      <categories>
        <category>简历</category>
      </categories>
      <tags>
        <tag>实用</tag>
        <tag>简历</tag>
        <tag>在线</tag>
      </tags>
  </entry>
  <entry>
    <title>RDD常用算子</title>
    <url>/2021/04/24/RDD%E5%B8%B8%E7%94%A8%E7%AE%97%E5%AD%90/</url>
    <content><![CDATA[<h2 id="一、Transformation"><a href="#一、Transformation" class="headerlink" title="一、Transformation"></a>一、Transformation</h2><p>Spark常用的Transformation算子如下表：</p>
<table>
<thead>
<tr>
<th>Transformation 算子</th>
<th>Meaning（含义）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>map</strong>(<em>func</em>)</td>
<td>对原RDD中每个元素运用<em>func</em>函数，并生成新的RDD</td>
</tr>
<tr>
<td><strong>filter</strong>(<em>func</em>)</td>
<td>对原RDD中每个元素使用<em>func</em>函数进行过滤，并生成新的RDD</td>
</tr>
<tr>
<td><strong>flatMap</strong>(<em>func</em>)</td>
<td>与map类似，但是每一个输入的item被映射成0个或多个输出的items（ <em>func</em>返回类型需要为Seq）。</td>
</tr>
<tr>
<td><strong>mapPartitions</strong>(<em>func</em>)</td>
<td>与map类似，但函数单独在RDD的每个分区上运行， <em>func</em>函数的类型为*Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt;*，其中T是RDD的类型，即RDD[T]</td>
</tr>
<tr>
<td><strong>mapPartitionsWithIndex</strong>(<em>func</em>)</td>
<td>与mapPartitions类似，但<em>func</em>类型为 (Int,Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt;，其中第一个参数为分区索引</td>
</tr>
<tr>
<td><strong>sample</strong>(<em>withReplacement</em>, <em>fraction</em>, <em>seed</em>)</td>
<td>数据采样，有三个可选参数：设置是否放回（withReplacement）、采样的百分比（<em>fraction</em>）、随机数生成器的种子（seed）。</td>
</tr>
<tr>
<td><strong>union</strong>(<em>otherDataset</em>)</td>
<td>合并两个RDD</td>
</tr>
<tr>
<td><strong>intersection</strong>(<em>otherDataset</em>)</td>
<td>求两个RDD的交集</td>
</tr>
<tr>
<td><strong>distinct</strong>([<em>numTasks</em>]))</td>
<td>去重</td>
</tr>
<tr>
<td><strong>groupByKey</strong>([<em>numTasks</em>])</td>
<td>按照key值进行分区，即在一个 (K, V) 对的dataset上调用时，返回一个 (K, Iterable&lt;V&gt;) <strong>Note:</strong> 如果分组是为了在每一个key上执行聚合操作（例如，sum 或 average)，此时使用 <code>reduceByKey</code> 或<code>aggregateByKey</code> 性能会更好<strong>Note:</strong> 默认情况下，并行度取决于父 RDD 的分区数。可以传入 <code>numTasks</code> 参数进行修改。</td>
</tr>
<tr>
<td><strong>reduceByKey</strong>(<em>func</em>, [<em>numTasks</em>])</td>
<td>按照key值进行分组，并对分组后的数据执行归约操作（于groupByKey相比，reduceByKey会有提前combine操作）。</td>
</tr>
<tr>
<td><strong>aggregateByKey</strong>(<em>zeroValue</em>,<em>numPartitions</em>)(<em>seqOp</em>, <em>combOp</em>, [<em>numTasks</em>])</td>
<td>当调用（K，V）对的数据集时，返回（K，U）对的数据集，其中使用给定的组合函数和zeroValue聚合每个键的值。与groupByKey类似，reduce任务的数量可通过第二个参数进行配置。</td>
</tr>
<tr>
<td><strong>sortByKey</strong>([<em>ascending</em>], [<em>numTasks</em>])</td>
<td>按照key进行排序，其中的key需要实现Ordered特质，即可比较</td>
</tr>
<tr>
<td><strong>join</strong>(<em>otherDataset</em>, [<em>numTasks</em>])</td>
<td>在一个 (K, V) 和 (K, W) 类型的dataset上调用时，返回一个 (K, (V, W)) pairs 的dataset，等价于内连接操作。如果想要执行外连接，可以使用 <code>leftOuterJoin</code>, <code>rightOuterJoin</code> 和 <code>fullOuterJoin</code> 等算子。</td>
</tr>
<tr>
<td><strong>cogroup</strong>(<em>otherDataset</em>, [<em>numTasks</em>])</td>
<td>在一个 (K, V) 对的dataset上调用时，返回一个 (K, (Iterable&lt;V&gt;, Iterable&lt;W&gt;)) tuples的dataset。</td>
</tr>
<tr>
<td><strong>cartesian</strong>(<em>otherDataset</em>)</td>
<td>在一个T和U类型的dataset上调用时，返回一个 (T, U) 类型的dataset（即笛卡尔积）。</td>
</tr>
<tr>
<td><strong>coalesce</strong>(<em>numPartitions</em>)</td>
<td>将RDD中的分区数减少为numPartitions。</td>
</tr>
<tr>
<td><strong>repartition</strong>(<em>numPartitions</em>)</td>
<td>随机重新调整RDD中的数据以创建更多或更少的分区，并在它们之间进行平衡。</td>
</tr>
<tr>
<td><strong>repartitionAndSortWithinPartitions</strong>(<em>partitioner</em>)</td>
<td>根据给定的partitioner（分区器）对RDD进行重新分区，并对分区中的数据按照key值进行排序。这比调用 <code>repartition</code> 然后再sorting（排序）效率更高，因为它可以将排序过程推送到shuffle操作所在的机器。</td>
</tr>
</tbody></table>
<p>下面给出部分算子的基本使用示例：</p>
<h3 id="1-1-map"><a href="#1-1-map" class="headerlink" title="1.1 map"></a>1.1 map</h3><figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>)<br>scala&gt; sc.parallelize(list).map(_ * <span class="hljs-number">2</span>).foreach(println)<br><span class="hljs-number">2</span><br><span class="hljs-number">2</span><br><span class="hljs-number">4</span><br><span class="hljs-number">8</span><br></code></pre></td></tr></table></figure>

<h3 id="1-2-filter"><a href="#1-2-filter" class="headerlink" title="1.2 filter"></a>1.2 filter</h3><figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>)<br>scala&gt; sc.parallelize(list).filter(_ &gt;= <span class="hljs-number">2</span>).foreach(println)<br><span class="hljs-number">2</span><br><span class="hljs-number">4</span><br></code></pre></td></tr></table></figure>

<h3 id="1-3-flatMap"><a href="#1-3-flatMap" class="headerlink" title="1.3 flatMap"></a>1.3 flatMap</h3><p><code>flatMap(func)</code> 与 <code>map</code> 类似，但每一个输入的item会被映射成0个或多个输出的items（<em>func</em>返回类型需要为<code>Seq</code>）。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-type">List</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), <span class="hljs-type">List</span>(<span class="hljs-number">4</span>), <span class="hljs-type">List</span>(), <span class="hljs-type">List</span>(<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>))<br>scala&gt; sc.parallelize(list).flatMap(_.toList).foreach(println)<br><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">4</span><br><span class="hljs-number">4</span><br><span class="hljs-number">6</span><br><span class="hljs-number">8</span><br></code></pre></td></tr></table></figure>

<p>flatMap在日志分析中使用概率非常高，这里进行一下演示：拆分输入的每行数据为单个单词，并赋值为1，代表出现一次，之后按照单词分组并统计其出现总次数，代码如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> lines=<span class="hljs-type">List</span>(<span class="hljs-string">&quot;spark flume xiaokang spark scala&quot;</span>,<span class="hljs-string">&quot;hadoop scala xiaokangxxs xiaokang flume hive&quot;</span>)<br>scala&gt; sc.parallelize(lines).flatMap(_.split(<span class="hljs-string">&quot; &quot;</span>)).map((_,<span class="hljs-number">1</span>)).reduceByKey(_+_).foreach(println)<br>(scala,<span class="hljs-number">2</span>)<br>(xiaokangxxs,<span class="hljs-number">1</span>)<br>(spark,<span class="hljs-number">2</span>)<br>(hive,<span class="hljs-number">1</span>)<br>(hadoop,<span class="hljs-number">1</span>)<br>(flume,<span class="hljs-number">2</span>)<br>(xiaokang,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>

<h3 id="1-4-mapPartitions"><a href="#1-4-mapPartitions" class="headerlink" title="1.4 mapPartitions"></a>1.4 mapPartitions</h3><p>与map类似，但函数单独在RDD的每个分区上运行， <em>func</em>函数的类型为<code>Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt;</code> (其中T是RDD的类型)，即输入和输出都必须是可迭代类型。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">import</span> scala.collection.mutable.<span class="hljs-type">ListBuffer</span><br><span class="hljs-keyword">import</span> scala.collection.mutable.<span class="hljs-type">ListBuffer</span><br>scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>)<br>scala&gt; sc.parallelize(list, <span class="hljs-number">3</span>).mapPartitions(iterator =&gt; &#123;<br>     |   <span class="hljs-keyword">val</span> buffer = <span class="hljs-keyword">new</span> <span class="hljs-type">ListBuffer</span>[<span class="hljs-type">Int</span>]<br>     |   <span class="hljs-keyword">while</span> (iterator.hasNext) &#123;<br>     |      buffer.append(iterator.next()*<span class="hljs-number">3</span>)<br>     |   &#125;<br>     |   buffer.toIterator&#125;).foreach(println)<br><span class="hljs-number">3</span><br><span class="hljs-number">3</span><br><span class="hljs-number">6</span><br><span class="hljs-number">12</span><br><span class="hljs-number">18</span><br><span class="hljs-number">24</span><br></code></pre></td></tr></table></figure>

<h3 id="1-5-mapPartitionsWithIndex"><a href="#1-5-mapPartitionsWithIndex" class="headerlink" title="1.5 mapPartitionsWithIndex"></a>1.5 mapPartitionsWithIndex</h3><p>  与mapPartitions类似，但<em>func</em>类型为 <code>(Int, Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt;</code> ，其中第一个参数为分区索引。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">import</span> scala.collection.mutable.<span class="hljs-type">ListBuffer</span><br><span class="hljs-keyword">import</span> scala.collection.mutable.<span class="hljs-type">ListBuffer</span><br>scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>)<br>scala&gt; sc.parallelize(list, <span class="hljs-number">3</span>).mapPartitionsWithIndex((index,iterator) =&gt; &#123;<br>     |   <span class="hljs-keyword">val</span> buffer = <span class="hljs-keyword">new</span> <span class="hljs-type">ListBuffer</span>[<span class="hljs-type">String</span>]<br>     |   <span class="hljs-keyword">while</span> (iterator.hasNext) &#123;<br>     |      buffer.append(index+<span class="hljs-string">&quot;---&quot;</span>+iterator.next()*<span class="hljs-number">3</span>)<br>     |   &#125;<br>     |   buffer.toIterator&#125;).foreach(println)<br><span class="hljs-number">0</span>--<span class="hljs-number">-3</span><br><span class="hljs-number">0</span>--<span class="hljs-number">-3</span><br><span class="hljs-number">1</span>--<span class="hljs-number">-6</span><br><span class="hljs-number">1</span>--<span class="hljs-number">-12</span><br><span class="hljs-number">2</span>--<span class="hljs-number">-18</span><br><span class="hljs-number">2</span>--<span class="hljs-number">-24</span><br></code></pre></td></tr></table></figure>

<h3 id="1-6-sample"><a href="#1-6-sample" class="headerlink" title="1.6 sample"></a>1.6 sample</h3><p>数据采样。有三个可选参数：设置是否放回 (withReplacement)、采样的百分比 (fraction)、随机数生成器的种子 (seed) ：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>)<br>scala&gt; sc.parallelize(list).sample(withReplacement=<span class="hljs-literal">false</span>,fraction=<span class="hljs-number">0.5</span>).foreach(println)<br><span class="hljs-number">1</span><br><span class="hljs-number">1</span><br><span class="hljs-number">4</span><br><span class="hljs-number">6</span><br>scala&gt; sc.parallelize(list).sample(withReplacement=<span class="hljs-literal">false</span>,fraction=<span class="hljs-number">0.5</span>).foreach(println)<br><span class="hljs-number">1</span><br><span class="hljs-number">8</span><br>scala&gt; sc.parallelize(list).sample(withReplacement=<span class="hljs-literal">false</span>,fraction=<span class="hljs-number">0.5</span>).foreach(println)<br><span class="hljs-number">1</span><br>scala&gt; sc.parallelize(list).sample(withReplacement=<span class="hljs-literal">false</span>,fraction=<span class="hljs-number">0.5</span>).foreach(println)<br><span class="hljs-number">1</span><br><span class="hljs-number">4</span><br><span class="hljs-number">6</span><br></code></pre></td></tr></table></figure>

<h3 id="1-7-union"><a href="#1-7-union" class="headerlink" title="1.7 union"></a>1.7 union</h3><p>合并两个RDD：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list1=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br>scala&gt; <span class="hljs-keyword">val</span> list2=<span class="hljs-type">List</span>(<span class="hljs-number">6</span>,<span class="hljs-number">8</span>,<span class="hljs-number">10</span>)<br>scala&gt; sc.parallelize(list1).union(sc.parallelize(list2)).foreach(println)<br><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">6</span><br><span class="hljs-number">8</span><br><span class="hljs-number">10</span><br></code></pre></td></tr></table></figure>

<h3 id="1-8-intersection"><a href="#1-8-intersection" class="headerlink" title="1.8 intersection"></a>1.8 intersection</h3><p>求两个 RDD 的交集：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list1=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)<br>scala&gt; <span class="hljs-keyword">val</span> list2=<span class="hljs-type">List</span>(<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">9</span>,<span class="hljs-number">11</span>)<br>scala&gt; sc.parallelize(list1).intersection(sc.parallelize(list2)).foreach(println)<br><span class="hljs-number">6</span><br></code></pre></td></tr></table></figure>

<h3 id="1-9-distinct"><a href="#1-9-distinct" class="headerlink" title="1.9 distinct"></a>1.9 distinct</h3><p>去重：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>)<br>scala&gt; sc.parallelize(list).distinct().foreach(println)<br><span class="hljs-number">4</span><br><span class="hljs-number">1</span><br><span class="hljs-number">6</span><br><span class="hljs-number">8</span><br><span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>

<h3 id="1-10-groupByKey"><a href="#1-10-groupByKey" class="headerlink" title="1.10 groupByKey"></a>1.10 groupByKey</h3><p>按照键进行分组：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-string">&quot;hadoop&quot;</span>, <span class="hljs-number">2</span>), (<span class="hljs-string">&quot;spark&quot;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&quot;xiaokang&quot;</span>, <span class="hljs-number">5</span>), (<span class="hljs-string">&quot;spark&quot;</span>, <span class="hljs-number">6</span>), (<span class="hljs-string">&quot;hadoop&quot;</span>, <span class="hljs-number">2</span>))<br>scala&gt; sc.parallelize(list).groupByKey().map(x =&gt; (x._1, x._2.toList)).foreach(println)<br>(spark,<span class="hljs-type">List</span>(<span class="hljs-number">3</span>, <span class="hljs-number">6</span>))<br>(hadoop,<span class="hljs-type">List</span>(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>(xiaokang,<span class="hljs-type">List</span>(<span class="hljs-number">5</span>))<br></code></pre></td></tr></table></figure>

<h3 id="1-11-reduceByKey"><a href="#1-11-reduceByKey" class="headerlink" title="1.11 reduceByKey"></a>1.11 reduceByKey</h3><p>按照键进行归约操作：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-string">&quot;hadoop&quot;</span>, <span class="hljs-number">2</span>), (<span class="hljs-string">&quot;spark&quot;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&quot;xiaokang&quot;</span>, <span class="hljs-number">5</span>), (<span class="hljs-string">&quot;spark&quot;</span>, <span class="hljs-number">6</span>), (<span class="hljs-string">&quot;hadoop&quot;</span>, <span class="hljs-number">2</span>))<br>scala&gt; sc.parallelize(list).reduceByKey(_+_).foreach(println)<br>(spark,<span class="hljs-number">9</span>)<br>(hadoop,<span class="hljs-number">4</span>)<br>(xiaokang,<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure>

<h3 id="1-12-sortBy-amp-sortByKey"><a href="#1-12-sortBy-amp-sortByKey" class="headerlink" title="1.12 sortBy &amp; sortByKey"></a>1.12 sortBy &amp; sortByKey</h3><p>按照键进行排序：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-number">100</span>, <span class="hljs-string">&quot;hadoop&quot;</span>), (<span class="hljs-number">90</span>, <span class="hljs-string">&quot;spark&quot;</span>), (<span class="hljs-number">120</span>, <span class="hljs-string">&quot;xiaokangxxs&quot;</span>))<br>scala&gt; sc.parallelize(list).sortByKey(ascending=<span class="hljs-literal">false</span>).foreach(println)<br>(<span class="hljs-number">120</span>,xiaokangxxs)<br>(<span class="hljs-number">100</span>,hadoop)<br>(<span class="hljs-number">90</span>,spark)<br></code></pre></td></tr></table></figure>

<p>按照指定元素进行排序：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">100</span>), (<span class="hljs-string">&quot;spark&quot;</span>,<span class="hljs-number">90</span>), (<span class="hljs-string">&quot;xiaokangxxs&quot;</span>,<span class="hljs-number">120</span>))<br>scala&gt; sc.parallelize(list).sortBy(x=&gt;x._2,ascending=<span class="hljs-literal">false</span>).foreach(println)<br>(xiaokangxxs,<span class="hljs-number">120</span>)<br>(hadoop,<span class="hljs-number">100</span>)<br>(spark,<span class="hljs-number">90</span>)<br></code></pre></td></tr></table></figure>

<h3 id="1-13-join"><a href="#1-13-join" class="headerlink" title="1.13 join"></a>1.13 join</h3><p>在一个 (K, V) 和 (K, W) 类型的Dataset上调用时，返回一个 (K, (V, W)) 的Dataset，等价于内连接操作。如果想要执行外连接，可以使用 <code>leftOuterJoin</code>, <code>rightOuterJoin</code> 和 <code>fullOuterJoin</code> 等算子。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list1=<span class="hljs-type">List</span>((<span class="hljs-number">1</span>,<span class="hljs-string">&quot;student01&quot;</span>),(<span class="hljs-number">2</span>,<span class="hljs-string">&quot;student02&quot;</span>),(<span class="hljs-number">3</span>,<span class="hljs-string">&quot;student03&quot;</span>))<br>scala&gt; <span class="hljs-keyword">val</span> list2=<span class="hljs-type">List</span>((<span class="hljs-number">1</span>,<span class="hljs-string">&quot;teacher01&quot;</span>),(<span class="hljs-number">2</span>,<span class="hljs-string">&quot;teacher02&quot;</span>),(<span class="hljs-number">3</span>,<span class="hljs-string">&quot;teacher03&quot;</span>))<br>scala&gt; sc.parallelize(list1).join(sc.parallelize(list2)).foreach(println)<br>(<span class="hljs-number">1</span>,(student01,teacher01))<br>(<span class="hljs-number">3</span>,(student03,teacher03))<br>(<span class="hljs-number">2</span>,(student02,teacher02))<br></code></pre></td></tr></table></figure>

<h3 id="1-14-cartesian"><a href="#1-14-cartesian" class="headerlink" title="1.14 cartesian"></a>1.14 cartesian</h3><p>计算笛卡尔积：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list1=<span class="hljs-type">List</span>(<span class="hljs-string">&quot;xiaokang&quot;</span>, <span class="hljs-string">&quot;spark&quot;</span>, <span class="hljs-string">&quot;flink&quot;</span>)<br>scala&gt; <span class="hljs-keyword">val</span> list2=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br>scala&gt; sc.parallelize(list1).cartesian(sc.parallelize(list2)).foreach(println)<br>(xiaokang,<span class="hljs-number">1</span>)<br>(xiaokang,<span class="hljs-number">2</span>)<br>(xiaokang,<span class="hljs-number">3</span>)<br>(spark,<span class="hljs-number">1</span>)<br>(spark,<span class="hljs-number">2</span>)<br>(spark,<span class="hljs-number">3</span>)<br>(flink,<span class="hljs-number">1</span>)<br>(flink,<span class="hljs-number">2</span>)<br>(flink,<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure>

<h3 id="1-15-aggregateByKey"><a href="#1-15-aggregateByKey" class="headerlink" title="1.15 aggregateByKey"></a>1.15 aggregateByKey</h3><p>当调用（K，V）对的数据集时，返回（K，U）对的数据集，其中使用给定的组合函数和zeroValue聚合每个键的值。与<code>groupByKey</code>类似，reduce任务的数量可通过第二个参数<code>numPartitions</code>进行配置。示例如下：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">3</span>), (<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">2</span>), (<span class="hljs-string">&quot;spark&quot;</span>,<span class="hljs-number">4</span>), (<span class="hljs-string">&quot;spark&quot;</span>,<span class="hljs-number">3</span>), (<span class="hljs-string">&quot;storm&quot;</span>,<span class="hljs-number">6</span>), (<span class="hljs-string">&quot;storm&quot;</span>,<span class="hljs-number">8</span>))<br>scala&gt; sc.parallelize(list,numSlices = <span class="hljs-number">2</span>).aggregateByKey(zeroValue = <span class="hljs-number">0</span>,numPartitions = <span class="hljs-number">3</span>)(<br>     |  seqOp=math.max(_, _),<br>     |  combOp=_ + _<br>     | ).collect.foreach(println)<br>(hadoop,<span class="hljs-number">3</span>)<br>(storm,<span class="hljs-number">8</span>)<br>(spark,<span class="hljs-number">7</span>)<br></code></pre></td></tr></table></figure>

<p>这里使用了<code>numSlices = 2</code>指定aggregateByKey父操作parallelize的分区数量为2，其执行流程如下：</p>
<div align="center"> <img src="https://gitee.com/heibaiying/BigData-Notes/raw/master/pictures/spark-aggregateByKey.png"/> </div>
基于同样的执行流程，如果`numSlices=1`，则意味着只有输入一个分区，则其最后一步combOp相当于是无效的，执行结果为：

<figure class="highlight properties"><table><tr><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">(hadoop,3)</span><br><span class="hljs-attr">(storm,8)</span><br><span class="hljs-attr">(spark,4)</span><br></code></pre></td></tr></table></figure>

<p>同样的，如果每个单词对一个分区，即<code>numSlices=6</code>，此时相当于求和操作，执行结果为：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">(hadoop,5)</span><br><span class="hljs-attr">(storm,14)</span><br><span class="hljs-attr">(spark,7)</span><br></code></pre></td></tr></table></figure>

<p><code>aggregateByKey(zeroValue=0,numPartitions=3)</code>的第二个参数<code>numPartitions</code> 决定的是输出 RDD 的分区数量，想要验证这个问题，可以对上面代码进行改写，使用<code>getNumPartitions</code>方法获取分区数量：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; sc.parallelize(list,numSlices=<span class="hljs-number">6</span>).aggregateByKey(zeroValue=<span class="hljs-number">0</span>,numPartitions=<span class="hljs-number">3</span>)(<br>     |   seqOp = math.max(_, _),<br>     |   combOp = _ + _<br>     | ).getNumPartitions<br>res16: <span class="hljs-type">Int</span> = <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure>

<h2 id="二、Action"><a href="#二、Action" class="headerlink" title="二、Action"></a>二、Action</h2><p>Spark常用的Action算子如下：</p>
<table>
<thead>
<tr>
<th>Action（动作）</th>
<th>Meaning（含义）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>reduce</strong>(<em>func</em>)</td>
<td>使用函数<em>func</em>执行归约操作</td>
</tr>
<tr>
<td><strong>collect</strong>()</td>
<td>以一个array数组的形式返回dataset的所有元素，适用于小结果集。</td>
</tr>
<tr>
<td><strong>count</strong>()</td>
<td>返回RDD中元素的个数。</td>
</tr>
<tr>
<td><strong>first</strong>()</td>
<td>返回RDD中的第一个元素，不排序。</td>
</tr>
<tr>
<td><strong>take</strong>(<em>n</em>)</td>
<td>将RDD中的前<em>n</em>个元素作为一个array数组返回。</td>
</tr>
<tr>
<td><strong>takeSample</strong>(<em>withReplacement</em>, <em>num</em>, [<em>seed</em>])</td>
<td>对一个RDD进行随机抽样</td>
</tr>
<tr>
<td><strong>takeOrdered</strong>(<em>n</em>, <em>[ordering]</em>)</td>
<td>按自然顺序（natural order）或自定义比较器（custom comparator）排序后返回前<em>n</em>个元素。只适用于小结果集，因为所有数据都会被加载到驱动程序的内存中进行排序。</td>
</tr>
<tr>
<td><strong>saveAsTextFile</strong>(<em>path</em>)</td>
<td>将RDD中的元素以文本文件的形式写入本地文件系统、HDFS或其它 Hadoop支持的文件系统中。Spark将对每个元素调用toString方法，将元素转换为文本文件中的一行记录。</td>
</tr>
<tr>
<td><strong>saveAsSequenceFile</strong>(<em>path</em>)</td>
<td>将RDD中的元素以Hadoop SequenceFile的形式写入到本地文件系统、HDFS或其它Hadoop支持的文件系统中。该操作要求RDD中的元素需要实现Hadoop的Writable接口。对于Scala语言而言，它可以将Spark中的基本数据类型自动隐式转换为对应Writable类型。(目前仅支持Java and Scala)</td>
</tr>
<tr>
<td><strong>saveAsObjectFile</strong>(<em>path</em>)</td>
<td>使用Java序列化后存储，可以使用<code>SparkContext.objectFile()</code>进行加载。(目前仅支持Java and Scala)</td>
</tr>
<tr>
<td><strong>countByKey</strong>()</td>
<td>计算每个键出现的次数。</td>
</tr>
<tr>
<td><strong>foreach</strong>(<em>func</em>)</td>
<td>遍历RDD中每个元素，并对其执行<em>fun</em>函数</td>
</tr>
<tr>
<td><strong>foreachPartition</strong>(<em>func</em>)</td>
<td>与foreach类似，但函数单独在RDD的每个分区上运行，运用<em>func</em>函数，并生成新的RDD。</td>
</tr>
</tbody></table>
<p>下面给出部分算子的基本使用示例：</p>
<h3 id="2-1-take"><a href="#2-1-take" class="headerlink" title="2.1 take"></a>2.1 take</h3><p>将RDD中的前<em>n</em>个元素作为一个array数组返回：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>,<span class="hljs-number">11</span>)<br>scala&gt; sc.parallelize(list).take(<span class="hljs-number">3</span>)<br>res21: <span class="hljs-type">Array</span>[<span class="hljs-type">Int</span>] = <span class="hljs-type">Array</span>(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>

<h3 id="2-3-first"><a href="#2-3-first" class="headerlink" title="2.3 first"></a>2.3 first</h3><p>返回RDD中的第一个元素，不排序：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>,<span class="hljs-number">11</span>)<br>scala&gt; sc.parallelize(list).first<br>res22: <span class="hljs-type">Int</span> = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>

<h3 id="2-4-reduce"><a href="#2-4-reduce" class="headerlink" title="2.4 reduce"></a>2.4 reduce</h3><p>使用函数<em>func</em>执行归约操作：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>)<br>scala&gt; sc.parallelize(list).reduce(_+_)<br>res18: <span class="hljs-type">Int</span> = <span class="hljs-number">55</span><br></code></pre></td></tr></table></figure>

<h3 id="2-5-takeOrdered"><a href="#2-5-takeOrdered" class="headerlink" title="2.5 takeOrdered"></a>2.5 takeOrdered</h3><p>按自然顺序（natural order）或自定义比较器（custom comparator）排序后返回前 <em>n</em> 个元素。需要注意的是 <code>takeOrdered</code> 使用隐式参数进行隐式转换，以下为其源码。所以在使用自定义排序时，需要继承 <code>Ordering[T]</code> 实现自定义比较器，然后将其作为隐式参数引入。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">takeOrdered</span></span>(num: <span class="hljs-type">Int</span>)(<span class="hljs-keyword">implicit</span> ord: <span class="hljs-type">Ordering</span>[<span class="hljs-type">T</span>]): <span class="hljs-type">Array</span>[<span class="hljs-type">T</span>] = withScope &#123;<br>  .........<br>&#125;<br></code></pre></td></tr></table></figure>

<p>自定义规则排序：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 继承 Ordering[T],实现自定义比较器，按照 value 值的长度进行排序</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomOrdering</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Ordering</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)] </span>&#123;<br>    <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compare</span></span>(x: (<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>), y: (<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)): <span class="hljs-type">Int</span><br>    = <span class="hljs-keyword">if</span> (x._2.length &gt; y._2.length) <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure>

<p>具体使用：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomOrdering</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Ordering</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)] </span>&#123;<br>     |     <span class="hljs-keyword">override</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compare</span></span>(x: (<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>), y: (<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)): <span class="hljs-type">Int</span><br>     |     = <span class="hljs-keyword">if</span> (x._2.length &gt; y._2.length) <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">-1</span><br>     | &#125;<br>defined <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomOrdering</span></span><br><span class="hljs-class"></span><br><span class="hljs-class"><span class="hljs-title">scala&gt;</span> <span class="hljs-title">val</span> <span class="hljs-title">list=List</span>(<span class="hljs-params">(1,&quot;hadoop&quot;</span>),(<span class="hljs-params">1,&quot;xiaokangxxs&quot;</span>),(<span class="hljs-params">1,&quot;azkaban&quot;</span>),(<span class="hljs-params">1,&quot;hive&quot;</span>),(<span class="hljs-params">1,&quot;spark&quot;</span>))</span><br><span class="hljs-class"><span class="hljs-title">list</span></span>: <span class="hljs-type">List</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)] = <span class="hljs-type">List</span>((<span class="hljs-number">1</span>,hadoop), (<span class="hljs-number">1</span>,xiaokangxxs), (<span class="hljs-number">1</span>,azkaban), (<span class="hljs-number">1</span>,hive), (<span class="hljs-number">1</span>,spark))<br><br>scala&gt; <span class="hljs-keyword">implicit</span> <span class="hljs-keyword">val</span> implicitOrdering=<span class="hljs-keyword">new</span> <span class="hljs-type">CustomOrdering</span><br>implicitOrdering: <span class="hljs-type">CustomOrdering</span> = <span class="hljs-type">CustomOrdering</span>@<span class="hljs-number">3102</span>c986<br><br>scala&gt; sc.parallelize(list).takeOrdered(<span class="hljs-number">5</span>)<br>res20: <span class="hljs-type">Array</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">String</span>)] = <span class="hljs-type">Array</span>((<span class="hljs-number">1</span>,hive), (<span class="hljs-number">1</span>,spark), (<span class="hljs-number">1</span>,hadoop), (<span class="hljs-number">1</span>,azkaban), (<span class="hljs-number">1</span>,xiaokangxxs))<br></code></pre></td></tr></table></figure>

<h3 id="2-6-countByKey"><a href="#2-6-countByKey" class="headerlink" title="2.6 countByKey"></a>2.6 countByKey</h3><p>计算每个键出现的次数：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">10</span>),(<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">10</span>),(<span class="hljs-string">&quot;xiaokangxxs&quot;</span>,<span class="hljs-number">3</span>),(<span class="hljs-string">&quot;xiaokang&quot;</span>,<span class="hljs-number">3</span>),(<span class="hljs-string">&quot;azkaban&quot;</span>,<span class="hljs-number">1</span>))<br>scala&gt; sc.parallelize(list).countByKey()<br>res23: scala.collection.<span class="hljs-type">Map</span>[<span class="hljs-type">String</span>,<span class="hljs-type">Long</span>] = <span class="hljs-type">Map</span>(xiaokangxxs -&gt; <span class="hljs-number">1</span>, hadoop -&gt; <span class="hljs-number">2</span>, xiaokang -&gt; <span class="hljs-number">1</span>, azkaban -&gt; <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h3 id="2-7-saveAsTextFile"><a href="#2-7-saveAsTextFile" class="headerlink" title="2.7 saveAsTextFile"></a>2.7 saveAsTextFile</h3><p>将RDD中的元素以文本文件的形式写入本地文件系统、HDFS或其它Hadoop支持的文件系统中。Spark将对每个元素调用toString方法，将元素转换为文本文件中的一行记录。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><code class="hljs scala">scala&gt; <span class="hljs-keyword">val</span> list=<span class="hljs-type">List</span>((<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">10</span>),(<span class="hljs-string">&quot;hadoop&quot;</span>,<span class="hljs-number">10</span>),(<span class="hljs-string">&quot;xiaokangxxs&quot;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&quot;spark&quot;</span>, <span class="hljs-number">3</span>), (<span class="hljs-string">&quot;azkaban&quot;</span>, <span class="hljs-number">1</span>))<br>scala&gt; sc.parallelize(list).saveAsTextFile(<span class="hljs-string">&quot;file:///home/xiaokang/file_out&quot;</span>)<br><br>[xiaokang<span class="hljs-meta">@xk</span>1181259634 ~/file_out <span class="hljs-number">18</span>:<span class="hljs-number">03</span>:<span class="hljs-number">23</span>]$cat /home/xiaokang/file_out/part<span class="hljs-number">-00000</span><br>(hadoop,<span class="hljs-number">10</span>)<br>(hadoop,<span class="hljs-number">10</span>)<br>(xiaokangxxs,<span class="hljs-number">3</span>)<br>(spark,<span class="hljs-number">3</span>)<br>(azkaban,<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>RDD</tag>
        <tag>算子</tag>
      </tags>
  </entry>
  <entry>
    <title>WebScraper爬虫</title>
    <url>/2021/04/24/WebScraper%E7%88%AC%E8%99%AB/</url>
    <content><![CDATA[<h2 id="前置准备"><a href="#前置准备" class="headerlink" title="前置准备"></a>前置准备</h2><p>chrome浏览器、Web Scraper-0.2.0.18</p>
<h2 id="一、插件安装"><a href="#一、插件安装" class="headerlink" title="一、插件安装"></a>一、插件安装</h2><p>打开chrome浏览器，地址栏内输入：<code>chrome://extensions/</code>，点击<code>加载已解压的扩展程序</code>，选择webscraper</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/add-1.png"/> </div>
加载完成后，在页面鼠标右击选择`检查(或F12)`，可以看到`Web Scraper`选项

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/add-2.png"/> </div>
插件以及视频中sitemap下载地址：[https://wwa.lanzous.com/b02b87nda](https://wwa.lanzous.com/b02b87nda)，密码:5rjv 

<h2 id="二、数据爬取"><a href="#二、数据爬取" class="headerlink" title="二、数据爬取"></a>二、数据爬取</h2><h3 id="2-1-选取目标网址"><a href="#2-1-选取目标网址" class="headerlink" title="2.1 选取目标网址"></a>2.1 选取目标网址</h3><p>这里我以<code>bilibili</code>为例进行演示，我将会爬取python关键字相关的信息。网址：<a href="https://search.bilibili.com/all?keyword=python&from_source=nav_suggest_new">https://search.bilibili.com/all?keyword=python&amp;from_source=nav_suggest_new</a></p>
<p>进入开发者模式的<code>Web Scraper</code>选项栏中，准备开始爬取数据。</p>
<h3 id="2-2-新建一个Sitemap"><a href="#2-2-新建一个Sitemap" class="headerlink" title="2.2  新建一个Sitemap"></a>2.2  新建一个Sitemap</h3><p>点击Create new sitemap，里面有两个选项：Import sitemap是指导入一个已有的sitemap，Create sitemap表示我们要新建一个sitemap。 这里大家可以用我已经测试好的来看下效果，也可以自己动手创建一个新的（爬其它数据），我给大家从新建开始演示。</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-1.png"/> </div>
Sitemap name：给你要爬取的网页取个名字，需要使用英文字母，并且至少3个字符。比如我抓的是B站有关python的数据，那我就用bi-python-spider来命名。
Start URL：把需要爬取的网页链接复制到这里。

<p>最后点击下方的Create Sitemap完成新建</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-2.png"/> </div>

<h3 id="2-3-设置这个Sitemap"><a href="#2-3-设置这个Sitemap" class="headerlink" title="2.3  设置这个Sitemap"></a>2.3  设置这个Sitemap</h3><p>点击 Add new selector 创建一级Selector</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-3.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-4.png"/> </div>
设置好这个一级的Selector之后，点进去设置二级的Selector

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-5.png"/> </div>
重复上面二级Selector的操作，直到选完你想爬的字段

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-6.png"/> </div>

<h3 id="2-4-爬取数据"><a href="#2-4-爬取数据" class="headerlink" title="2.4  爬取数据"></a>2.4  爬取数据</h3><p>点击Scrape，设置好请求时间间隔和页面加载延迟（默认即可），然后点Start scraping，弹出一个小窗后爬虫就会开始工作。你会得到一个列表，上面有你想要的所有数据。 </p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-7.png"/> </div>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-8.png"/> </div>
由于我们只是爬取了第一页的数据，所以很快我们就可以看到结果

<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-9.png"/> </div>

<h3 id="2-5-数据导出"><a href="#2-5-数据导出" class="headerlink" title="2.5 数据导出"></a>2.5 数据导出</h3><p>这里我们可以将爬取的数据以CSV格式导出，同样也可以将Sitemap导出供他人使用。</p>
<div align="center"> <img width="600px" src="https://raw.githubusercontent.com/xiaokangxxs/notebook/master/docs/spider/scraper-10.png"/> </div>

<h2 id="三、其它"><a href="#三、其它" class="headerlink" title="三、其它"></a>三、其它</h2><p>有些时候我们需要爬取的数据往往会有分页，比如我们上面有关python的检索结果<a href="https://search.bilibili.com/all?keyword=python&from_source=nav_suggest_new&page=2">https://search.bilibili.com/all?keyword=python&amp;from_source=nav_suggest_new&amp;page=2</a>，这里第二页是通过路径一个page参数来进行传递。在Web Scraper 中提供了一种写法，可以设置页码范围及递增步长。格式： [开始值-结束值:步长]，举几个例子来说明一下：</p>
<p>1、获取2-6页，步长为1的页面 ：[2-6] 或者 [2-6:1]</p>
<p>2、获取2-6页，步长为2的页面：[2-6:2]</p>
<p>这里小编只是简单介绍总结了Web Scraper的插件的安装以及一个简单的单页面例子。其实Web Scraper的功能远远不止于此，它还能抓取分页、多页多元素的页面，还能抓取二级页面。需要大家自己慢慢摸索~~~ </p>
]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>chrome插件</tag>
        <tag>手把手教学</tag>
      </tags>
  </entry>
  <entry>
    <title>实用网站</title>
    <url>/2021/04/24/%E5%AE%9E%E7%94%A8%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<h3 id="搞学习"><a href="#搞学习" class="headerlink" title="搞学习"></a>搞学习</h3><ul>
<li>知乎：<a href="http://www.zhihu.com/">www.zhihu.com</a></li>
<li>TED（最优质的演讲）：<a href="https://www.ted.com/">https://www.ted.com/</a></li>
<li>大学资源网：<a href="http://www.dxzy163.com/">http://www.dxzy163.com/</a></li>
<li>简答题：<a href="http://www.jiandati.com/">http://www.jiandati.com/</a></li>
<li>网易公开课：<a href="https://open.163.com/ted/">https://open.163.com/ted/</a></li>
<li>网易云课堂：<a href="https://study.163.com/">https://study.163.com/</a></li>
<li>中国大学MOOC：<a href="http://www.icourse163.org/">www.icourse163.org</a></li>
<li>网易云课堂：study.163.com</li>
<li>哔哩哔哩弹幕网：<a href="http://www.bilibili.com/">www.bilibili.com</a></li>
<li>我要自学网：<a href="http://www.51zxw.net/">www.51zxw.net</a></li>
<li>学堂在线：<a href="http://www.xuetangx.com/">www.xuetangx.com</a></li>
<li>爱课程：<a href="http://www.icourses.cn/">www.icourses.cn</a></li>
<li>猫咪论文：<a href="https://lunwen.im/">https://lunwen.im/</a></li>
<li>iData（论文搜索）：<a href="http://www.cn-ki.net/">www.cn-ki.net</a></li>
<li>文泉考试：<a href="https://www.wqkaoshi.com/">https://www.wqkaoshi.com</a></li>
<li>码农之家（计算机电子书下载）：<a href="http://www.xz577.com/">www.xz577.com</a></li>
<li>鸠摩搜书：<a href="http://www.jiumodiary.com/">www.jiumodiary.com</a></li>
<li>云海电子图书馆：<a href="http://www.pdfbook.cn/">www.pdfbook.cn</a></li>
<li>周读（书籍搜索）：ireadweek.com</li>
<li>知轩藏书：<a href="http://www.zxcs.me/">http://www.zxcs.me/</a></li>
<li>脚本之家电子书下载：<a href="https://www.jb51.net/books/">https://www.jb51.net/books/</a></li>
<li>搜书VIP-电子书搜索：<a href="http://www.soshuvip.com/all.html">http://www.soshuvip.com/all.html</a></li>
<li>书格（在线古籍图书馆）：<a href="https://new.shuge.org/">https://new.shuge.org/</a></li>
<li>术语在线：<a href="http://www.termonline.cn/">http://www.termonline.cn/</a></li>
<li>必看网（人生必看的书籍）：<a href="https://www.biikan.com/">https://www.biikan.com/</a></li>
</ul>
<h3 id="冷知识-黑科技"><a href="#冷知识-黑科技" class="headerlink" title="冷知识 / 黑科技"></a>冷知识 / 黑科技</h3><ul>
<li>上班摸鱼必备（假装电脑系统升级）：<a href="http://fakeupdate.net/">http://fakeupdate.net/</a></li>
<li>创意光线绘画：<a href="http://weavesilk.com/">http://weavesilk.com/</a></li>
<li>星系观察：<a href="https://stellarium-web.org/">https://stellarium-web.org/</a></li>
<li>煎蛋：<a href="http://jandan.net/">http://jandan.net/</a></li>
<li>渣男-说话的艺术：<a href="https://lovelive.tools/">https://lovelive.tools/</a></li>
<li>全历史：<a href="https://www.allhistory.com/">https://www.allhistory.com/</a></li>
<li>iData：<a href="https://www.cn-ki.net/">https://www.cn-ki.net/</a></li>
<li>caj云阅读：<a href="http://cajviewer.cnki.net/cajcloud/">http://cajviewer.cnki.net/cajcloud/</a></li>
</ul>
<h3 id="资源搜索"><a href="#资源搜索" class="headerlink" title="资源搜索"></a>资源搜索</h3><ul>
<li>DogeDoge搜索引擎：<a href="http://www.dogedoge.com/">www.dogedoge.com</a></li>
<li>秘迹搜索：<a href="https://mijisou.com/">https://mijisou.com/</a></li>
<li>小白盘：<a href="https://www.xiaobaipan.com/">https://www.xiaobaipan.com/</a></li>
<li>云盘精灵（资源搜索）：<a href="http://www.yunpanjingling.com/">www.yunpanjingling.com</a></li>
<li>虫部落（资源搜索）：<a href="http://www.chongbuluo.com/">www.chongbuluo.com</a></li>
<li>如风搜（资源搜索）：<a href="http://www.rufengso.net/">http://www.rufengso.net/</a></li>
<li>爱扒：<a href="https://www.zyboe.com/">https://www.zyboe.com/</a></li>
</ul>
<h3 id="小工具"><a href="#小工具" class="headerlink" title="小工具"></a>小工具</h3><ul>
<li>云端超级应用空间（PS，PPT，Excel，Ai）：<a href="https://uzer.me/">https://uzer.me/</a></li>
<li>在线接口测试（Getman）：<a href="https://getman.cn/">https://getman.cn/</a></li>
<li>香当网（年终总结，个人简历，事迹材料，租赁合同，演讲稿）：<a href="https://www.xiangdang.net/">https://www.xiangdang.net/</a></li>
<li>二维码生成：<a href="https://cli.im/">https://cli.im/</a></li>
<li>搜狗翻译：fanyi.sogou.com</li>
<li>熵数（图表制作，数据可视化）：<a href="https://dydata.io/appv2/#/pages/index/home">https://dydata.io/appv2/#/pages/index/home</a></li>
<li>拷贝兔：<a href="https://cp.anyknew.com/">https://cp.anyknew.com/</a></li>
<li>图片无限变放大：<a href="http://bigjpg.com/zh">http://bigjpg.com/zh</a></li>
<li>幕布（在线大纲笔记工具）：mubu.com</li>
<li>奶牛快传（在线传输文件利器）：cowtransfer.com</li>
<li>在线转换器（在线转换器转换任何测量单位）：<a href="https://zh.justcnw.com/">https://zh.justcnw.com/</a></li>
<li>调查问卷制作：<a href="https://www.wenjuan.com/">https://www.wenjuan.com/</a></li>
<li>果核剥壳（软件下载）：<a href="https://www.ghpym.com/">https://www.ghpym.com/</a></li>
<li>软件下载：<a href="https://www.unyoo.com/">https://www.unyoo.com/</a></li>
<li>MSDN我告诉你（windows10系统镜像下载）：<a href="https://msdn.itellyou.cn/">https://msdn.itellyou.cn/</a></li>
</ul>
<h3 id="导航页（工具集）"><a href="#导航页（工具集）" class="headerlink" title="导航页（工具集）"></a>导航页（工具集）</h3><ul>
<li>NiceTool.net 好工具网：<a href="http://www.nicetool.net/">http://www.nicetool.net/</a></li>
<li>现实君工具箱（综合型在线工具集成网站）：<a href="http://tool.uixsj.cn/">http://tool.uixsj.cn/</a></li>
<li>蓝调网站：<a href="http://lcoc.top/">http://lcoc.top/</a></li>
<li>偷渡鱼：<a href="https://touduyu.com/">https://touduyu.com/</a></li>
<li>牛导航：<a href="http://www.ziliao6.com/">http://www.ziliao6.com/</a></li>
<li>小呆导航：<a href="https://www.webjike.com/index.html">https://www.webjike.com/index.html</a></li>
<li>简法主页：<a href="http://www.jianfast.com/">http://www.jianfast.com/</a></li>
<li>KIM主页：<a href="https://kim.plopco.com/">https://kim.plopco.com/</a></li>
<li>聚BT：<a href="https://jubt.net/cn/index.html">https://jubt.net/cn/index.html</a></li>
<li>精准云工具合集：<a href="https://jingzhunyun.com/">https://jingzhunyun.com/</a></li>
<li>兔2工具合集：<a href="https://www.tool2.cn/">https://www.tool2.cn/</a></li>
<li>爱资料工具（在线实用工具集合）：<a href="http://www.toolnb.com/">www.toolnb.com</a></li>
<li>工具导航：<a href="https://hao.logosc.cn/">https://hao.logosc.cn/</a></li>
</ul>
<h3 id="看视频"><a href="#看视频" class="headerlink" title="看视频"></a>看视频</h3><ul>
<li>电影推荐（分类别致）：<a href="http://www.mvcat.com/">http://www.mvcat.com</a></li>
<li>去看TV：<a href="https://www.qukantv.net/">https://www.qukantv.net/</a></li>
<li>动漫视频网：<a href="http://www.zzzfun.com/">http://www.zzzfun.com/</a></li>
<li>94神马电影网：<a href="http://www.9rmb.com/">http://www.9rmb.com/</a></li>
<li>NO视频官网：<a href="http://www.novipnoad.com/">http://www.novipnoad.com/</a></li>
<li>蓝光画质电影：<a href="http://www.languang.co/">http://www.languang.co/</a></li>
<li>在线看剧：<a href="http://dy.27234.cn/">http://dy.27234.cn/</a></li>
<li>大数据导航：<a href="http://hao.199it.com/">http://hao.199it.com/</a></li>
<li>多功能图片网站：<a href="https://www.logosc.cn/so/">https://www.logosc.cn/so/</a></li>
<li>牛牛TV：<a href="http://www.ziliao6.com/tv/">http://www.ziliao6.com/tv/</a></li>
<li>VideoFk解析视频：<a href="http://www.videofk.com/">http://www.videofk.com/</a></li>
<li>蓝调网站：<a href="http://lcoc.top/vip2.3/">http://lcoc.top/vip2.3/</a></li>
</ul>
<h3 id="学设计"><a href="#学设计" class="headerlink" title="学设计"></a>学设计</h3><ul>
<li>免费音频素材：<a href="https://icons8.cn/music">https://icons8.cn/music</a></li>
<li>新CG儿（视频素材模板，无水印+免费下载）：<a href="https://www.newcger.com/">https://www.newcger.com/</a></li>
<li>小图标下载：<a href="https://www.easyicon.net/">https://www.easyicon.net/</a></li>
<li>第一字体转换器：<a href="http://www.diyiziti.com/">http://www.diyiziti.com/</a></li>
<li>doyoudosh（平面设计）：<a href="http://www.doyoudo.com/">www.doyoudo.com</a></li>
<li>企业宣传视频在线制作：<a href="https://duomu.tv/">https://duomu.tv/</a></li>
<li>MAKE海报设计官网：<a href="http://maka.im/">http://maka.im/</a></li>
<li>一键海报神器：<a href="https://www.logosc.cn/photo/?utm_source=hao.logosc.cn&amp;utm_medium=referral">https://www.logosc.cn/photo/?utm_source=hao.logosc.cn&amp;utm_medium=referral</a></li>
<li>字由（字体设计）：<a href="http://www.hellofont.cn/">http://www.hellofont.cn/</a></li>
<li>查字体网站：<a href="https://fonts.safe.360.cn/">https://fonts.safe.360.cn/</a></li>
<li>爱给网（免费素材下载的网站，包括音效、配乐，3D、视频、游戏，平面、教程）：<a href="http://www.aigei.com/">http://www.aigei.com/</a></li>
<li>在线视频剪辑：<a href="https://bilibili.clipchamp.com/editor">https://bilibili.clipchamp.com/editor</a></li>
</ul>
<h3 id="搞文档"><a href="#搞文档" class="headerlink" title="搞文档"></a>搞文档</h3><ul>
<li>即书（在线制作PPT）：<a href="https://www.keysuper.com/">https://www.keysuper.com/</a></li>
<li>PDF处理：<a href="https://smallpdf.com/cn">https://smallpdf.com/cn</a></li>
<li>PDF处理：<a href="https://www.ilovepdf.com/zh-cn">https://www.ilovepdf.com/zh-cn</a></li>
<li>PDF处理：<a href="https://www.pdfpai.com/">https://www.pdfpai.com/</a></li>
<li>PDF处理：<a href="https://www.hipdf.cn/">https://www.hipdf.cn/</a></li>
<li>腾讯文档（在线协作编辑和管理文档）：docs.qq.com</li>
<li>ProcessOn（在线协作制作结构图）：<a href="http://www.processon.com/">www.processon.com</a></li>
<li>iLovePDF（在线转换PDF利器）：<a href="http://www.ilovepdf.com/">www.ilovepdf.com</a></li>
<li>PPT在线制作：<a href="https://www.woodo.cn/">https://www.woodo.cn/</a></li>
<li>PDF24工具（pdf处理工具）：<a href="https://tools.pdf24.org/en">https://tools.pdf24.org/en</a></li>
<li>IMGBOT（在线图片处理）：<a href="http://www.imgbot.ai/">www.imgbot.ai</a></li>
<li>福昕云编辑（在线编辑PDF）：edit.foxitcloud.cn</li>
<li>TinyPNG（在线压缩图片）：tinypng.com</li>
<li>UZER.ME（在线使用各种大应用，在线使用CAD，MATLAB，Office三件套<br>）：uzer.me</li>
<li>优品PPT（模板下载）：<a href="http://www.ypppt.com/">http://www.ypppt.com/</a></li>
<li>第一PPT（模板下载）：<a href="http://www.1ppt.com/xiazai/">http://www.1ppt.com/xiazai/</a></li>
<li>三顿PPT导航：sandunppt.com</li>
</ul>
<h3 id="找图片"><a href="#找图片" class="headerlink" title="找图片"></a>找图片</h3><ul>
<li>电脑壁纸：<a href="http://lcoc.top/bizhi/">http://lcoc.top/bizhi/</a></li>
<li><a href="https://unsplash.com/">https://unsplash.com/</a></li>
<li><a href="https://pixabay.com/">https://pixabay.com/</a></li>
<li><a href="https://www.pexels.com/">https://www.pexels.com/</a></li>
<li><a href="https://visualhunt.com/">https://visualhunt.com/</a></li>
<li><a href="https://www.ssyer.com/">https://www.ssyer.com/</a></li>
<li>彼岸图网：<a href="http://pic.netbian.com/">http://pic.netbian.com/</a></li>
<li>极像素（超高清大图）：<a href="https://www.sigoo.com/">https://www.sigoo.com/</a></li>
<li>免费版权图片搜索：<a href="https://www.logosc.cn/so/">https://www.logosc.cn/so/</a></li>
</ul>
]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>网站</tag>
        <tag>推荐</tag>
        <tag>实用</tag>
      </tags>
  </entry>
</search>
